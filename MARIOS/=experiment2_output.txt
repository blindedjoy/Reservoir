Total cpus available: 10
RUNNING EXPERIMENT 2 YOU ARE NOT RUNNING EXP TESTS RIGHT NOW
This is not a test
{'size': 'small', 'verbose': False, 'obs_freqs': [250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 900, 910, 920, 930, 940, 950, 960, 970, 980, 990, 1000, 1010, 1020, 1030, 1040, 1050, 1060, 1070, 1080, 1090, 1100, 1110, 1120, 1130, 1140], 'target_freqs': [500, 510, 520, 530, 540, 550, 560, 570, 580, 590, 600, 610, 620, 630, 640, 650, 660, 670, 680, 690, 700, 710, 720, 730, 740, 750, 760, 770, 780, 790, 800, 810, 820, 830, 840, 850, 860, 870, 880, 890], 'prediction_type': 'block', 'model': 'cyclic'}
dataset shape(512, 552)
resp_idx.shape (20,)
Train Region Train/Observers shape: (256, 26)
Test Region Train/Observers shape: (256, 26)
Train Region Target shape: (256, 20)
Test Region Target shape: (256, 20)
.cyclic.
cyclicrc cv set, ready to train 
Model initialization and exploration run...
Starting optimization... 

Hayden edit: space: <GPyOpt.core.task.space.Design_space object at 0x2b06d75e6910>
Hayden edit: fixed_parameters: ['n_nodes']
Hayden edit: free_parameters: ['cyclic_res_w', 'cyclic_input_w', 'cyclic_bias', 'leaking_rate']
Score: 0.997491323840343
Score: 0.9999811080917962
Score: 0.9932328870626306
Score: 0.9989623155327961
Score: 0.9525636314581981
Score: 0.7463618290574653
Score: 0.7822222024339048
Score: 0.7274067971531577
Score: 0.0939083971315462
Score: 0.9999463371274901
Score: 0.9868978441925371
Score: 0.24376536403603755
Score: 0.8515072233216422
Score: 0.991312672282158
Score: 0.9999515257233476
Score: 0.9974126923910995
Score: 0.5699873432949784
Score: 0.9999999999999979
Score: 0.36813514825892757
Score: 0.999999999999993
Score: 0.8889948539389285
Score: 0.9941123192025842
Score: 0.9964167031656547
Score: 1.0
Score: 0.535069405383633
Score: 0.9948786593493859
Score: 0.999999999902623
Score: 0.5442763055798423
Score: 0.9999868558744118
Score: 0.9976172432848273
Score: 0.9999920799070772
Score: 0.9993220732345215
Score: 0.9766226768404402
Score: 0.5363692103106457
Score: 0.9978510606132486
Score: 0.9745300786656655
Score: 0.8836793042320931
Score: 0.7891798936421263
Score: 0.998085163938637
Score: 0.12943197138495197
Score: 0.5085083849028698
Score: 0.9999999999998418
Score: 0.9544808952844203
Score: 1.0
Score: 1.0
Score: 1.0
Score: 0.7367760246648932
Score: 0.9997920159142074
Score: 0.9999747635700202
Score: 0.48122675943226423
Score: 0.9999980284551981
Score: 0.999991290352394
Score: 0.47093980660256496
Score: 0.9999999540015553
Score: 0.7048957851546329
Score: 0.9918482018027747
Score: 0.9999999974319089
Score: 0.9429303679969948
Score: 0.9357709092472193
Score: 0.7449169508268534
Score: 1.0
Score: 0.9999225911808677
Score: 0.9835869660555355
Score: 0.3476175848624028
Score: 0.9986468670911465
Score: 0.9808758048261325
Score: 0.9705851696114458
Score: 0.9999991884098253
Score: 0.9966850464747539
Score: 0.9991654195111462
Score: 0.9419755293878406
Score: 0.9783356790356535
Score: 0.9995071306739379
Score: 0.8699591956131215
Score: 1.0
Score: 0.9946439189959633
Score: 0.4229327805578651
Score: 0.24429715367099394
Score: 0.3940992416129894
Score: 0.9999999800200831
Score: 0.9654036149504648
Score: 0.8128883085069462
Score: 0.9968261973387423
Score: 0.9472477221632136
Score: 1.0
Score: 0.9896131385312483
Score: 0.9945293457523233
Score: 0.9934678638232853
Score: 0.9213321968946279
Score: 0.6365485743462567
Score: 0.20738508490717156
Score: 0.9993900159410842
Score: 1.0
Score: 0.9643761842082028
Score: 0.1125687024758102
Score: 0.2977910786185427
Score: 0.9798730099171854
Score: 0.9935753284825108
Score: 0.9999967174979137
Score: 0.9999929492172541
Model initialization done. 


Name : GP regression
Objective : 156.8736067434986
Number of Parameters : 6
Number of Optimization Parameters : 6
Updates : True
Parameters:
  [1mGP_regression.         [0;0m  |               value  |  constraints  |       priors      
  [1mMat52.variance         [0;0m  |  0.6515351786355258  |      +ve      |  iGa(0.001, 0.001)
  [1mMat52.lengthscale      [0;0m  |                (4,)  |      +ve      |  iGa(0.001, 0.001)
  [1mGaussian_noise.variance[0;0m  |  0.3245519711372225  |      +ve      |  iGa(0.001, 0.001) 

  [1mindex[0;0m  |  GP_regression.Mat52.lengthscale  |  constraints  |       priors      
  [1m[0]  [0;0m  |                       0.84897147  |      +ve      |  iGa(0.001, 0.001)
  [1m[1]  [0;0m  |                       0.44249945  |      +ve      |  iGa(0.001, 0.001)
  [1m[2]  [0;0m  |                       0.19942216  |      +ve      |  iGa(0.001, 0.001)
  [1m[3]  [0;0m  |                       1.04338847  |      +ve      |  iGa(0.001, 0.001) 

Score: 0.14334283691028335
Score: 0.09531268978991747
Score: 0.11434526465832502
Score: 0.10478761647468654
Score: 0.14967562964476225
Score: 0.11203125887901014
Score: 0.14917509448295682
Score: 0.14544295795092693
Score: 0.14185070707167882
Score: 0.09443085416144793
Score: 0.10041368800399715
Score: 0.1578623436422195
Score: 0.10682706270283707
Score: 0.0930369119439936
Score: 0.13826291259989193
Score: 0.09517963174068814
Score: 0.29227787552577156
Score: 0.1023869670871756
Score: 0.11707879480902926
Score: 0.09648672409076117
Score: 0.10864864406716288
Score: 0.11525354166869467
Score: 0.10431793443330653
Score: 0.09996638363271643
Score: 0.10423814078756814
Score: 0.21223031326832703
Score: 0.1475436772162348
Score: 0.10725341706105959
Score: 0.09888412141855721
Score: 0.09828879261041293
Score: 0.11911807275403787
Score: 0.09985709305059329
Score: 0.11433254464204116
Score: 0.15438951242158042
Score: 0.23762782004691335
Score: 0.10025180361285087
Score: 0.20086804494384308
Score: 0.1232243915828313
Score: 0.1055515482914579
Score: 0.10762000272949465
Score: 0.11235322118268411
Score: 0.11961515319468233
Score: 0.1167593788931783
Score: 0.10323120178846044
Score: 0.11393359034939261
Score: 0.09883285146627015
Score: 0.12630270998454768
Score: 0.0999783399564269
Score: 0.0938240732403084
Score: 0.11636796223311219
Score: 0.2282884162176037
Score: 0.11987620604721828
Score: 0.11103808591611732
Score: 0.14921528228288813
Score: 0.10972368052264077
Score: 0.12613260491460862
Score: 0.10899098309843734
Score: 0.14182124605611485
Score: 0.11532867888237731
Score: 0.16875118094075953
Score: 0.11228611013281187
Score: 0.11343231685264778
Score: 0.106448656484043
Score: 0.09463924154526164
Score: 0.1192369426093027
Score: 0.11002403738292488
Score: 0.10844291066814371
Score: 0.10931856982205791
Score: 0.10222873304092393
Score: 0.10164164319946858
Score: 0.10464693739653441
Score: 0.21544581661561307
Score: 0.10827207188230954
Score: 0.11777452627756561
Score: 0.09531146237043875
Score: 0.11077653316398009
Score: 0.09523780225379692
Score: 0.2007409114313165
Score: 0.11400676070899186
Score: 0.11445074119428099
Score: 0.16930746708752503
Score: 0.120174962419888
Score: 0.2232203988017785
Score: 0.10519038766570742
Score: 0.1088121868889186
Score: 0.1181492563222899
Score: 0.09946954849068783
Score: 0.24358185652075337
Score: 0.10312875812668154
Score: 0.1036109248094767
Score: 0.10770322410872013
Score: 0.10832984280971253
Score: 0.10887307037308641
Score: 0.21613463856731113
Score: 0.11238605285076536
Score: 0.2469592788990184
Score: 0.14288616009654678
Score: 0.10044806013890968
Score: 0.10138182441203998
Score: 0.10400236418432426
Score: 0.10515756215857432
Score: 0.10556753566919665
Score: 0.09973087977253332
Score: 0.10550272200200793
Score: 0.11105128400509527
Score: 0.20605757239371308
Score: 0.1109412383681481
Score: 0.11461594498751998
Score: 0.19872929822356966
Score: 0.10487070017567642
Score: 0.10245986040183913
Score: 0.1947998382625603
Score: 0.1192164942659815
Score: 0.12896914846628166
Score: 0.10711868360633912
Score: 0.11709729109819379
Score: 0.12446507867564259
Score: 0.11516847613861911
Score: 0.12919218749481887
Score: 0.10811570018466471
Score: 0.15651093969488622
Score: 0.10649952865711194
Score: 0.16739811717119976
Score: 0.10816933374364505
Score: 0.12677924327471954
Score: 0.10030514853890675
Score: 0.10031513260704304
Score: 0.1269237310431301
Score: 0.12340250683103493
Score: 0.09876895157802515
Score: 0.10968795599777995
Score: 0.11330080150255305
Score: 0.10784160184723428
Score: 0.09864934497529493
Score: 0.09158981930074377
Score: 0.24784449854697777
Score: 0.1209286981834271
Score: 0.1214149878246749
Score: 0.12112142555957858
Score: 0.11807826225032905
Score: 0.09867779110920984
Score: 0.11355230175558247
Score: 0.11043443087104646
Score: 0.10598344241137315
Score: 0.11091043483171643
Score: 0.10897770739233316
Score: 0.11070119714228423
Score: 0.11411367662740618
Score: 0.10645915356639148
Score: 0.10488835705244451
Score: 0.09629983030757548
Score: 0.10838270436934841
Score: 0.2426183015382652
Score: 0.2138027052303337
Score: 0.10020314887834653
Score: 0.10685120245384346
Score: 0.10473260874699152
Score: 0.1187394307168013
Score: 0.1019776087555465
Score: 0.1171765771341476
Score: 0.10367563789678111
Score: 0.10489963532600527
Score: 0.2284158341344171
Score: 0.09623917278060938
Score: 0.09284929278594227
Score: 0.2700648524412514
Score: 0.13853245729558994
Score: 0.10821303069173152
Score: 0.25844350554047707
Score: 0.1258838656570301
Score: 0.11524886923016912
Score: 0.10643867558123726
Score: 0.12796950678520191
Score: 0.10913888977006993
Score: 0.09602368450602768
Score: 0.10487270275115339
Score: 0.09514141169108478
Score: 0.10732140249210777
Score: 0.09791088871905916
Score: 0.11186882795566185
Score: 0.28786492362426525
Score: 0.10789858181226956
Score: 0.10147761406804046
Score: 0.12894896432673725
Score: 0.23561431154855764
Score: 0.10467772008915062
Score: 0.09825553998808774
Score: 0.10108112161389471
Score: 0.09926383295968326
Score: 0.10214514365075163
Score: 0.11873386563533457
Score: 0.1795916221459298
Score: 0.10392627327908818
Score: 0.1030422187134105
Score: 0.14994644244875197
Score: 0.11630945630666305
Score: 0.11307525889650431
Score: 0.10979899749381802
Score: 0.14086414970953248
Score: 0.09540733477460013
Score: 0.11996655604815022
Score: 0.10827976953787043
Score: 0.10316261025663936
Score: 0.1058209589006529
Score: 0.13114534893183133
Score: 0.1463565258978915
Score: 0.10009350510713974
Score: 0.10325569757754591
Score: 0.11047660638543468
Score: 0.10119787794466231
Score: 0.11266968223491323
Score: 0.10274230508317651
Score: 0.11259729522429968
Score: 0.2589790432040546
Score: 0.14641894335184022
Score: 0.3120651522906952
Score: 0.11568763571137562
Score: 0.10862208380242094
Score: 0.10868102250659979
Score: 0.20358989540988212
Score: 0.1139050527281419
Score: 0.09926873620536697
Score: 0.12095880314347048
Score: 0.11679179685870794
Score: 0.10825575690566168
Score: 0.21457776778936508
Score: 0.10935706715797221
Score: 0.10932655133770662
Score: 0.10757597488983572
Score: 0.10682557349044126
Score: 0.10604762068870563
Score: 0.10360704342352373
Score: 0.09392913589455766
Score: 0.10648569953042415
Score: 0.11001777119060345
Score: 0.10901200499947566
Score: 0.10370857134568946
Score: 0.13265319875460008
Score: 0.09475292290162321
Score: 0.18154328040988363
Score: 0.11695727833479995
Score: 0.12065543408402381
Score: 0.20640764401830536
Score: 0.09557259934024823
Score: 0.11844226718525075
Score: 0.10628286508361902
Score: 0.19163056676982923
Score: 0.1169853445039195
Score: 0.12948634818982094
Score: 0.11365210042508282
Score: 0.09756766248537095
Score: 0.10076527077091141
Score: 0.17735991701943601
Score: 0.1663428288563585
Score: 0.2595709980354993
Score: 0.10684304151477013
Score: 0.1048247040449696
Score: 0.12628218506579458
Score: 0.13264687063073693
Score: 0.11750930607408969
Score: 0.11000407587452449
Score: 0.12007086295472735
Score: 0.09920577181216973
Score: 0.09922308206788442
Score: 0.20306329312117508
Score: 0.10198138757649092
Score: 0.09695262501565162
Score: 0.1859057042821874
Score: 0.10839967624000772
Score: 0.12114765398200512
Score: 0.09898748010241223
Score: 0.10814978375040114
Score: 0.11563209804665885
Score: 0.09596629451463437
Score: 0.11198882728577689
Score: 0.1498341865670522
Score: 0.11795102909391578
Score: 0.12735657691779537
Score: 0.1143091509301997
Score: 0.16895034805324935
Score: 0.20661181388776237
Score: 0.11831146006104855
Score: 0.11035566910350075
Score: 0.18429667125957253
Score: 0.20558460912180898
Score: 0.11314304137551072
Score: 0.21625229019607475
Score: 0.0996726253579169
Score: 0.09850427220378585
Score: 0.10713284836854682
Score: 0.1535832339908179
Score: 0.09955917779299518
Score: 0.10451502178850008
Score: 0.107606022842001
Score: 0.10374168112451988
Score: 0.11270985805271404
Score: 0.10274121302221223
Score: 0.09751061228491047
Score: 0.22932398146536395
Score: 0.11414358278526333
Score: 0.13316530592076306
Score: 0.10230416082498264
Score: 0.14760655353626267
Score: 0.1450304681364722
Score: 0.2751782767193788
Score: 0.1378402740809141
Score: 0.11372381726911177
Score: 0.10711189821643562
Score: 0.12590199104191085
Score: 0.09753209758272498
Score: 0.19263284185876495
Score: 0.1042841839464395
Score: 0.09998504965143212
Score: 0.14681266403574356
Score: 0.11546502264720697
Score: 0.10830243995361397
Score: 0.124420208999816
Score: 0.10727055531908297
Score: 0.13172537778685925
Score: 0.10819423061207714
Score: 0.1455928148770153
Score: 0.1102607505971174
Score: 0.18690542453322656
Score: 0.09963219193870763
Score: 0.10056980000112917
Score: 0.10224550163793623
Score: 0.11033201900866078
Score: 0.11542930287111657
Score: 0.11407227201307828
Score: 0.09623118393638234
Score: 0.10943819938983863
Score: 0.1240178186877439
Score: 0.11439970793249898
Score: 0.1701517176244421
Score: 0.10415782275369062
Score: 0.13362348147969783
Score: 0.09498347455364423
Score: 0.10686772857012897
Score: 0.11134470188528738
Score: 0.14316445948113213
Score: 0.11206102530259883
Score: 0.10374019605940825
Score: 0.09904934747126107
Score: 0.10857454729103859
Score: 0.2035120810440624
Score: 0.1075977248191843
Score: 0.1166739597148245
Score: 0.10477344725190256
Score: 0.10476479506803611
Score: 0.10646345385548624
Score: 0.09695224271062536
Score: 0.11853480477376169
Score: 0.10306887063993825
Score: 0.10554823510198331
Score: 0.10260642407505668
Score: 0.17734619037115654
Score: 0.11486603463422775
Score: 0.11887574312562317
Score: 0.09867779400798886
Score: 0.10546617719235206
Score: 0.12409366304478021
Score: 0.1362183990927249
Score: 0.1140014771031608
Score: 0.11532814125771972
Score: 0.10766628096067388
Score: 0.09378510771982548
Score: 0.10260643597142062
Score: 0.13352499878000218
Score: 0.1044701489949315
Score: 0.10049639096376013
Score: 0.1083411368886465
Score: 0.10113375905971987
Score: 0.11369844224911226
Score: 0.10726806180317035
Score: 0.13826929070897656
Score: 0.11665061438438167
Score: 0.1278053635473372
Score: 0.09011630557833288
Score: 0.14581152309055023
Score: 0.0971267682207047
Score: 0.11850641772653449
Score: 0.10344693262947692
Score: 0.3492733553803405
Score: 0.11696309518179755
Score: 0.11200190279435865
Score: 0.1055299879928975
Score: 0.10768083289831809
Score: 0.11296464830349386
Score: 0.11151312661306913
Score: 0.1461997823944568
Score: 0.11595330159956502
Score: 0.10768761920489851
Score: 0.19530749032204955
Score: 0.15061056427919936
Score: 0.10496824958193551
Score: 0.10485267273621268
Score: 0.10747466070405011
Score: 0.11220277590903996
Score: 0.10540547014018253
Score: 0.1995464009883614
Score: 0.1520474374462911
Score: 0.10929898299141744
Score: 0.12196319966662268
Score: 0.11695656894880699
Score: 0.09983955043769928
Score: 0.09614887580654843
Score: 0.1062569119125641
Score: 0.10566957252931404
Score: 0.10897783639230348
Score: 0.22732875915998008
Score: 0.11072698222307124
Score: 0.18394001604646892
Score: 0.20032580640568368
Score: 0.10354244912990758
Score: 0.1053135995497439
Score: 0.15679682410239354
Score: 0.33627242582833117
Score: 0.11608047883883765
Score: 0.10372015191558716
Score: 0.10180836027051417
Score: 0.09380053375755985
Score: 0.2029000087634308
Score: 0.10795309814266164
Score: 0.10564334148630602
Score: 0.1022110764013698
Score: 0.2706740052215112
Score: 0.33775638688274
Score: 0.10680974342937087
Score: 0.11523232948969907
Converged at iteration 529
Done after 529 iterations.
Bayesian Optimization complete. Now running saving data, getting prediction etc. 
{'bounds': {'n_nodes': 1000, 'cyclic_res_w': (-4, 0.5), 'cyclic_input_w': (-4, 0.5), 'cyclic_bias': (-1, 1), 'leaking_rate': (0.001, 1)}, 'scoring_method': 'tanh', 'n_jobs': 10, 'verbose': True, 'plot': False, 'cv_samples': 6, 'max_iterations': 1000, 'eps': 1e-05, 'subsequence_length': 180, 'initial_samples': 100, 'activation_function': 'sin_sq', 'model_type': 'cyclic', 'esn_feedback': False, 'obs_index': [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], 'target_index': [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], 'exp_weights': False}
{'bounds': {'n_nodes': 1000, 'cyclic_res_w': (-4, 0.5), 'cyclic_input_w': (-4, 0.5), 'cyclic_bias': (-1, 1), 'leaking_rate': (0.001, 1)}, 'scoring_method': 'tanh', 'n_jobs': 10, 'verbose': True, 'plot': False, 'cv_samples': 6, 'max_iterations': 1000, 'eps': 1e-05, 'subsequence_length': 180, 'initial_samples': 100, 'activation_function': 'sin_sq'}
{'cyclic_res_w': 0.003924064541909408, 'cyclic_input_w': 0.0001, 'cyclic_bias': 1.2138562032071165, 'leaking_rate': 0.001, 'n_nodes': 1000, 'random_seed': 123, 'feedback': False}
initialiazing json2be


object doesn't have the prediction attribute.


object doesn't have the prediction attribute.

 
 rc cv data saved @ : experiment_results/small/split_0.5/block_cyclicN_Targidx_20N_Obsidx_26.pickle
Time:  1604.3367290230235
