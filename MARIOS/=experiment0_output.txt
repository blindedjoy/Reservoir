Total cpus available: 10
RUNNING EXPERIMENT 0 YOU ARE NOT RUNNING EXP TESTS RIGHT NOW
TEST
single column target[299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374]
experiment_inputs: {'size': 'small', 'target_frequency': None, 'verbose': False, 'prediction_type': 'column', 'train_time_idx': [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], 'test_time_idx': [299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374], 'k': None, 'model': 'cyclic'}
obs_inputs: {'split': 0.5, 'aspect': 0.9, 'plot_split': False, 'method': 'exact'}
.cyclic.
cyclicrc cv set, ready to train 
Warning: y-array has more series (columns) than samples (rows). Check if this is correct
Model initialization and exploration run...
Starting optimization... 

Hayden edit: space: <GPyOpt.core.task.space.Design_space object at 0x2b44c1c26450>
Hayden edit: fixed_parameters: ['n_nodes']
Hayden edit: free_parameters: ['cyclic_res_w', 'cyclic_input_w', 'cyclic_bias', 'leaking_rate']
Score: 0.9598247748164328
Score: 0.08947473187787632
Score: 0.949194191263351
Score: 0.7143114675929076
Score: 0.9116343841675079
Score: 0.3220331258524916
Score: 0.6165078795171861
Score: 0.0851060925767662
Score: 0.38085118880366303
Score: 0.08757383810231024
Score: 0.8653743447227334
Score: 0.5623307272321233
Score: 0.9905257612215864
Score: 0.9952363732155884
Score: 0.9801885209730731
Score: 0.710296126546738
Score: 0.9173227302528466
Score: 0.8191681785573296
Score: 0.47296695342765943
Score: 0.07959437637491971
Score: 0.8743514949574929
Score: 0.4953514375248696
Score: 0.3007159396584183
Score: 0.9976708584484333
Score: 0.9838748406086839
Score: 0.1632620676143407
Score: 0.9883766612584527
Score: 0.43788261570668335
Score: 0.06867759326797576
Score: 0.891405609322391
Score: 0.7783568720841515
Score: 0.7910955473234436
Score: 0.10041497333477205
Score: 0.15508025392693622
Score: 0.08859239069190597
Score: 0.6571105534753408
Score: 0.3654110220174875
Score: 0.8021873830884424
Score: 0.1602680492492916
Score: 0.4385830700283475
Score: 0.7362563466585694
Score: 0.3635864612329114
Score: 0.9956375476840257
Score: 0.754310833999541
Score: 0.07941789741052671
Score: 0.31308902938777794
Score: 0.9247045786043931
Score: 0.6590985713812783
Score: 0.09188078244579923
Score: 0.8931601587487866
Score: 0.975033041651327
Score: 0.19690239412114754
Score: 0.999672860138362
Score: 0.11726347044137832
Score: 0.8621885742955362
Score: 0.986276161763509
Score: 0.5167989245808524
Score: 0.13250535553433265
Score: 0.3690965476157941
Score: 0.8329851640395407
Score: 0.4710857162730348
Score: 0.2146327531880775
Score: 0.8825389676289231
Score: 0.29061062642176755
Score: 0.20501421284467417
Score: 0.9682756288820664
Score: 0.1099463889898777
Score: 0.992665430553332
Score: 0.9176879163937983
Score: 0.48002226811869436
Score: 0.41222722314813237
Score: 0.990997624291055
Score: 0.2642674598549165
Score: 0.9335060974191165
Score: 0.11844056409049143
Score: 0.3732822002603516
Score: 0.9909241192132773
Score: 0.9649432770649049
Score: 0.9584423708787001
Score: 0.4444963063108699
Score: 0.9064525167187037
Score: 0.44549831377138227
Score: 0.5644158421616893
Score: 0.9358675194851854
Score: 0.8297317080782414
Score: 0.9931356558149956
Score: 0.10059479806315882
Score: 0.48242734177892993
Score: 0.41890284954761886
Score: 0.2492790901200093
Score: 0.9918272815339417
Score: 0.14369791029438414
Score: 0.25855440022380366
Score: 0.9712771561460688
Score: 0.13855758720835706
Score: 0.9592682158832535
Score: 0.9833504379460574
Score: 0.9724634705585915
Score: 0.5105536754232071
Score: 0.2417757793048784
Model initialization done. 


Name : GP regression
Objective : 133.73430515944733
Number of Parameters : 6
Number of Optimization Parameters : 6
Updates : True
Parameters:
  [1mGP_regression.         [0;0m  |                value  |  constraints  |       priors      
  [1mMat52.variance         [0;0m  |   0.9663627991896993  |      +ve      |  iGa(0.001, 0.001)
  [1mMat52.lengthscale      [0;0m  |                 (4,)  |      +ve      |  iGa(0.001, 0.001)
  [1mGaussian_noise.variance[0;0m  |  0.07145736479227224  |      +ve      |  iGa(0.001, 0.001) 

  [1mindex[0;0m  |  GP_regression.Mat52.lengthscale  |  constraints  |       priors      
  [1m[0]  [0;0m  |                       1.41899081  |      +ve      |  iGa(0.001, 0.001)
  [1m[1]  [0;0m  |                       0.23884315  |      +ve      |  iGa(0.001, 0.001)
  [1m[2]  [0;0m  |                       0.28528411  |      +ve      |  iGa(0.001, 0.001)
  [1m[3]  [0;0m  |                       0.49658996  |      +ve      |  iGa(0.001, 0.001) 

Score: 0.09234560930257571
Score: 0.07125988495038015
Score: 0.06555398627456278
Score: 0.08125800723334121
Score: 0.9417439536430212
Score: 0.13961570990728012
Score: 0.09473286942924962
Score: 0.09014922110923583
Score: 0.0957175701229052
Score: 0.1227644322667078
Score: 0.09356892568246973
Score: 0.10114766123240963
Score: 0.1352089814245785
Score: 0.08544356385884529
Score: 0.12928442259349257
Score: 0.11665352022093577
Score: 0.08294732196370302
Score: 0.0882306992894816
Score: 0.12305427249402161
Score: 0.10653090936040957
Score: 0.11600515566781569
Score: 0.08127677930990942
Score: 0.11098219901849964
Score: 0.0777002659827086
Score: 0.06780496108467474
Score: 0.08478516734106994
Score: 0.11197553077582911
Score: 0.10523882460912863
Score: 0.0762142836874188
Score: 0.15221606725186937
Score: 0.10922386675899463
Score: 0.10244927804680813
Score: 0.12942073958612518
Score: 0.08595542560135655
Score: 0.1022462430430404
Score: 0.08149441746011918
Score: 0.09378465287198166
Score: 0.06779206793633051
Score: 0.07936175730206298
Score: 0.14309494056020283
Score: 0.10981413669844498
Score: 0.06853396381070623
Score: 0.1182026263454722
Score: 0.08180404592038718
Score: 0.09436714942657912
Score: 0.09978207101107055
Score: 0.09954142628457388
Score: 0.08149737052233913
Score: 0.07785960049869577
Score: 0.10889712825986866
Score: 0.09038431164237073
Score: 0.08130948959506368
Score: 0.09757590708633902
Score: 0.06903382311791746
Score: 0.11630152396933792
Score: 0.09496951076397707
Score: 0.08197095862893623
Score: 0.0832608605254398
Score: 0.09019392484037352
Score: 0.14521117135761286
Score: 0.08592572695111256
Score: 0.1057354263317811
Score: 0.10510757671114793
Score: 0.0847104640522121
Score: 0.11074565560405321
Score: 0.1377557658675522
Score: 0.0968247713616929
Score: 0.10884018332440538
Score: 0.10460464551731677
Score: 0.08470675200712825
Score: 0.10674916269116347
Score: 0.10187856729476588
Score: 0.11098513782663466
Score: 0.1006852054535989
Score: 0.08607768243920921
Score: 0.0572960985589689
Score: 0.07277466597097978
Score: 0.09714266660175014
Score: 0.0936011567702686
Score: 0.10107924825808506
Score: 0.10575692967775015
Score: 0.08163955117463126
Score: 0.08028037298007393
Score: 0.12711125933484405
Score: 0.0819227894439605
Score: 0.14450768583476006
Score: 0.07215889884671312
Score: 0.101629033180885
Score: 0.10483220493111559
Score: 0.1039762569254818
Score: 0.09474053675814242
Score: 0.1020761021595241
Score: 0.07693780135209262
Score: 0.09199218232895184
Score: 0.12163219926199287
Score: 0.07375057975836143
Score: 0.07309170083672638
Score: 0.0834607432579968
Score: 0.10811742870450497
Score: 0.10045875019388614
Score: 0.0769210736107839
Score: 0.077865387443125
Score: 0.10883609345344433
Score: 0.16970452263346422
Score: 0.09949983266395131
Score: 0.08443489757361237
Score: 0.11338657764872548
Score: 0.11200592660702802
Score: 0.11959786117913895
Score: 0.08540516065651511
Score: 0.07669483465340808
Score: 0.07411320881946429
Score: 0.09751878303168716
Score: 0.09198066244281149
Score: 0.10910972329089978
Score: 0.08831479173641531
Score: 0.079054791355108
Score: 0.12432529329348078
Score: 0.1270619603151189
Score: 0.3057025310041622
Score: 0.11228580958018358
Score: 0.08405493692481501
Score: 0.125594586365511
Score: 0.15656393247586683
Score: 0.11312739940326955
Score: 0.07018914025608411
Score: 0.11128862080797385
Score: 0.06740314902721141
Score: 0.08149624045668019
Score: 0.07140734960744989
Score: 0.07698063656713862
Score: 0.07252414950447633
Score: 0.10804515728880977
Score: 0.10337048355377222
Score: 0.1218695357505679
Score: 0.1283853455847777
Score: 0.09915622985008732
Score: 0.1088290725825816
Score: 0.11303283977507678
Score: 0.09013838351345058
Score: 0.09471740607559062
Score: 0.06335053405294826
Score: 0.08671585445671104
Score: 0.12410512515955613
Score: 0.07558411544520108
Score: 0.11170086827272047
Score: 0.08653216243206244
Score: 0.1117393010335271
Score: 0.08696015040017728
Score: 0.11638243799810445
Score: 0.07508963833060701
Score: 0.12187832123453964
Score: 0.1554456019687177
Score: 0.10565063907816395
Score: 0.1262738668532271
Score: 0.16766646815835545
Score: 0.13464214363383653
Score: 0.08922768801921184
Score: 0.08336351755469155
Score: 0.12907221085785736
Score: 0.0793587265853305
Score: 0.1534321912304402
Score: 0.12367593656250646
Score: 0.0881441462827583
Score: 0.07717853436634174
Score: 0.09710953795233936
Score: 0.07519404498757808
Score: 0.07120298320552954
Score: 0.08165338482256013
Score: 0.08581142151040067
Score: 0.09486989786039818
Score: 0.06900449019914655
Score: 0.06198815493338248
Score: 0.10912311476517139
Score: 0.08066955038702225
Score: 0.10035754159812527
Score: 0.08874558913194197
Score: 0.10739356735728481
Score: 0.20118095204885214
Score: 0.1140812338940959
Score: 0.125806828654714
Score: 0.07009104457100396
Score: 0.11647620534048332
Score: 0.11023758908614106
Score: 0.08694782263698192
Score: 0.10826675213174464
Score: 0.08996398576378474
Score: 0.08741338110983794
Score: 0.13644338811980813
Score: 0.07369111735882126
Score: 0.09276885607690312
Score: 0.0908212927093117
Score: 0.07089739605448145
Score: 0.08268836976467865
Score: 0.09435521503689312
Score: 0.08843457578010193
Score: 0.0742164916618722
Score: 0.07939722284173194
Score: 0.11339220287953998
Score: 0.10022885613469343
Score: 0.08525799938440069
