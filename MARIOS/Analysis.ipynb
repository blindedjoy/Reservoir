{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram Analysis Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to consider today:\n",
    "\n",
    "It’s publication time. Execute all Marios related tasks.\n",
    "\n",
    "0) get Marios information on the new result.\n",
    "\n",
    "1) Identify the joint prediction paths, automate plot production, upload all these types of plots online\n",
    "\n",
    "2) Print out and read the article\n",
    "\n",
    "3) prepare for meeting with Marios, prepare pure prediction, multiple kinds.\n",
    "\n",
    "4) get ready for 3D loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'PyFiles/imports.py'\n",
    "%run -i 'PyFiles/helpers.py'\n",
    "%run -i \"PyFiles/experiment.py\"\n",
    "%run -i \"PyFiles/analysis.py\"\n",
    "\n",
    "import copy\n",
    "import glob\n",
    "import matplotlib\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "\n",
    "\n",
    "#def blockPrint():\n",
    "#    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore\n",
    "#def enablePrint():\n",
    "#    sys.stdout = sys.__stdout__\n",
    "#sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50187ad3837741c2b43c9a72d769f35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment list, loading data...', max=1.0, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug loc 2: ['./experiment_results/small/split_0.5/block_DLtargetHz_ctr:_1000targetKhz:_0.03__obskHz:_0.05.pickle']\n",
      "\n",
      "debug loc alpha: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f077680354a4aacaff206ff63550bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment list, fixing interpolation...', max=1.0, style…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'freq', 'split': 0.5, 'aspect': 0.9}\n",
      "exact\n",
      "OBS IDX: [49, 51]\n",
      "RESP IDX: [50]\n",
      "Train Region Train/Observers shape: (256, 2)\n",
      "Test Region Train/Observers shape: (256, 2)\n",
      "Train Region Target shape: (256, 1)\n",
      "Test Region Target shape: (256, 1)\n",
      "dict_keys(['delay_line'])\n",
      "DELAY LINE ALREADY TRAINED\n",
      "debug loc 3: ['./experiment_results/small/split_0.5/block_DLtargetHz_ctr:_1000targetKhz:_0.03__obskHz:_0.05.pickle'] prediction\n",
      "debug loc 3: ['./experiment_results/small/split_0.5/block_DLtargetHz_ctr:_1000targetKhz:_0.03__obskHz:_0.05.pickle'] nrmse\n",
      "\n",
      "[]\n",
      "[]\n",
      "total experiments completed: 1\n",
      "total experiments half complete: 0\n",
      "total experiments not yet run: 0\n",
      "Percentage of tests completed: 100.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63f4a2033a84417bfadfd59e6daa80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='processing path list...', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbcfd4089214cceb18da4008a030d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='processing path list...', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dl_pth_lst = [\"./experiment_results/small/split_0.5/block_DLtargetHz_ctr:_1000targetKhz:_0.03__obskHz:_0.05.pickle\"]\n",
    "dl_expers = EchoStateAnalysis(dl_pth_lst, model = \"delay_line\",\n",
    "                              ip_use_observers = True, ip_method = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delay_line': {'cyclic_res_w': 0.001421140206703317,\n",
       "  'cyclic_input_w': 0.5588298351069185,\n",
       "  'cyclic_bias': 0.6018490096941536,\n",
       "  'leaking_rate': 0.8195344650745392,\n",
       "  'n_nodes': 1000,\n",
       "  'random_seed': 123}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_expers.experiment_lst[0][\"nrmse\"]\n",
    "dl_expers.experiment_lst[0].keys()\n",
    "dl_expers.experiment_lst[0][\"best arguments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25ff085b9df48ee951245a9e97adbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='processing path list...', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c30593759d4a3b81dbde2a7a2765aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='processing path list...', max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dl_expers.build_loss_df(group_by = \"freq\", models = [\"delay_line\", \"ip: linear\"], columnwise = False)\n",
    "dl_expers.build_loss_df(group_by = \"time\", models = [\"delay_line\",\"ip: linear\"], columnwise = False)\n",
    "\n",
    "#pickle_A.experiment_lst[0] = pickle_zhizhuo.experiment_lst[0] \n",
    "freq_plot(dl_expers, 0, title = \"Observer 4 experiment: Avg. L2 Loss vs Frequency\", save = \"obs_4_freq\")\n",
    "time_plot(dl_expers, experiment_num = 0, rolling = 150, save = \"obs_4_time\",\n",
    "          title = \"Observer 4 experiment: Avg. L2 Loss vs Time (rolling average)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delay Line: Reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.full((3,3), fill_value = 1)\n",
    "cyclic_weight = 1\n",
    "n_nodes = 10\n",
    "\n",
    "weights = np.zeros((n_nodes, n_nodes), dtype=np.int32) #np.float32)\n",
    "#weights[0, -1] = cyclic_weight <-- This is the only difference between the cyclic reservoir and the delay line.\n",
    "for i in range(n_nodes - 1):\n",
    "    #weights[i + 1, i] = cyclic_weight\n",
    "    weights[i+1, i] = cyclic_weight\n",
    "pd.DataFrame(weights)\n",
    "plt.imshow(weights)\n",
    "plt.xlabel(\"N: Number of Nodes\")\n",
    "plt.ylabel(\"N: Number of Nodes\")\n",
    "plt.title(\"Reservoir Weights\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 100\n",
    "alpha = 50\n",
    "n_nodes = 10\n",
    "n_inputs = 10\n",
    "orig_inputs = np.random.uniform(-1, 1, size = 4)\n",
    "\n",
    "input_bias = np.full((n_nodes,1), fill_value = alpha)\n",
    "\n",
    "input_weights = np.full((1,n_inputs), fill_value = beta)\n",
    "input_weights_zeroes = np.zeros((n_nodes -1, n_inputs))\n",
    "\n",
    "input_weights = np.vstack((input_weights, input_weights_zeroes))\n",
    "input_weights = np.hstack((input_bias, input_weights))\n",
    "plt.imshow(input_weights, aspect = 0.5)\n",
    "plt.xlabel(\"M: number of inputs\")\n",
    "plt.ylabel(\"N: number of Nodes\")\n",
    "plt.title(\"Delay Line Input Weights\")\n",
    "plt.colorbar()\n",
    "inputs = np.hstack((1, orig_inputs))\n",
    "print(inputs)\n",
    "print(alpha + np.sum(orig_inputs)*beta)\n",
    "input_weights @ inputs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_sq(arr):\n",
    "    temp = np.sin(arr)\n",
    "    return(temp**2)\n",
    "sin_sq(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legitimate Delay line. The only output is a single number for the first node of the Rc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 100\n",
    "alpha = 50\n",
    "n_nodes = 10\n",
    "n_inputs = 6\n",
    "input_bias = np.full((1,), fill_value = alpha)\n",
    "input_weights = np.full((n_inputs,), fill_value = beta)\n",
    "\n",
    "input_weights = np.hstack((input_bias, input_weights))\n",
    "input_weights_zeroes = np.zeros((n_nodes-1, n_inputs + 1))\n",
    "\n",
    "input_weights = np.vstack((input_weights, input_weights_zeroes))\n",
    "print(\"Input Weights (bias = 1, beta = 100)\")\n",
    "display(input_weights)\n",
    "plt.imshow(input_weights, aspect = 0.5)\n",
    "plt.xlabel(\"M: number of inputs\")\n",
    "plt.ylabel(\"N: number of Nodes\")\n",
    "plt.title(\"Delay Line Input Weights\")\n",
    "plt.colorbar()\n",
    "orig_inputs = np.random.uniform(-1, 1, size = n_inputs)\n",
    "inputs = np.hstack((1, orig_inputs))\n",
    "print(\"\")\n",
    "print(\"Inputs\")\n",
    "print(inputs)\n",
    "print(alpha + np.sum(orig_inputs)*beta)\n",
    "print(\"\")\n",
    "print(\"Output\")\n",
    "display(input_weights @ inputs.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delay Line input weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls experiment_results/medium/split_0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Prediction 2.0\n",
    "The key to the pure prediction is to break it down. We are going to take in a parameter k, which is the maximum time-series to include in a block prediction. Then we will break the target matrix A into component sections.\n",
    "\n",
    "This will simply require an appropriate series. The next step is to develop an appropriate method for combining the different matrices.\n",
    "\n",
    "There can be two options: overlapping and not overlapping. If there are over-lapping predictions we take a simple average. Otherwise we simply combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls spectrogram_data/medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_med = loadmat('spectrogram_data/medium/Intensity_1024.mat')[\"M\"]\n",
    "plt.imshow(A_med)\n",
    "plt.show()\n",
    "A_med = A_med.T\n",
    "plt.imshow(A_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zhizhuo experiment 1: finding the right indices ; 249, 289\n",
    "lst__ = [i for i in list(range(250 - 1, 289))]\n",
    "assert len(lst__) == 40\n",
    "assert lst__[0] + 1 == 250\n",
    "assert lst__[-1] + 1 == 289\n",
    "print(len(lst__))\n",
    "print(lst__[0] + 1)\n",
    "print(lst__[-1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#250-289 inclusive\n",
    "def get_series(matrixx, k, zhizhuo_endpoints = None, shape_assert = None, plott = False):\n",
    "    matrixx = (matrixx - np.mean(matrixx)) / np.std(matrixx)\n",
    "    start = 0\n",
    "    stop = matrixx.shape[1]\n",
    "    break_points = range(start, stop, k)\n",
    "    break_points = list(break_points)\n",
    "    if zhizhuo_endpoints:\n",
    "        zlb, zub = zhizhuo_endpoints[0], zhizhuo_endpoints[1]\n",
    "    \n",
    "    train_arrays  = []\n",
    "    target_arrays = []\n",
    "    \n",
    "    #### --> test area\n",
    "    if plott:\n",
    "        fig, ax = plt.subplots(1, len(break_points) - 1, figsize = (8, 12))\n",
    "    for i in range(len(break_points) - 1):\n",
    "        lb, ub = break_points[i], break_points[i+1]\n",
    "        if zhizhuo_endpoints:\n",
    "            sub_df = matrixx[ zlb:zub, lb:ub]\n",
    "            sub_df_train = matrixx[ (zlb - 100):zlb, lb:ub]\n",
    "            train_arrays.append(sub_df_train)\n",
    "            target_arrays.append(sub_df)\n",
    "            if plott:\n",
    "                ax[i].imshow(sub_df, aspect = 10)\n",
    "            if shape_assert:\n",
    "                assert( shape_assert == sub_df.shape[0])\n",
    "        else:\n",
    "            ax[i].imshow(matrixx[:,lb:ub], aspect = 1)\n",
    "            target_arrays.append(matrixx[:,lb:ub])\n",
    "    if plott:\n",
    "        plt.show()\n",
    "    print(len(train_arrays))\n",
    "    \n",
    "    dictt = {\"Train\" :[np.ones(arr.shape) for arr in train_arrays] , \n",
    "             \"xTr\" : train_arrays,\n",
    "             \"target\" :  [np.ones(arr.shape) for arr in target_arrays], #np.ones(self.xTr.shape), np.ones(self.xTe.shape)\n",
    "             \"xTe\" : target_arrays }\n",
    "    return dictt\n",
    "broken_up_A_med = get_series(A_med, k = 5, zhizhuo_endpoints = [249, 289], shape_assert = 40)\n",
    "# The question is obvious,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(broken_up_A_med[\"xTr\"][0], aspect = 0.1)\n",
    "plt.show()\n",
    "plt.imshow(broken_up_A_med[\"xTe\"][0], aspect = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = { 'connectivity':    (-5, 0),       # 0.5888436553555889, \n",
    "                'n_nodes':   1000,\n",
    "                'spectral_radius': (0.001, 0.999),\n",
    "                'regularization':  (-3, 4),#(-12, 1),\n",
    "                \"leaking_rate\" :   (0.001, 1) # we want some memory. 0 would mean no memory.\n",
    "                # current_state = self.leaking_rate * update + (1 - self.leaking_rate) * current_state\n",
    "                }\n",
    "esn_cv_spec = EchoStateNetworkCV(bounds = bounds, subsequence_length = 75, esn_feedback = True)\n",
    "assert broken_up_A_med[\"Train\"][0].shape == broken_up_A_med[\"xTr\"][0].shape\n",
    "best_args_ = esn_cv_spec.optimize(y = broken_up_A_med[\"xTr\"][0])\n",
    "#self.best_arguments =  self.esn_cv.optimize(x = self.Train, y = self.xTr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_args_ = {'connectivity': 1.0,\n",
    " 'spectral_radius': 0.5420020711421967,\n",
    " 'regularization': 1.367683798343926,\n",
    " 'leaking_rate': 1.0,\n",
    " 'n_nodes': 1000,\n",
    " 'random_seed': 123,\n",
    " 'feedback': False}\n",
    "esn_spec =  EchoStateNetwork(**best_args_, already_normalized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(broken_up_A_med[\"xTr\"][0].shape)\n",
    "print(np.ones(broken_up_A_med[\"xTr\"][0].shape).shape)\n",
    "broken_up_A_med.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_up_A_med[\"target\"][0].shape\n",
    "type(broken_up_A_med[\"Train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = broken_up_A_med[\"xTe\"][0]\n",
    "esn_spec.train(y = broken_up_A_med[\"xTe\"][0],  x = test_)\n",
    "\n",
    "pred_ = esn_spec.predict( n_steps = test_.shape[0], x = test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmse(test_, pred_)\n",
    "plt.imshow(pred_)\n",
    "plt.show()\n",
    "plt.imshow(test_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enablePrint()\n",
    "pickle_list = glob.glob('experiment_results/publish/*/*.pickle')\n",
    "pickle_list = pickle_list[1:]\n",
    "print(pickle_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check if path list has duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pickle_list) == len(list(np.unique(pickle_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle_A = EchoStateAnalysis(pickle_list, model = \"uniform\", ip_use_observers = True, ip_method = \"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following helper functions are assisting me to accomplish getting the final figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_freq(experiment):\n",
    "    freq_spec_lst = np.array(experiment[\"f\"])[experiment[\"resp_idx\"]]\n",
    "    target_freq_spec = np.round(np.mean(freq_spec_lst),1)\n",
    "    return(target_freq_spec)\n",
    "\n",
    "def IdxMatch(experiment, \n",
    "             resp_idx_range = range(272, 301), \n",
    "             n_obs = 28\n",
    "             ):\n",
    "    \"\"\"\n",
    "    obs3:\n",
    "    obs4: resp_idx_range = range(272, 301) n_obs = 28\n",
    "    obs5:\n",
    "    \"\"\"\n",
    "    #if obs_idx_lst == experiment[\"obs_idx\"]:\n",
    "    #    if resp_idx_lst == experiment[\"resp_idx\"]:\n",
    "    #        return True\n",
    "    resp_idx_list = list(resp_idx_range)\n",
    "    if resp_idx_list == experiment[\"resp_idx\"]:\n",
    "        if n_obs == len(experiment[\"obs_idx\"]):\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def freq_plot(analysis_obj, experiment_num = 0, title = \"Observer 4 experiment\",  save = None):\n",
    "    freq_rDF = analysis_obj.rDF_freq\n",
    "    freq_loss_df =  freq_rDF[freq_rDF[\"experiment #\"] == experiment_num]\n",
    "    \n",
    "    plt.figure(figsize = (12,5))\n",
    "    sns.scatterplot(x = \"freq\", y = \"L2_loss\", data = freq_loss_df, hue = \"model\", alpha = 0.3, legend = None)\n",
    "    sns.lineplot(x = \"freq\", y = \"L2_loss\", data = freq_loss_df, hue = \"model\", alpha = 0.9)\n",
    "    plt.title(title, fontsize = 16)\n",
    "    plt.xlabel(\"Frequency (Hz)\", fontsize = 15)\n",
    "    plt.ylabel(\"L2 Loss\", fontsize = 15)\n",
    "    if save:\n",
    "        plt.savefig(save)\n",
    "\n",
    "def time_plot(analysis_obj, experiment_num = 0, title = \"Observer 4 experiment\", rolling = None, save = None):\n",
    "    time_rDF = analysis_obj.rDF_time\n",
    "    time_loss_df =  time_rDF[time_rDF[\"experiment #\"] == experiment_num]\n",
    "    #display(time_loss_df)\n",
    "    \n",
    "    plt.figure(figsize = (12,5))\n",
    "    \n",
    "    #sns.scatterplot(x = \"time\", y = \"L2_loss\", data = time_loss_df, hue = \"model\", alpha = 0.1)\n",
    "\n",
    "    rollings = {}\n",
    "    if rolling:\n",
    "        mean_ = []\n",
    "        #print( np.unique(time_loss_df.model))\n",
    "        for model in np.unique(time_loss_df.model):\n",
    "            sub_df = time_loss_df[time_loss_df.model == model]\n",
    "            rollings[model]= sub_df.L2_loss.rolling(rolling).mean()\n",
    "        \n",
    "        time_loss_df[\"rolling_L2\"] = -1\n",
    "        for model in np.unique(time_loss_df.model):\n",
    "            time_loss_df.rolling_L2[time_loss_df.model == model] = rollings[model]\n",
    "        sns.lineplot(x = \"time\", y = \"rolling_L2\", data = time_loss_df, hue = \"model\", alpha = 0.9)\n",
    "    else:\n",
    "        sns.lineplot(x = \"time\", y = \"L2_loss\", data = time_loss_df, hue = \"model\", alpha = 0.9)\n",
    "    lb = 0\n",
    "    ub = np.percentile(time_loss_df.L2_loss, 95)\n",
    "    #plt.ylim((lb,ub))\n",
    "    \n",
    "    title = title\n",
    "    plt.title(title, fontsize = 16)\n",
    "    plt.xlabel(\"Time (seconds)\", fontsize = 15)\n",
    "    plt.ylabel(\"L2 Loss\", fontsize = 15)\n",
    "    sns.despine()\n",
    "    if save:\n",
    "        plt.savefig(save)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_freqs = []\n",
    "for i, experiment in enumerate(pickle_A.experiment_lst):\n",
    "    tf = get_target_freq(experiment)\n",
    "    target_freqs.append(tf)\n",
    "    #print(experiment[\"resp_idx\"])\n",
    "    if IdxMatch(experiment):\n",
    "        freq_plot(pickle_A, experiment_num = i)\n",
    "    if IdxMatch(experiment, n_obs = 96):\n",
    "        freq_plot(pickle_A, experiment_num = i)\n",
    "target_freqs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Zhizhuo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_zhizhuo_data(analysis_obj_, experiment_num):\n",
    "    analysis_obj = copy.copy(analysis_obj_)#.copy()\n",
    "    obs4_yhat = loadmat('/Users/hayden/Desktop/ytesthat_ob4.mat')\n",
    "    zhizhuo_rez = obs4_yhat[\"ytesthat_ob4\"]\n",
    "    zhizhuo_rez = zhizhuo_rez.T\n",
    "    zhizhuo_rez = np.flip(zhizhuo_rez, axis = 1)\n",
    "    plt.imshow(zhizhuo_rez, aspect = 0.05)\n",
    "    #0 is zhizhuo_test\n",
    "    for n in [experiment_num]:\n",
    "        #hi = analysis_obj.get_experiment(analysis_obj.experiment_lst[n])\n",
    "        analysis_obj.model = \"uniform\"\n",
    "\n",
    "        exper_unif = analysis_obj.get_experiment(analysis_obj.experiment_lst[n])\n",
    "\n",
    "        unif_nrmse = nrmse(exper_unif.prediction, exper_unif.xTe)\n",
    "        analysis_obj.experiment_lst[n][\"prediction\"][\"uniform\"] = exper_unif.prediction\n",
    "        analysis_obj.experiment_lst[n][\"nrmse\"][\"uniform\"] = unif_nrmse\n",
    "\n",
    "        zhizhuo_nrmse = nrmse(zhizhuo_rez, exper_unif.xTe)\n",
    "        analysis_obj.experiment_lst[n][\"prediction\"][\"zhizhuo\"] = zhizhuo_rez\n",
    "        analysis_obj.experiment_lst[n][\"nrmse\"][\"zhizhuo\"] = zhizhuo_nrmse\n",
    "\n",
    "        #nrmse(exper_unif.prediction, exper_unif.xTe)\n",
    "        analysis_obj.model = \"exponential\"\n",
    "        exper_exp = analysis_obj.get_experiment(analysis_obj.experiment_lst[n])\n",
    "        print(n)\n",
    "        exper_exp.model = \"exponential\"\n",
    "        exp_nrmse = nrmse(exper_exp.prediction, exper_exp.xTe)\n",
    "\n",
    "        analysis_obj.experiment_lst[n][\"prediction\"][\"exponential\"] = exper_exp.prediction\n",
    "        analysis_obj.experiment_lst[n][\"nrmse\"][\"exponential\"] = exp_nrmse\n",
    "        analysis_obj.model = \"uniform\"\n",
    "    print(\"\")\n",
    "    return analysis_obj\n",
    "pickle_zhizhuo = add_zhizhuo_data(pickle_A, 0)\n",
    "pickle_zhizhuo.experiment_lst = [pickle_zhizhuo.experiment_lst[0]]\n",
    "pickle_zhizhuo.build_loss_df(group_by = \"freq\", models = [\"uniform\", \"exponential\", \"zhizhuo\", \"ip: linear\"], columnwise = False)\n",
    "pickle_zhizhuo.build_loss_df(group_by = \"time\", models = [\"uniform\", \"exponential\", \"zhizhuo\", \"ip: linear\"], columnwise = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_zhizhuo.build_loss_df(group_by = \"freq\", models = [\"uniform\", \"exponential\", \"zhizhuo\", \"ip: linear\"], columnwise = False)\n",
    "pickle_zhizhuo.build_loss_df(group_by = \"time\", models = [\"uniform\", \"exponential\", \"zhizhuo\", \"ip: linear\"], columnwise = False)\n",
    "\n",
    "pickle_A.experiment_lst[0] = pickle_zhizhuo.experiment_lst[0] \n",
    "freq_plot(pickle_zhizhuo, 0, title = \"Observer 4 experiment: Avg. L2 Loss vs Frequency\", save = \"obs_4_freq\")\n",
    "time_plot(pickle_zhizhuo, experiment_num = 0, rolling = 150, save = \"obs_4_time\",\n",
    "          title = \"Observer 4 experiment: Avg. L2 Loss vs Time (rolling average)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plots(experiment_num):\n",
    "    print(\"experiment number: \" + str(experiment_num))\n",
    "    experiment = pickle_A.experiment_lst[experiment_num]\n",
    "    print(\"target_freq: \" + str(get_target_freq(experiment)))\n",
    "    print(\"n observers: \" + str(len(experiment[\"obs_idx\"])))\n",
    "    #print(experiment[\"resp_idx\"])\n",
    "    freq_plot(pickle_A, experiment_num = experiment_num, \n",
    "              title = \"low Frequency experiment: \" + \"loss vs freq\")\n",
    "    time_plot(pickle_A, experiment_num = experiment_num, rolling = 150, \n",
    "              title = \"low Frequency experiment: \" + \"time vs freq\")\n",
    "get_plots(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_plot(pickle_A, 1, title = \"Low Frequency experiment: Avg. L2 Loss vs Frequency\", save = \"low_freq_freq\")\n",
    "time_plot(pickle_A, experiment_num = 1, rolling = 150, save = \"low_freq_time\",\n",
    "          title = \"Low Frequency experiment: Avg. L2 Loss vs Time (rolling average)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_idx = pickle_A.experiment_lst[1][\"resp_idx\"]\n",
    "print(resp_idx)\n",
    "f = np.array(pickle_A.experiment_lst[1][\"f\"])\n",
    "f[resp_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_plot(pickle_A, 2, title = \"Rena experiment: Avg. L2 Loss vs Frequency\", save = \"Rena_freq\")\n",
    "time_plot(pickle_A, experiment_num = 2, rolling = 150, save = \"Rena_time\",\n",
    "          title = \"Rena experiment: Avg. L2 Loss vs Time (rolling average)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, len(pickle_A.experiment_lst)):\n",
    "    get_plots(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_A.hyper_parameter_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pickle_A.experiment_lst)):\n",
    "    freq_plot(pickle_A, i)\n",
    "    time_plot(pickle_A, experiment_num = i, rolling = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_A.make_R_barplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_rDF = pickle_A.rDF_time\n",
    "plt.figure(figsize = (16,8))\n",
    "pickle_loss_df_50_50_split =  pickle_rDF[pickle_rDF.split == 0.5]\n",
    "#pickle_loss_df_50_50_split = pickle_loss_df_50_50_split[pickle_loss_df_50_50_split.model != \"exponential\"]\n",
    "\n",
    "mean_ =  pickle_loss_df_50_50_split.R.rolling(50).mean()\n",
    "colors = [\"cyan\", \"red\"]\n",
    "\n",
    "sns.scatterplot(x = \"time\", y = pickle_loss_df_50_50_split[\"L2_loss\"], data = pickle_loss_df_50_50_split, \n",
    "                hue = \"model\", alpha = 0.02)\n",
    "\n",
    "sns.lineplot(x = \"time\", y = mean_, data = pickle_loss_df_50_50_split, \n",
    "             hue = \"model\", alpha = 0.9)\n",
    "plt.title(\"block_N_Targidx_40N_Obsidx_26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickle_rDF = pickle_A.rDF\n",
    "plt.figure(figsize = (16,8))\n",
    "pickle_loss_df_50_50_split =  pickle_rDF[pickle_rDF.split == 0.7]\n",
    "#pickle_loss_df_50_50_split = pickle_loss_df_50_50_split[pickle_loss_df_50_50_split.model != \"exponential\"]\n",
    "\n",
    "mean_ =  pickle_loss_df_50_50_split.R.rolling(50).mean()\n",
    "colors = [\"cyan\", \"red\"]\n",
    "\n",
    "sns.scatterplot(x = \"time\", y = pickle_loss_df_50_50_split[\"R\"], data = pickle_loss_df_50_50_split, \n",
    "                hue = \"model\", alpha = 0.02)\n",
    "\n",
    "sns.lineplot(x = \"time\", y = mean_, data = pickle_loss_df_50_50_split, \n",
    "             hue = \"model\", alpha = 0.9)\n",
    "plt.title(\"block_N_Targidx_40N_Obsidx_26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_rDF = pickle_A.rDF\n",
    "plt.figure(figsize = (16,8))\n",
    "pickle_loss_df_50_50_split =  pickle_rDF[pickle_rDF.split == 0.9]\n",
    "#pickle_loss_df_50_50_split = pickle_loss_df_50_50_split[pickle_loss_df_50_50_split.model != \"exponential\"]\n",
    "\n",
    "mean_ =  pickle_loss_df_50_50_split.R.rolling(50).mean()\n",
    "colors = [\"cyan\", \"red\"]\n",
    "\n",
    "sns.scatterplot(x = \"time\", y = pickle_loss_df_50_50_split[\"R\"], data = pickle_loss_df_50_50_split, \n",
    "                hue = \"model\", alpha = 0.02)\n",
    "\n",
    "sns.lineplot(x = \"time\", y = mean_, data = pickle_loss_df_50_50_split, \n",
    "             hue = \"model\", alpha = 0.9)\n",
    "plt.title(\"block_N_Targidx_40N_Obsidx_26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_pretty_pics(experiment_number = 0, \n",
    "                     modelz = [\"ip: linear\", \"uniform\",  \"exponential\"], #\"zhizhuo\",\n",
    "                    show_images = False, show_residuals = False\n",
    "                    ):\n",
    "    #blockPrint()\n",
    "    if experiment_number == 0:\n",
    "        zhizhuo_label = \"obs4\"\n",
    "    elif experiment_number == 4:\n",
    "        zhizhuo_label = \"obs5\"\n",
    "    else:\n",
    "        zhizhuo_label = \"experiment \" + str(experiment_number)\n",
    "        \n",
    "    if experiment_number == 0:\n",
    "        zhizhuo_label = \"low frequency\"\n",
    "    \n",
    "    spec = pickle_A.experiment_lst[experiment_number]\n",
    "    f =  spec[\"f\"]\n",
    "    freqs_dict = { idx : f[idx] for idx in spec[\"obs_idx\"]}\n",
    "    freqs_ = [f[idx] for idx in spec[\"resp_idx\"]]\n",
    "    \n",
    "    truth = spec[\"xTe\"]\n",
    "    if show_images:\n",
    "        plt.imshow(truth, aspect = 0.01)\n",
    "        plt.title(\"Ground truth\")\n",
    "        plt.show()\n",
    "        fig, ax = plt.subplots(2,2, figsize = (12, 6))\n",
    "        ax = ax.flatten()\n",
    "        for i, model in enumerate(modelz):\n",
    "\n",
    "            ax[i].imshow(spec[\"prediction\"][model], aspect = 0.01)\n",
    "            ax[i].set_title(model)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    nrmses = []\n",
    "    \n",
    "    #for i, model in enumerate(modelz):\n",
    "        \n",
    "    residuals = []\n",
    "    for i, model in enumerate(modelz):\n",
    "        pred_ = spec[\"prediction\"][model]\n",
    "        #if model == \"zhizhuo\":\n",
    "        #    pred_ = np.flip(pred_, axis = 1)\n",
    "        nrmse_spec = nrmse(pred_, truth)\n",
    "        nrmses.append({model : nrmse_spec})\n",
    "        residuals.append(np.abs(truth - pred_))\n",
    "        \n",
    "    if show_residuals:\n",
    "        fig, ax = plt.subplots(2,2, figsize = (12, 6))\n",
    "        ax = ax.flatten()\n",
    "        for i, model in enumerate(modelz):\n",
    "            sns.heatmap(residuals[i], ax = ax[i])\n",
    "            ax[i].set_title(model + \" residuals^2, R: \" + str(round(nrmse_spec, 5)))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    palette_ = dict(zip(modelz, sns.color_palette(\"tab10\")[0:4]))\n",
    "    # = {\"uniform\": \"C0\", \"best interpolation\": \"C1\", \"zhizhuo\": \"C2\", \"expoenential\": \"k\"}\n",
    "    \n",
    "    nrmse_df = pd.DataFrame(nrmses)\n",
    "    nrmse_df = nrmse_df.melt()\n",
    "    nrmse_df.columns = [\"model\", \"R\"]\n",
    "    nrmse_df = nrmse_df.sort_values(by='R', ascending=True)\n",
    "    \n",
    "    modelz_ord = list(nrmse_df.model.values)\n",
    "    \n",
    "    #barplot\n",
    "    #fig, ax = plt.subplots(1,1, figsize = (12, 6.5))\n",
    "    display(nrmse_df)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    barplot = sns.barplot(x = \"model\", y = \"R\", data = nrmse_df, palette = palette_)\n",
    "    #pal.as_hex()\n",
    "    plt.title(\"RMSE for \" + zhizhuo_label)\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.savefig('obs5_R.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "make_pretty_pics(0, show_residuals = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# serious problem: experiments are getting duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pickle_A.experiment_lst:\n",
    "    spec = i[\"resp_idx\"]\n",
    "    \n",
    "    if len(spec) > 1:\n",
    "        exp_resp_lst = (spec)\n",
    "        exp_f = i.keys()\n",
    "        print(exp_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, join as pjoin\n",
    "import scipy.io as sio\n",
    "new_f = sio.loadmat(\"/Users/hayden/Desktop/f_new.mat\")\n",
    "new_f = new_f[\"f\"]\n",
    "\n",
    "freq_imp = [list(new_f[idx])[0] for idx in exp_resp_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_f[exp_resp_lst[-1] +13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_results_df = pickle_A.R_results_df\n",
    "R_results_df_rel = pickle_A.R_results_df_rel\n",
    "R_results_df[\"experiment\"] = [0,1,2] * 2\n",
    "R_results_df_rel = R_results_df_rel[R_results_df_rel[\"model\"] != \"interpolation\"]\n",
    "R_results_df_rel[\"experiment\"] = [0,1,2] * 2\n",
    "display(R_results_df_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = \"model\", y = \"R\", data = R_results_df_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize = (14, 15))\n",
    "ax = ax.flatten()\n",
    "print(ax)\n",
    "\n",
    "for i in range(2):\n",
    "    \n",
    "    R_df_spec = R_results_df[R_results_df.experiment == i]\n",
    "    R_df_rel_spec = R_results_df_rel[R_results_df_rel.experiment == i]\n",
    "    \n",
    "    #sns.barplot(x = \"model\", y = \"R\", data = R_df_spec)#, ax=ax[0])\n",
    "    R_df_spec =R_df_spec.drop(columns = \"experiment\")\n",
    "    R_df_rel_spec =R_df_rel_spec.drop(columns = \"experiment\")\n",
    "    \n",
    "    #sns.violinplot(x = \"model\", y = \"R\", data = self.R_results_df_rel, ax=ax[1])\n",
    "    sns.barplot(x = \"model\", y = \"R\", data = R_df_spec, ci = None, ax=ax[2*i])\n",
    "    \n",
    "    sns.barplot(x = \"model\", y = \"R\", data = R_df_rel_spec, ci = None, ax=ax[2*i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_rDF = pickle_A.rDF\n",
    "plt.figure(figsize = (16,8))\n",
    "pickle_loss_df_50_50_split =  pickle_rDF[pickle_rDF.split == 0.9]\n",
    "#pickle_loss_df_50_50_split = pickle_loss_df_50_50_split[pickle_loss_df_50_50_split.model != \"exponential\"]\n",
    "\n",
    "mean_ =  pickle_loss_df_50_50_split.R.rolling(50).mean()\n",
    "colors = [\"cyan\", \"red\"]\n",
    "\n",
    "sns.scatterplot(x = \"time\", y = pickle_loss_df_50_50_split[\"R\"], data = pickle_loss_df_50_50_split, \n",
    "                hue = \"model\", alpha = 0.02)\n",
    "\n",
    "sns.lineplot(x = \"time\", y = mean_, data = pickle_loss_df_50_50_split, \n",
    "             hue = \"model\", alpha = 0.9)\n",
    "plt.title(\"block_N_Targidx_40N_Obsidx_26\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with asymmetric experiment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'PyFiles/imports.py'\n",
    "%run -i 'PyFiles/helpers.py'\n",
    "%run -i \"PyFiles/experiment.py\"\n",
    "%run -i \"PyFiles/analysis.py\"\n",
    "import scipy.stats as stats\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_path_list = glob.glob('experiment_results/medium/*/*.txt')\n",
    "test_analysis = EchoStateAnalysis([medium_path_list[0]], \n",
    "                                  model = \"uniform\", \n",
    "                                  ip_use_observers = True, \n",
    "                                  ip_method = \"linear\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_obj_test = test_analysis.experiment_lst[0]\n",
    "test_experiment = test_analysis.get_experiment(json_obj_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_obj_test[\"best arguments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_esn = test_experiment.esn_spec\n",
    "test2_esn = EchoStateNetwork(**json_obj_test[\"best arguments\"][\"exponential\"],\n",
    "                             resp_idx = json_obj_test[\"resp_idx\"],\n",
    "                             obs_idx = json_obj_test[\"obs_idx\"],\n",
    "                             exponential = False, plot = True, \n",
    "                             llambda2 = 10**(-2))\n",
    "test2_esn.noise = 0.5\n",
    "test2_esn.get_exp_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = np.array([[16,16,17,18], [15,15,15,15]])\n",
    "np.hstack((hi, np.array([[2],[2]])))\n",
    "# {'llambda': 0.00938595717962852, 'llambda2': 0.002908498759116776, 'connectivity': 1.0, 'spectral_radius': 0.48154601180553436, 'regularization': 0.3676013152573216, 'leaking_rate': 0.7179883186221123, 'noise': 1.2589254117941673, 'n_nodes': 1000, 'random_seed': 123}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_esn.exp_weights.shape\n",
    "test2_esn.obs_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_esn = test_experiment.esn_spec\n",
    "test2_esn = EchoStateNetwork(**json_obj_test[\"best arguments\"][\"exponential\"],\n",
    "                             resp_idx = json_obj_test[\"resp_idx\"],\n",
    "                             obs_idx = json_obj_test[\"obs_idx\"],\n",
    "                             exponential = False, plot = True, dual_lambda = True, \n",
    "                             llambda2 = 0.0001)\n",
    "test2_esn.noise = 0.1\n",
    "test2_esn.get_exp_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_esn = test_experiment.esn_spec\n",
    "test2_esn = EchoStateNetwork(**json_obj_test[\"best arguments\"][\"exponential\"],\n",
    "                             resp_idx = json_obj_test[\"resp_idx\"],\n",
    "                             obs_idx = json_obj_test[\"obs_idx\"],\n",
    "                             exponential = False, plot = True, dual_lambda = True, \n",
    "                             llambda2 = 10)\n",
    "test2_esn.noise = 0.5\n",
    "test2_esn.get_exp_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform(-1, 1, size=(10, 3))\n",
    "np.random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_error = np.random.normal(loc = 0, scale = 0.01, size = (10,3))\n",
    "normal_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_weights1to3 = test2_esn.exp_weights[:3]\n",
    "print(exp_weights1to3 )\n",
    "exp_weights1to3 + normal_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice([-1, 1], (3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining new pickle results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\".pickle\" in 'experiment_results/publish/split_0.5/block_N_Targidx_1N_Obsidx_4.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_A.experiment_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages, glob the path lists from experiment results\n",
    "\n",
    "Why not try something asymmetric? Asymmetric exponential weights? Otherwise we will totally collapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import glob\n",
    "\n",
    "%run -i 'PyFiles/imports.py'\n",
    "%run -i 'PyFiles/helpers.py'\n",
    "%run -i \"PyFiles/experiment.py\"\n",
    "%run -i \"PyFiles/analysis.py\"\n",
    "medium_path_list = glob.glob('experiment_results/medium/*/*.txt')\n",
    "publish_path_list = glob.glob('experiment_results/publish/*/*.txt')\n",
    "publish_path_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## September 18th Task List:\n",
    "\n",
    "\n",
    "0) Continue to clean up analysis notebook\n",
    "1) Work to finish grading\n",
    "2) code asymmetric exponential weights\n",
    "3) Work more on biological kaggle problem\n",
    "4) Work on the paper (Rena parts)\n",
    "\n",
    "## Monday Tasks\n",
    "1) fix figure (Cycles 4 and 5) <br> \n",
    "2) check out the new biological kaggle problem (Cycle 3) <br> \n",
    "3) Select and extract (adjusted) indexes for block tests for Zhizhuo (Cycle 2) <br>\n",
    "4) Do the parts of the paper which Rena requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i \"PyFiles/experiment.py\"\n",
    "publish_sightIp = EchoStateAnalysis(publish_path_list, model = \"uniform\", ip_use_observers = True, ip_method = \"linear\")\n",
    "publish_sightIp.build_loss_df(models = [\"uniform\", \"exponential\", \"ip: linear\"])\n",
    "publish_sightIp.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_sightIp.build_loss_df(models = [\"uniform\", \"exponential\", \"ip: linear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = publish_sightIp.get_experiment(publish_sightIp.experiment_lst[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_f(path = '/Users/hayden/Downloads/f_3000.mat'):\n",
    "    zhiF = loadmat(path)\n",
    "    \n",
    "    \n",
    "    ff = list(zhiF[\"f\"].reshape(-1,))\n",
    "    print(ff[272])\n",
    "#\"/Users/hayden/Desktop/DL_LAB/Reservoir/MARIOS/spectrogram_data/publish/f_new.mat\")\n",
    "get_f()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(publish_sightIp.rDF.model) # you need to expand this to include \"ip: nearest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment session: relative R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rolling_rel_plot(n, rolling = 100, difference = False):\n",
    "    dictLst = []\n",
    "    hi = publish_sightIp.rDF\n",
    "    #display(set(hi.model))\n",
    "    #print(\"hi\")\n",
    "\n",
    "    sub_hi = hi[hi[\"experiment #\"] == n]\n",
    "    sub_hi_unif = sub_hi.R[sub_hi.model == \"uniform\"].values\n",
    "    sub_hi_ip = sub_hi.R[sub_hi.model == \"ip: linear\"].values\n",
    "    #we want to normalize, for the sake of comparison, the r values across the different models.\n",
    "    # divide by the sum of the ip\n",
    "    lenn = len(sub_hi_ip)\n",
    "\n",
    "    denominator = np.sum(sub_hi_ip) / lenn\n",
    "\n",
    "    sub_hi_unif = pd.Series(sub_hi_unif / denominator)\n",
    "    sub_hi_ip   = pd.Series(sub_hi_ip / denominator)\n",
    "    diff = sub_hi_unif - sub_hi_ip \n",
    "\n",
    "    dict_ = {\"uniform\" :  sub_hi_unif, \"ip\" : sub_hi_ip}\n",
    "\n",
    "    dictLst.append(dict_)\n",
    "    rolling_ip = sub_hi_ip.rolling(rolling).mean()\n",
    "    rolling_unif = sub_hi_unif.rolling(rolling).mean()\n",
    "    #print(np.mean(diff))\n",
    "    diff_roll = diff.rolling(rolling).mean()\n",
    "    xx = range(len(rolling_ip))\n",
    "    if difference:\n",
    "        color_ = \"green\" if np.mean(diff)<0 else \"red\"\n",
    "        sns.scatterplot(x = xx, y = diff,  color = color_, alpha = 0.01)\n",
    "        sns.lineplot(x = xx, y = diff_roll,  color = color_, alpha = 0.3)\n",
    "        plt.ylim(-5,5)\n",
    "        plt.title(\"Difference: rel unif - interpolation: > 0 -> rc doing better\")\n",
    "        return((np.mean(diff) < 0), len(diff))\n",
    "    else:\n",
    "        sns.lineplot(x = xx, y = rolling_ip,  color = \"red\", alpha = 0.3) #label = \"interpolation\",\n",
    "        sns.lineplot(x = xx, y = rolling_unif,  color = \"blue\", alpha = 0.3) #label = \"Uniform Random RC\",\n",
    "   \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 5))\n",
    "better_90 = []\n",
    "better_50 = []\n",
    "for i in range(29):\n",
    "    try:\n",
    "        bet = rolling_rel_plot(i, rolling = 150, difference = True)\n",
    "        if bet[1] > 400:\n",
    "            better_50.append(bet[0])\n",
    "        else:\n",
    "            better_90.append(bet[0])\n",
    "    except:\n",
    "        print(i)\n",
    "def quality(better):\n",
    "    return(str(np.sum(better)/len(better)))\n",
    "print(quality(better_50))\n",
    "print(quality(better_90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the nan interpolation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_where_linear_fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#indices_where_linear_fails = []\n",
    "for i, experiment in enumerate(publish_sightIp.experiment_lst): #gets indices of nan interpolation methods.\n",
    "    spec_ip = experiment[\"nrmse\"][\"ip: linear\"]\n",
    "    if math.isnan(spec_ip):\n",
    "        hi = publish_sightIp.get_experiment(experiment)\n",
    "        hi.interpolation_method = \"griddata-nearest\"\n",
    "        hi.runInterpolation()\n",
    "        print(hi.ip_res[\"nrmse\"])\n",
    "        print(i)\n",
    "        #indices_where_linear_fails.append(i)\n",
    "        \n",
    "        publish_sightIp.experiment_lst[i][\"nrmse\"][\"ip: linear\"] = hi.ip_res[\"nrmse\"]\n",
    "        publish_sightIp.experiment_lst[i][\"prediction\"][\"ip: linear\"] = hi.ip_res[\"prediction\"]\n",
    "        #later uncomment these lines. For now I am simply overwriting ip:linear for the loss_df.\n",
    "        #publish_sightIp.experiment_lst[i][\"nrmse\"][\"best interpolation\"] = hi.ip_res[\"nrmse\"]\n",
    "        #publish_sightIp.experiment_lst[i][\"prediction\"][\"best interpolation\"] = hi.ip_res[\"prediction\"]\n",
    "    else:\n",
    "        print(\"\")\n",
    "        #publish_sightIp.experiment_lst[i][\"nrmse\"][\"best interpolation\"] = spec_ip\n",
    "        #publish_sightIp.experiment_lst[i][\"prediction\"][\"best interpolation\"] = experiment[\"prediction\"][\"ip: linear\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in publish_sightIp.experiment_lst[8][\"prediction\"].items():\n",
    "    print(np.array(value).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "for n in range(len(publish_sightIp.experiment_lst)):\n",
    "    if not n:\n",
    "        new, old = [], []\n",
    "    exper_unif = publish_sightIp.get_experiment(publish_sightIp.experiment_lst[n])\n",
    "    \n",
    "    #nrmse(exper_unif.prediction, exper_unif.xTe)\n",
    "    exper_exp = publish_sightIp.get_experiment(publish_sightIp.experiment_lst[n])\n",
    "    print(n)\n",
    "    exper_exp.model = \"exponential\"\n",
    "    new_ = nrmse(exper_exp.prediction, exper_exp.xTe)\n",
    "    publish_sightIp.experiment_lst[n][\"prediction\"][\"exponential\"] = exper_exp.prediction\n",
    "    publish_sightIp.experiment_lst[n][\"nrmse\"][\"exponential\"] = new_\n",
    "    #new.append(new_)\n",
    "    #old.append(old_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmse_lst = []\n",
    "for i, exp_ in enumerate(publish_sightIp.experiment_lst[1:26]):\n",
    "    nrmse_lst.append(exp_[\"nrmse\"])\n",
    "hi = pd.DataFrame(nrmse_lst)\n",
    "hi = hi.drop(columns = [\"ip: linear\", \"exponential\"])\n",
    "hi = hi.melt()\n",
    "\n",
    "hi.columns = [\"model\", \"nrmse\"]\n",
    "sns.violinplot(x = \"model\", y = \"nrmse\" , data = hi)\n",
    "print(np.mean(hi.nrmse[hi.model == \"exponential\"]))\n",
    "print(np.mean(hi.nrmse[hi.model == \"uniform\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_sightIp.experiment_lst = publish_sightIp.experiment_lst[:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_best_args = publish_sightIp.experiment_lst[n][\"best arguments\"][\"exponential\"]\n",
    "\n",
    "#test_esn.get_observers(publish_sightIp.experiment_lst[1][\"get observer inputs\"])\n",
    "test_esn = EchoStateNetwork(**test_best_args, exponential = True)\n",
    "test_esn.train(x = exper_.Train, y = exper_.xTr) #self.Train, y = self.xTr\n",
    "pred_ = test_esn.predict(exper_.xTe.shape[0], exper_.xTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_sightIp.make_R_barplots() #TODO fix compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(publish_sightIp.experiment_lst[i][\"prediction\"][\"ip: linear\"].shape)\n",
    "    #sub_df_nrows = blindIP_loss_df[blindIP_loss_df[\"experiment #\"] == i].shape[0]\n",
    "    #print(sub_df_nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average R across frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle_A.rDF\n",
    "plt.figure(figsize = (16,8))\n",
    "blindIP_loss_df_50_50_split = df[df == 0.5]\n",
    "#blindIP_loss_df_50_50_split = df[df.model != \"exponential\"]\n",
    "\n",
    "mean_ =  blindIP_loss_df_50_50_split.R.rolling(50).mean()\n",
    "colors = [\"cyan\", \"red\"]\n",
    "\n",
    "sns.scatterplot(x = \"time\", y = blindIP_loss_df_50_50_split[\"R\"], data = blindIP_loss_df_50_50_split, \n",
    "                hue = \"model\", alpha = 0.02)\n",
    "\n",
    "sns.lineplot(x = \"time\", y = mean_, data = blindIP_loss_df_50_50_split, \n",
    "             hue = \"model\", alpha = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blindIP_loss_df = publish_sightIp.rDF\n",
    "plt.figure(figsize = (16,8))\n",
    "blindIP_loss_df_50_50_split = publish_sightIp.rDF[publish_sightIp.rDF.split == 0.5]\n",
    "blindIP_loss_df_50_50_split = blindIP_loss_df_50_50_split[blindIP_loss_df_50_50_split.model != \"uniform\"]\n",
    "\n",
    "mean_ =  blindIP_loss_df_50_50_split.R.rolling(50).mean()\n",
    "colors = [\"cyan\", \"red\"]\n",
    "\n",
    "sns.scatterplot(x = \"time\", y = blindIP_loss_df_50_50_split[\"R\"], data = blindIP_loss_df_50_50_split, \n",
    "                hue = \"model\", alpha = 0.02)\n",
    "\n",
    "sns.lineplot(x = \"time\", y = mean_, data = blindIP_loss_df_50_50_split, \n",
    "             hue = \"model\", alpha = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blindIP_loss_df = publish_sightIp.rDF\n",
    "plt.figure(figsize = (16,8))\n",
    "blindIP_loss_df_50_50_split = publish_sightIp.rDF[publish_sightIp.rDF.split == 0.5]\n",
    "blindIP_loss_df_50_50_split = blindIP_loss_df_50_50_split[blindIP_loss_df_50_50_split.model != \"ip: linear\"]\n",
    "\n",
    "mean_ =  blindIP_loss_df_50_50_split.R.rolling(50).mean()\n",
    "colors = [\"cyan\", \"red\"]\n",
    "\n",
    "sns.scatterplot(x = \"time\", y = blindIP_loss_df_50_50_split[\"R\"], data = blindIP_loss_df_50_50_split, \n",
    "                hue = \"model\", alpha = 0.02)\n",
    "\n",
    "sns.lineplot(x = \"time\", y = mean_, data = blindIP_loss_df_50_50_split, \n",
    "             hue = \"model\", alpha = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log R. These plots are bad because they don't care about the average loss per frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "blindIP_loss_df = publish_sightIp.rDF\n",
    "plt.figure(figsize = (16,8))\n",
    "blindIP_loss_df_50_50_split = publish_sightIp.rDF[publish_sightIp.rDF.split == 0.5]\n",
    "blindIP_loss_df_50_50_split = blindIP_loss_df_50_50_split[blindIP_loss_df_50_50_split.model != \"exponential\"]\n",
    "\n",
    "blindIP_loss_df_50_50_split[\"log_R\"] = np.log(blindIP_loss_df_50_50_split.R)\n",
    "\n",
    "mean_ =  blindIP_loss_df_50_50_split.log_R.rolling(50).mean()\n",
    "colors = [\"cyan\", \"red\"]\n",
    "\n",
    "sns.scatterplot(x = \"time\", y = np.log(blindIP_loss_df_50_50_split[\"R\"]), data = blindIP_loss_df_50_50_split, \n",
    "                hue = \"model\", alpha = 0.02)\n",
    "\n",
    "sns.lineplot(x = \"time\", y = mean_, data = blindIP_loss_df_50_50_split, \n",
    "             hue = \"model\", alpha = 0.9)\n",
    "plt.ylim(-10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blindIP_loss_df = publish_sightIp.rDF\n",
    "plt.figure(figsize = (16,8))\n",
    "blindIP_loss_df_50_50_split = publish_sightIp.rDF[publish_sightIp.rDF.split == 0.5]\n",
    "blindIP_loss_df_50_50_split = blindIP_loss_df_50_50_split[blindIP_loss_df_50_50_split.model != \"exponential\"]\n",
    "#blindIP_loss_df_50_50_split[blindIP_loss_df_50_50_split.model != \"exponential\"] = blindIP_loss_df_50_50_split\n",
    "sns.scatterplot(x = \"time\", y = \"R\", data = blindIP_loss_df_50_50_split, hue = \"model\", alpha = 0.02)\n",
    "\n",
    "\n",
    "\n",
    "#mean_ =  blindIP_loss_df_50_50_split.R.rolling(50).mean()\n",
    "#std_ = blindIP_loss_df_50_50_split.R.rolling(50).std()\n",
    "#ub = mean_ - std_\n",
    "#lb = mean_ + std_\n",
    "\n",
    "sns.lineplot(x = \"time\", y = blindIP_loss_df_50_50_split.R.rolling(50).mean(),\n",
    "             data = blindIP_loss_df_50_50_split, hue = \"model\", alpha = 0.9)\n",
    "\n",
    "sns.lineplot(x = \"time\", y = blindIP_loss_df_50_50_split.R.rolling(50).quantile(.95),\n",
    "             data = blindIP_loss_df_50_50_split, hue = \"model\", alpha = 0.4)\n",
    "\n",
    "sns.lineplot(x = \"time\", y = blindIP_loss_df_50_50_split.R.rolling(50).quantile(0.05), data = blindIP_loss_df_50_50_split, hue = \"model\", alpha = 0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_sightIp.kde_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#publish_sightIp.build_loss_df(models = [\"uniform\", \"ip: linear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_sightIp.experiment_lst[1].keys()\n",
    "\n",
    "hi = publish_sightIp.get_experiment(publish_sightIp.experiment_lst[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(15):\n",
    "    \n",
    "    #print(publish_sightIp.experiment_lst[n][\"nrmse\"])\n",
    "    hi = publish_sightIp.experiment_lst[n][\"get_observer_inputs\"][\"split\"]\n",
    "    if hi == 0.5:\n",
    "        nrmse_dict = publish_sightIp.experiment_lst[n][\"nrmse\"]\n",
    "        for key in nrmse_dict.keys():\n",
    "            nrmse_dict[key] = np.round(nrmse_dict[key], 3)\n",
    "        \n",
    "        print(n)\n",
    "        print(nrmse_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kl_div(exper_number, col_wise = False, plot = True, col_wise_method = \"freq\"):\n",
    "    \"\"\" Calculates KL Divergence #https://towardsdatascience.com/kl-divergence-python-example-b87069e4b810\n",
    "    Assuming experiment_lst[0]\n",
    "    \"\"\"\n",
    "    xTe = np.array(publish_sightIp.experiment_lst[exper_number][\"xTe\"])\n",
    "    pred_test = publish_sightIp.experiment_lst[exper_number][\"prediction\"]\n",
    "   \n",
    "    #print(publish_sightIp.experiment_lst[0][\"nrmse\"])\n",
    "    def get_empirical_pdf_data(obj, plot = plot):\n",
    "        obj = obj.flatten()\n",
    "        nparam_density = stats.kde.gaussian_kde(obj)\n",
    "        x = np.linspace(-4, 3, 200)\n",
    "        nparam_density = nparam_density(x)\n",
    "        #ax.plot(x, nparam_density, 'r-', label='non-parametric density (smoothed by Gaussian kernel)')\n",
    "        if plot:\n",
    "            plt.hist(np.array(pred_test[\"uniform\"]).ravel(),  normed=True)\n",
    "            plt.plot(x, nparam_density, 'k--', label='non-parametric density')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        return(nparam_density)\n",
    "\n",
    "    def kl_divergence(p, q):\n",
    "        return np.sum(np.where(p != 0, p * np.log(p / q), 0))\n",
    "    if not col_wise: #col_number is related to frequency.\n",
    "        uniform_rc_epdf = get_empirical_pdf_data(obj = np.array(pred_test[\"uniform\"]))\n",
    "        linear_ip_epdf = get_empirical_pdf_data(obj = pred_test[\"ip: linear\"])\n",
    "        ground_truth_epdf = get_empirical_pdf_data(obj = xTe)\n",
    "        \n",
    "        kl_divergence_dict = {}\n",
    "        for key in pred_test.keys():\n",
    "            epdf_spec = get_empirical_pdf_data(np.array(pred_test[key]))\n",
    "            kl_divergence_dict[key] = kl_divergence(epdf_spec, ground_truth_epdf)\n",
    "        return(kl_divergence_dict)\n",
    "    else:\n",
    "        which_axis = 1 if col_wise_method == \"freq\" else 0\n",
    "        \n",
    "        kl_divergence_dict = {}\n",
    "        for key in pred_test.keys():\n",
    "            kl_divs_spec = []\n",
    "            for i in range(xTe.shape[which_axis]):\n",
    "                if col_wise_method == \"freq\":\n",
    "                    epdf_spec_i = get_empirical_pdf_data(np.array(pred_test[key])[:, i])\n",
    "                    ground_truth_epdf_i = get_empirical_pdf_data(obj = xTe[:, i])\n",
    "                else:\n",
    "                    epdf_spec_i = get_empirical_pdf_data(np.array(pred_test[key])[i, :])\n",
    "                    ground_truth_epdf_i = get_empirical_pdf_data(obj = xTe[i, :])\n",
    "                kl_spec_i = kl_divergence(epdf_spec_i, ground_truth_epdf_i)\n",
    "                kl_divs_spec.append(kl_spec_i)\n",
    "            kl_divergence_dict[key]=kl_divs_spec\n",
    "            \n",
    "        kl_divergence_df = pd.DataFrame(kl_divergence_dict)\n",
    "        kl_divergence_df = kl_divergence_df.drop(columns = 'ip: linear')\n",
    "        \n",
    "        #rolling\n",
    "        if col_wise_method == \"time\":\n",
    "            print(\"rolling\")\n",
    "            for col in list(kl_divergence_df.columns):\n",
    "                print(col)\n",
    "                print(kl_divergence_df[col])\n",
    "                mean_ = kl_divergence_df[col].rolling(5).median()\n",
    "                kl_divergence_df[col] = mean_\n",
    "        \n",
    "        len_df = len(kl_divergence_df)\n",
    "        kl_divergence_df = kl_divergence_df.melt()\n",
    "        kl_divergence_df.columns = [\"model\", \"kl divergence\"]\n",
    "        kl_divergence_df[\"freq_idx\"] = list(range(len_df))*len(kl_divergence_df.model.unique())\n",
    "        sns.lineplot(x = \"freq_idx\", y = \"kl divergence\", data = kl_divergence_df, hue = \"model\")\n",
    "        plt.show()\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    kl_spec = get_kl_div(i, col_wise = True, plot = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broad kl-divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_lst= []\n",
    "for i in trange(25):\n",
    "    kl_spec = get_kl_div(i, plot = False)\n",
    "    print(kl_spec)\n",
    "    kl_div_lst.append(kl_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_pd = pd.DataFrame(kl_div_lst)\n",
    "kl_div_pd = kl_div_pd.drop(columns = [\"best interpolation\", \"zhizhuo\"])\n",
    "kl_div_pd = kl_div_pd.melt()\n",
    "kl_div_pd.columns = [\"model\", \"kl divergence\"]\n",
    "sns.swarmplot(x = \"model\", y = \"kl divergence\", data = kl_div_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hi.f))\n",
    "\n",
    "\n",
    "new_T = np.arange(min(hi.T),max(hi.T), step = 1/2751.5)\n",
    "assert len(new_T) == len(hi.f)\n",
    "T_dict = {\"T\": new_T}\n",
    "savemat(\"new_T.mat\", T_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#sns.barplot(data = pd.DataFrame(exp0[\"nrmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette(\"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = sns.color_palette().as_hex()\n",
    "list(np.array(o)[[2,3,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs4 = publish_sightIp.experiment_lst[0]\n",
    "obs4_dictt = {\"experiment\": obs4}\n",
    "\n",
    "with open('obs4.pickle', 'wb') as handle:\n",
    "    pickle.dump(obs4_dictt, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_pretty_pics(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array(publish_sightIp.experiment_lst[0][\"prediction\"][\"uniform\"])\n",
    "arr1.shape\n",
    "arr2 = np.array(publish_sightIp.experiment_lst[4][\"prediction\"][\"uniform\"])\n",
    "\n",
    "rc1dict = {\"rc_pred\" : arr1,\n",
    "           \"interpolation\" : publish_sightIp.experiment_lst[0][\"prediction\"][\"ip: linear\"],\n",
    "           \"ground_truth\" : np.array(publish_sightIp.experiment_lst[0][\"xTe\"]) }\n",
    "rc2dict = {\"rc_pred\" : arr2,\n",
    "           \"interpolation\" : publish_sightIp.experiment_lst[4][\"prediction\"][\"ip: linear\"],\n",
    "           \"ground_truth\" : np.array(publish_sightIp.experiment_lst[4][\"xTe\"]) }\n",
    "savemat(\"rc1.mat\", rc1dict)\n",
    "savemat(\"rc2.mat\", rc2dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zhizhuo_freqs(nn = 1):\n",
    "    for n in range(nn):\n",
    "    \n",
    "        #print(publish_sightIp.experiment_lst[n][\"nrmse\"])\n",
    "        split_ = publish_sightIp.experiment_lst[n][\"get_observer_inputs\"][\"split\"]\n",
    "        if split_ == 0.5:\n",
    "            nrmse_dict = publish_sightIp.experiment_lst[n][\"nrmse\"]\n",
    "            for key in nrmse_dict.keys():\n",
    "                nrmse_dict[key] = np.round(nrmse_dict[key], 3)\n",
    "\n",
    "            print(n)\n",
    "            print(nrmse_dict)\n",
    "\n",
    "\n",
    "            resp_idx_spec = publish_sightIp.experiment_lst[n][\"resp_idx\"]\n",
    "            xTe = publish_sightIp.experiment_lst[n][\"xTe\"]\n",
    "            missing_frequencies = [np.round(hi.f[idx],1) for idx in resp_idx_spec]\n",
    "            print(missing_frequencies[0])\n",
    "            print(missing_frequencies[-1])\n",
    "\n",
    "            matlab_resp_idxs = [idx + 1 for idx in resp_idx_spec]\n",
    "            \n",
    "            print(\"response indices: \" + str(matlab_resp_idxs[0]) + \" \" + str(matlab_resp_idxs[-1]))\n",
    "            print(\"number of f missing lines: \" + str(len(matlab_resp_idxs)))\n",
    "\n",
    "            print(\"T's: (\" + str(hi.xTe.shape[0]) + \", \" + str(hi.A.shape[0]) + \")\")\n",
    "\n",
    "            obs_idx_spec = publish_sightIp.experiment_lst[n][\"obs_idx\"] \n",
    "            matlab_obs_idxs = [idx + 1 for idx in obs_idx_spec]\n",
    "            print(\"total observers: \" + str(len(matlab_obs_idxs)))\n",
    "    \n",
    "    #return(matlab_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_zhizhuo_freqs()\n",
    "get_zhizhuo_freqs(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array(publish_sightIp.experiment_lst[0][\"prediction\"][\"uniform\"])\n",
    "arr1.shape\n",
    "arr2 = np.array(publish_sightIp.experiment_lst[13][\"prediction\"][\"uniform\"])\n",
    "arr2.shape\n",
    "publish_sightIp.experiment_lst[13][\"nrmse\"]\n",
    "\n",
    "rc1dict = {\"rc_pred\" : arr1,\n",
    "           \"interpolation\" : publish_sightIp.experiment_lst[0][\"prediction\"][\"ip: linear\"],\n",
    "           \"ground_truth\" : np.array(publish_sightIp.experiment_lst[0][\"xTe\"]) }\n",
    "rc2dict = {\"rc_pred\" : arr2,\n",
    "           \"interpolation\" : publish_sightIp.experiment_lst[13][\"prediction\"][\"ip: linear\"],\n",
    "           \"ground_truth\" : np.array(publish_sightIp.experiment_lst[13][\"xTe\"]) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "arr1 = np.array(publish_sightIp.experiment_lst[0][\"prediction\"][\"uniform\"])\n",
    "arr1.shape\n",
    "arr2 = np.array(publish_sightIp.experiment_lst[13][\"prediction\"][\"uniform\"])\n",
    "arr2.shape\n",
    "publish_sightIp.experiment_lst[13][\"nrmse\"]\n",
    "\n",
    "rc1dict = {\"rc_pred\" : arr1,\n",
    "           \"interpolation\" : publish_sightIp.experiment_lst[0][\"prediction\"][\"ip: linear\"],\n",
    "           \"ground_truth\" : np.array(publish_sightIp.experiment_lst[0][\"xTe\"]) }\n",
    "rc2dict = {\"rc_pred\" : arr2,\n",
    "           \"interpolation\" : publish_sightIp.experiment_lst[13][\"prediction\"][\"ip: linear\"],\n",
    "           \"ground_truth\" : np.array(publish_sightIp.experiment_lst[13][\"xTe\"]) }\n",
    "savemat(\"rc1.mat\", rc1dict)\n",
    "savemat(\"rc2.mat\", rc2dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(publish_sightIp.experiment_lst[0][\"xTe\"]), aspect = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_sightIp.hyper_parameter_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#publish_sightIp.loss_plot(split = 0.5, rolling = 40)\n",
    "\n",
    "sns.lineplot(x = \"time\", y = blindIP_loss_df_50_50_split.R.rolling(50).mean(),\n",
    "             data = blindIP_loss_df_50_50_split, hue = \"model\", alpha = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blindIP_loss_df = publish_sightIp.rDF\n",
    "plt.figure(figsize = (16,8))\n",
    "blindIP_loss_df_90_10_split = publish_sightIp.rDF[publish_sightIp.rDF.split == 0.9]\n",
    "#blindIP_loss_df_50_50_split[blindIP_loss_df_50_50_split.model != \"exponential\"] = blindIP_loss_df_50_50_split\n",
    "sns.scatterplot(x = \"time\", y = \"R\", data = blindIP_loss_df_90_10_split, hue = \"model\", alpha = 0.02)\n",
    "\n",
    "sns.lineplot(x = \"time\", y = blindIP_loss_df_90_10_split.R.rolling(50).mean(),\n",
    "             data = blindIP_loss_df_90_10_split, hue = \"model\", alpha = 0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium\n",
    "#### Blind Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_blindIp = EchoStateAnalysis(medium_path_list, ip_use_observers = False)\n",
    "#medium_blindIp.make_R_barplots() \n",
    "medium_blindIp.build_loss_df()\n",
    "medium_blindIp.loss_plot(rolling = 7, split = 0.5)\n",
    "medium_blindIp.loss_plot(rolling = 7, split = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_blindIp.hyper_parameter_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "medium_sightIp = EchoStateAnalysis(medium_path_list, ip_use_observers = True)\n",
    "medium_sightIp.build_loss_df(models = [\"uniform\", \"exponential\", \"ip: linear\"])\n",
    "medium_sightIp.loss_plot(rolling = 7, split = 0.5)\n",
    "medium_sightIp.loss_plot(rolling = 7, split = 0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publish Size Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_blindIp = EchoStateAnalysis(publish_path_list, ip_use_observers = False)\n",
    "publish_blindIp.hyper_parameter_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_blindIp.make_R_barplots() \n",
    "publish_blindIp.build_loss_df()\n",
    "publish_blindIp.loss_plot(rolling = 7, split = 0.5, loss = \"R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_blindIp.loss_plot(rolling = 7, split = 0.9, loss = \"R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### publish sight ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_sightIp.loss_plot(rolling = 7, split = 0.9, loss = \"R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i \"PyFiles/analysis.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_sightIp.df.info() #is there  something I'm not seeing? What will I have to present tomorrow? What can I deliver?\n",
    "np.unique(publish_sightIp.df[\"target hz\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zhizhuo results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'PyFiles/imports.py'\n",
    "%run -i 'PyFiles/helpers.py'\n",
    "%run -i \"PyFiles/experiment.py\"\n",
    "%run -i \"PyFiles/analysis.py\"\n",
    "files2import = glob.glob('/Users/hayden/Desktop/zhizhuo_block_results/*.mat')\n",
    "files2import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lst = []\n",
    "for i in files2import:\n",
    "    data_lst.append(loadmat(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real51, y_hat101, y_real101, y_hat51 = data_lst\n",
    "truth_51 = y_real51[list(y_real51.keys())[3]]\n",
    "pred_51  = y_hat51[list(y_hat51.keys())[3]]\n",
    "print(nrmse(pred_51, truth_51))\n",
    "plt.imshow(truth_51, aspect = 4)\n",
    "plt.show()\n",
    "plt.imshow(pred_51, aspect = 4)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_freqs_51 = list(range(1740, 2240 + 10, 10)) \n",
    "obs_freqs51a = list(range(1740  - (26*10), 1740, 10))\n",
    "obs_freqs51b = list(range(2240 + 10, 2240 + (26*10) + 10, 10))\n",
    "assert targ_freqs_51[-1] + 10 == obs_freqs51b[0]\n",
    "assert targ_freqs_51[0] - 10 == obs_freqs51a[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "truth_101 = y_real101[list(y_real101.keys())[3]]\n",
    "pred_101  = y_hat101[list(y_hat101.keys())[3]]\n",
    "print(nrmse(pred_101, truth_101))\n",
    "plt.imshow(truth_101, aspect = 4)\n",
    "plt.show()\n",
    "plt.imshow(pred_101, aspect = 4)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "zhizhuo51 = EchoStateExperiment(\"medium\", obs_freqs = obs_freqs51a + obs_freqs51b, target_freqs = targ_freqs_51 )\n",
    "zhizhuo51.f[zhizhuo51.resp_idx[0]]\n",
    "#print(zhizhuo51.A.shape)\n",
    "#for i in zhizhuo51.A.shape[1]\n",
    "hi = \"\"\"\n",
    "for i in range(0,1000):\n",
    "    his = truth_51.T[0:]\n",
    "    mine = zhizhuo51.A[:, i ] #511:\n",
    "    assert his.shape == mine.shape, str(his.shape) + str(mine.shape)\n",
    "    if np.array_equal(his,mine):\n",
    "        print(i)\n",
    "\"\"\"\n",
    "\n",
    "def retrieve_zhizhuo_series(series_idx):\n",
    "    mine = zhizhuo51.A[ 511:, 153 ]\n",
    "    his = truth_51[series_idx,:]\n",
    "    nrmse_lst = []\n",
    "    for i in range(0, 1000):\n",
    "        mine = zhizhuo51.A.T[ i , 511: ]\n",
    "        nrmse_spec = nrmse(his,mine)\n",
    "\n",
    "        nrmse_lst.append(nrmse_spec)\n",
    "    nrmse_series = pd.Series(nrmse_lst)\n",
    "    candidate_idx = nrmse_series.idxmin()\n",
    "    candidate = zhizhuo51.A.T[candidate_idx , 511: ]\n",
    "    plt.plot(candidate, \"--\", linewidth = 5, alpha = 0.6, label = \"actual data\") \n",
    "    plt.plot(his, \":r\", label = \"zhizhuo testset\", linewidth = 3, alpha = 0.5)\n",
    "    titl = str(candidate_idx) + \" idx: \" +  str(zhizhuo51.f[candidate_idx]) + \" Hz\"\n",
    "    plt.title(titl)\n",
    "    plt.legend()\n",
    "    print(truth_51.shape)\n",
    "retrieve_zhizhuo_series(0)\n",
    "plt.show()\n",
    "retrieve_zhizhuo_series(-1)\n",
    "plt.show()\n",
    "plt.plot(zhizhuo51.A[511:, 249])\n",
    "\n",
    "#plt.plot(zhizhuo51.A[174, :])\n",
    "#zhizhuo51.get_observers(split = 0.4995, method = \"exact\", plot_split = True)\n",
    "#zhizhuo51.runInterpolation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert zhizhuo51.xTe.T.shape == truth_51.shape, str(zhizhuo51.xTe.T.shape) + \" != \" + str(truth_51.shape)\n",
    "sns.heatmap(truth_51)\n",
    "plt.show()\n",
    "sns.heatmap(zhizhuo51.xTe.T)\n",
    "plt.show() \n",
    "plt.imshow(pred_51, aspect = 4)\n",
    "plt.show() \n",
    "\n",
    "plt.imshow(zhizhuo51.ip_res[\"prediction\"].T, aspect = 4)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(zhizhuo51.xTe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Zhizhuo block results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Step 2: store hyper-parameter-results: Let's get some nice hyper-parameter plots.\n",
    "#TODO: Step 1: check if observers are correct:\n",
    "#TODO: fix\n",
    "\n",
    "\n",
    "def check_shape_obs(file = \"default\"):\n",
    "    \"\"\"\n",
    "    Check the shape\n",
    "    \"\"\"\n",
    "    if file == \"default\":\n",
    "        nf = get_new_filename(exp = exp, current = True)\n",
    "    else:\n",
    "        nf = file\n",
    "    with open(nf) as json_file: # 'non_exp_w.txt'\n",
    "        datt = json.load(json_file)\n",
    "    #datt = non_exp_best_args[\"dat\"]\n",
    "    #datt[\"obs_tr\"], datt[\"obs_te\"]   = np.array(datt[\"obs_tr\"]), np.array(datt[\"obs_te\"])\n",
    "    #datt[\"resp_tr\"], datt[\"resp_te\"] = np.array(datt[\"resp_tr\"]), np.array(datt[\"resp_te\"])\n",
    "    return(datt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#experiment.save_json(exp = False)\n",
    "#fp = bp + 'targetKhz:_0.01__obskHz:_0.01.txt'\n",
    "#fp = bp + 'targetKhz:_0.02__obskHz:_0.01.txt'\n",
    "def topline(spec_path, \n",
    "            base_path = \"/Users/hayden/Desktop/experiment_results/2k/medium/\",\n",
    "            #base_path = #\"./experiment_results/...\"\n",
    "            verbose = False,\n",
    "            print_filestructure = False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    print(base_path)\n",
    "    fp = base_path + spec_path\n",
    "    \n",
    "    hi = load_data(file = fp)\n",
    "    if print_filestructure == True:\n",
    "        for i in hi.keys():\n",
    "            print(i + \"/\")\n",
    "\n",
    "            if type(hi[i]) == dict:\n",
    "\n",
    "                for j in hi[i].keys():\n",
    "                    print(\"    \" + j)\n",
    "                    \n",
    "    if verbose == True:\n",
    "        print(\"DATA STRUCTURE: (it's a dict)\")\n",
    "        print(\"/n inputs:\")\n",
    "        print(hi[\"experiment_inputs\"])\n",
    "        print(hi[\"get_observer_inputs\"])\n",
    "\n",
    "        print(\"/n key saved values:\")\n",
    "        print(hi[\"best arguments\"])\n",
    "        print(hi[\"nrmse\"])\n",
    "    return(hi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifdel(dictt, key):\n",
    "    \"\"\" If a key is in a dictionary delete it. Return [modified] dictionary.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        del dictt[key]\n",
    "        return(dictt)\n",
    "    except:\n",
    "        return(dictt)\n",
    "ifdel({\"a\":1, \"b\" : 2}, \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_lst = []\n",
    "for exper in experiment_lst:\n",
    "    print()\n",
    "    pd_lst.append(exper[\"nrmse\"]) #, index = [0]))\n",
    "hi = pd.melt(pd.DataFrame(pd_lst))\n",
    "hi.columns = [\"model\" ,\"nrmse\"]\n",
    "hi = hi.iloc[:11,:]\n",
    "sns.catplot(x = \"model\", y = \"nrmse\", data = hi, kind = \"bar\")\n",
    "plt.title(\"R for block prediction: large dataset\")\n",
    "plt.ylabel(\"R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path_lst_unq = check_for_duplicates(path_lst, verbose = False)\n",
    "dict_lst_unq = check_for_duplicates(dict_lst, verbose = False)\n",
    "\n",
    "complete_experiment_path_lst = path_lst_unq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete_experiment_path_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(check_for_duplicates(complete_experiment_path_lst) != True), \"duplicates found\"\n",
    "%run -i '../MARIOS/PyFiles/imports.py'\n",
    "%run -i '../MARIOS/PyFiles/helpers.py'\n",
    "%run -i \"../MARIOS/PyFiles/experiment.py\"\n",
    "bp_ = \"\"# \"./experiment_results/\"\n",
    "\n",
    "\n",
    "\n",
    "# fix nrmse calculation AND interpolation\n",
    "for i in trange(len(experiment_lst), desc='experiment list, fixing interpolation...'): \n",
    "    exper_ = experiment_lst[i]\n",
    "    exper_obj = get_experiment(exper_)\n",
    "    \n",
    "    train_set, test_set = exper_obj.xTr, exper_obj.xTe\n",
    "    models_spec = list(exper_[\"prediction\"].keys())\n",
    "    \n",
    "    for model_ in models_spec:\n",
    "        pred_ = exper_[\"prediction\"][model_]\n",
    "        corrected_nrmse = nrmse(pred_, test_set)\n",
    "        exper_[\"nrmse\"][model_] = corrected_nrmse\n",
    "        \n",
    "    experiment_lst[i] = fix_interpolation(exper_, method = \"linear\") \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_combination(ip, exp, Test, n = 10, optimize = True):\n",
    "    \n",
    "    if optimize == True:\n",
    "        nrmses = []\n",
    "        predictions = []\n",
    "        #(np.array(Test) + np.array(predictions[\"exponential\"])) / 2\n",
    "        vals =[]\n",
    "        for i in range(n):\n",
    "            a = i / n\n",
    "            b = 1 - a\n",
    "            hybrid_pred = ((1-a) * ip + a * exp)\n",
    "            predictions += [hybrid_pred]\n",
    "            nrmses += [nrmse(hybrid_pred , Test) ]\n",
    "            vals += [a]\n",
    "            #nrmse(predictions[\"hybrid\"], Test) \n",
    "        idx = np.argmin(nrmses) \n",
    "        print(nrmses)\n",
    "        print(\"A!! \" + str(vals[idx]))\n",
    "        best_prediction = predictions[idx]\n",
    "        best_nrmse      = nrmses[idx]\n",
    "        return(best_prediction, best_nrmse)\n",
    "    else:\n",
    "        hybrid_pred  = (0.5 * ip) + (0.5 * exp)\n",
    "        hybrid_nrmse = nrmse(hybrid_pred , Test)\n",
    "        return(hybrid_pred, hybrid_nrmse)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add hybrids\n",
    "for i in list(range(len(experiment_lst))):\n",
    "    experiment_lst[i]\n",
    "    predictions_= experiment_lst[i][\"prediction\"]\n",
    "    Train, Test = recover_test_set(experiment_lst[i])\n",
    "    #hybrid_pred_, hybrid_R = optimize_combination(np.array(predictions_[\"interpolation\"]),\n",
    "    #                                                                  np.array(predictions_[\"exponential\"]),\n",
    "    #                                                                  Test, optimize = False)\n",
    "    experiment_lst[i][\"nrmse\"][\"hybrid\"]      = hybrid_R\n",
    "    experiment_lst[i][\"prediction\"][\"hybrid\"] = hybrid_pred_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_lst[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_df():\n",
    "    IGNORE_IP = False\n",
    "\n",
    "    def quick_dirty_convert(lst):\n",
    "        if IGNORE_IP == True:\n",
    "            lst *= 2\n",
    "        else:\n",
    "            lst *= 4\n",
    "        pd_ = pd.DataFrame(np.array(lst).reshape(-1,1))\n",
    "        return(pd_)\n",
    "\n",
    "\n",
    "    idx_lst = list(range(len(experiment_lst)))\n",
    "    #idx_lst *= 3\n",
    "    #idx_lst = pd.DataFrame(np.array(idx_lst).reshape(-1,1))\n",
    "\n",
    "    idx_lst = quick_dirty_convert(idx_lst)\n",
    "\n",
    "    obs_hz_lst, targ_hz_lst, targ_freq_lst = [], [], []\n",
    "\n",
    "    for i, experiment in enumerate(experiment_lst):\n",
    "        #print(experiment['experiment_inputs'].keys())\n",
    "        targ_hz = experiment[\"experiment_inputs\"][\"target_hz\"]\n",
    "        obs_hz  = experiment[\"experiment_inputs\"][\"obs_hz\"]\n",
    "        targ_freq = experiment[\"experiment_inputs\"]['target_frequency']\n",
    "\n",
    "        if experiment[\"experiment_inputs\"][\"target_hz\"] < 1:\n",
    "            targ_hz *= 1000*1000\n",
    "            obs_hz  *= 1000*1000\n",
    "        obs_hz_lst  += [obs_hz]\n",
    "        targ_hz_lst += [targ_hz]\n",
    "        targ_freq_lst += [targ_freq]\n",
    "\n",
    "\n",
    "        hz_line = {\"target hz\" : targ_hz }\n",
    "        hz_line = Merge(hz_line , {\"obs hz\" : obs_hz })\n",
    "\n",
    "        #print(hz_line)\n",
    "        df_spec= experiment[\"nrmse\"]\n",
    "\n",
    "        #df_spec = Merge(experiment[\"nrmse\"], {\"target hz\": targ_hz})\n",
    "        df_spec = pd.DataFrame(df_spec, index = [0])\n",
    "\n",
    "        df_spec_rel = df_spec.copy()\n",
    "        #/df_spec_diff[\"uniform\"]\n",
    "        #df_spec_diff[\"rc_diff\"]\n",
    "\n",
    "        if IGNORE_IP == True:\n",
    "            df_spec_rel = df_spec_rel / experiment[\"nrmse\"][\"uniform\"]#\n",
    "        else:\n",
    "            df_spec_rel = df_spec_rel / experiment[\"nrmse\"][\"interpolation\"]\n",
    "\n",
    "\n",
    "\n",
    "        #print( df_spec_rel)\n",
    "        #print(experiment[\"experiment_inputs\"].keys())\n",
    "        if i == 0:\n",
    "            df      = df_spec\n",
    "            df_rel  = df_spec_rel\n",
    "\n",
    "\n",
    "        else:\n",
    "            df = pd.concat([df, df_spec])\n",
    "            df_rel = pd.concat([df_rel, df_spec_rel])\n",
    "\n",
    "\n",
    "    df_net = df_rel.copy()\n",
    "\n",
    "    obs_hz_lst, targ_hz_lst = quick_dirty_convert(obs_hz_lst), quick_dirty_convert(targ_hz_lst)\n",
    "    targ_freq_lst = quick_dirty_convert(targ_freq_lst)\n",
    "    #display(df)\n",
    "    if IGNORE_IP == True:\n",
    "        df_rel = df_rel.drop(columns = [\"interpolation\"])\n",
    "        df  = df.drop(columns = [\"interpolation\"])\n",
    "    #df_rel  = df_rel.drop(columns = [\"hybrid\"])\n",
    "    #df      = df.drop(    columns = [\"hybrid\"])\n",
    "\n",
    "    df, df_rel = pd.melt(df), pd.melt(df_rel)\n",
    "    df  = pd.concat( [idx_lst, df,  obs_hz_lst, targ_hz_lst, targ_freq_lst] ,axis = 1)\n",
    "\n",
    "    df_rel = pd.concat( [idx_lst, df_rel,  obs_hz_lst, targ_hz_lst, targ_freq_lst], axis = 1)\n",
    "\n",
    "    #df_diff = pd.concat( [idx_lst, df_diff,  obs_hz_lst, targ_hz_lst, targ_freq_lst], axis = 1)\n",
    "\n",
    "    col_names = [\"experiment\", \"model\", \"nrmse\", \"obs hz\", \"target hz\", \"target freq\" ]\n",
    "    df.columns, df_rel.columns    = col_names, col_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df_diff = df[df[\"model\"] == \"uniform\"]\n",
    "df_diff.model = \"diff\"\n",
    "nrmse_ = (df[df[\"model\"] == \"exponential\"][\"nrmse\"].values - df_diff[\"nrmse\"].values) * 100\n",
    "df_diff.nrmse = nrmse_\n",
    "def plot_loss_reduction():\n",
    "\n",
    "    df_diff = df[df[\"model\"] == \"uniform\"]\n",
    "    df_diff.model = \"diff\"\n",
    "    #df_diff[\"nrmse\"] = df_diff[\"nrmse\"] - df[df[\"model\"] == \"exponential\"][\"nrmse\"]\n",
    "\n",
    "    \n",
    "    \n",
    "    #df[df[\"model\"] == \"exponential\"] \n",
    "\n",
    "    nrmse_ = (df[df[\"model\"] == \"exponential\"][\"nrmse\"].values - df_diff[\"nrmse\"].values) * 100\n",
    "    df_diff.nrmse = nrmse_\n",
    "    pct = round(np.mean(nrmse_ < 0) * 100,2)\n",
    "    print(\"odds of loss reduction with exponential weights vs uniform weights: \" + str(pct) + \"%\")\n",
    "    print(\"mean % loss change: \" + str(round(np.mean(nrmse_))) + \"%\")\n",
    "\n",
    "    #sns.catplot(x = \"model\", y = \"nrmse\", data = df_diff)\n",
    "    fig, ax = plt.subplots(1,1,figsize = (10, 6))\n",
    "    plt.xlabel(\"%change in loss\")\n",
    "    plt.ylabel(\"density\")\n",
    "    sns.kdeplot(df_diff[\"nrmse\"], shade = True)\n",
    "    plt.axvline(x=0, color = \"black\", label = \"zero\")\n",
    "    plt.axvline(x=np.mean(df_diff[\"nrmse\"]), color = \"red\", label = \"mean loss reduction\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_loss_reduction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_reduction2d(xx = \"target hz\"):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (6,6))\n",
    "    sns.kdeplot(df_diff[xx], df_diff[\"nrmse\"],\n",
    "                     cmap=\"Blues\", shade=True, shade_lowest=False, ax = ax)#, alpha = 0.5)\n",
    "    #plt.ayvline(y=0, color = \"black\", label = \"zero\")\n",
    "    sns.scatterplot(x = xx, y = \"nrmse\", data = df_diff, ax = ax,  linewidth=0, color = \"black\", alpha = 0.4)\n",
    "    plt.title(\"2d kde plot: nrmse vs target hz\")\n",
    "    plt.axhline(y=0.5, color='black', linestyle='-')\n",
    "    ax.set_ylabel(\"pct loss exp vs unif RC\")\n",
    "plot_loss_reduction2d()\n",
    "plot_loss_reduction2d(xx = \"obs hz\")\n",
    "plot_loss_reduction2d(xx = \"target freq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(experiment_lst[0][\"prediction\"][\"uniform\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_lst[0][\"nrmse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in experiment_lst:\n",
    "    print(i.keys())\n",
    "    print(i[\"best arguments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args= {\"relative\": False,\n",
    "       \"columnwise\" : True,\n",
    "       \"rolling\" : 9,\n",
    "        \"models\" : [\"uniform\", \"exponential\", \"ip: linear\"]#, \"hybrid\"]\n",
    "}\n",
    "Loss_df = build_loss_df(**args)\n",
    "#L2_loss_df = loss_df(**args, loss_ = \"L2\")\n",
    "#L1_loss_df = loss_df(relative = False, columnwise = False, rolling = 10, loss_ = \"L1\", models = [\"uniform\", \"exponential\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_plot(Loss_df, rolling = 1, split = 0.9, loss = \"R\", include_ip = True)\n",
    "loss_plot(Loss_df, rolling = 30, split = 0.5, loss = \"R\", include_ip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_plot(Loss_df, rolling = 1, split = 0.5, loss = \"R\", include_ip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nrmse_kde_2d(xx = \"target hz\", \n",
    "                      log = True, \n",
    "                      alph = 1, \n",
    "                      black_pnts = True, \n",
    "                      models = {\"interpolation\" : \"Greens\", \"exponential\" : \"Reds\", \"uniform\" : \"Blues\"},\n",
    "                      enforce_bounds = False,\n",
    "                      target_freq = None):\n",
    "    \"\"\"\n",
    "    #todo description\n",
    "    \"\"\"\n",
    "    if target_freq != None:\n",
    "        df_spec = df[df[\"target freq\"] == target_freq]\n",
    "    else:\n",
    "        df_spec = df.copy()\n",
    "            \n",
    "    \n",
    "    def plot_(model_, colorr, alph = alph,  black_pnts =  black_pnts):\n",
    "        if colorr == \"Blues\":\n",
    "            color_ = \"blue\"\n",
    "        elif colorr == \"Reds\":\n",
    "            color_ = \"red\"\n",
    "        elif colorr == \"Greens\":\n",
    "            color_ = \"green\"\n",
    "            \n",
    "        df_ = df_spec[df_spec.model == model_] #df_ip  = df[df.model == \"interpolation\"]\n",
    "        \n",
    "        #display(df_)\n",
    "            \n",
    "        \n",
    "        hi = df_[\"nrmse\"]\n",
    "        cap = 1\n",
    "        if log == True:\n",
    "            hi = np.log(hi)/ np.log(10)\n",
    "            cap = np.log(cap) / np.log(10)\n",
    "        \n",
    "        \n",
    "        sns.kdeplot(df_[xx], hi, cmap= colorr, \n",
    "                    shade=True, shade_lowest=False, ax = ax, label = model_, alpha = alph)#, alpha = 0.5)\n",
    "        \n",
    "        if  black_pnts == True:\n",
    "            col_scatter = \"black\"\n",
    "        else:\n",
    "            col_scatter = color_\n",
    "        \n",
    "        sns.scatterplot(x = xx, y = hi, data = df_,  linewidth=0, \n",
    "                        color = col_scatter, alpha = 0.4, ax = ax)\n",
    "        \n",
    "        plt.title(\"2d kde plot: nrmse vs \" + xx)\n",
    "        \n",
    "        plt.axhline(y=cap, color=color_, linestyle='-', label = \"mean \" + str(model_), alpha = 0.5)\n",
    "        sns.lineplot(y = hi, x = xx, data = df_ , color = color_)#, alpha = 0.2)\n",
    "        if enforce_bounds == True:\n",
    "            ax.set_ylim(0,1)\n",
    "        if log == True:\n",
    "            ax.set_ylabel(\"log( NRMSE) \")\n",
    "        else: \n",
    "            ax.set_ylabel(\"NRMSE\")\n",
    "            \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (12,6))\n",
    "    for model in list(models.keys()):\n",
    "        print(model)\n",
    "        plot_(model, models[model], alph = alph)\n",
    "    #plot_(\"interpolation\", \"Blues\")\n",
    "    #plot_(\"exponential\", \"Reds\", alph = alph)\n",
    "    \n",
    "def kde_plots( target_freq = None, \n",
    "               log = False, \n",
    "               model = \"uniform\", \n",
    "               models = {\"interpolation\" : \"Greens\", \"exponential\" : \"Reds\", \"uniform\" : \"Blues\"},\n",
    "               enforce_bounds = True,\n",
    "               split = None):\n",
    "    \"\"\"\n",
    "    HEATMAP EXAMPLE:\n",
    "                     enforce_bounds = True)\n",
    "    flights = flights.pivot(\"month\", \"year\", \"passengers\") #y, x, z\n",
    "    ax = sns.heatmap(flights)\n",
    "    plot_nrmse_kde_2d(**additional_arguments, \n",
    "                      models = {\"interpolation\" : \"Greens\", \"exponential\" : \"Reds\", \"uniform\" : \"Blues\"})\n",
    "    \n",
    "    plot_nrmse_kde_2d(xx = \"obs hz\", **additional_arguments, \n",
    "                      models = {\"interpolation\" : \"Greens\", \"exponential\" : \"Reds\", \"uniform\" : \"Blues\"})\n",
    "    \"\"\"\n",
    "    \n",
    "    additional_arguments ={ \"black_pnts\" : False, \n",
    "                           \"alph\" : 0.3, \n",
    "                           \"target_freq\" : target_freq}    \n",
    "    \n",
    "    cmap = \"coolwarm\"\n",
    "    \n",
    "   \n",
    "    def add_noise(np_array, log = log):\n",
    "        sizee = len(np_array)\n",
    "        x =  np.random.randint(100, size = sizee) + np_array \n",
    "        \n",
    "        return(x)\n",
    "    \n",
    "    nrmse_dict = {}\n",
    "    \n",
    "    for i, model in enumerate([\"uniform\", \"exponential\", \"interpolation\"]):\n",
    "        df_ = df[df.model == model ]\n",
    "        \n",
    "        xx, yy = add_noise(df_[\"target hz\"]), add_noise(df_[\"obs hz\"])\n",
    "\n",
    "        nrmse= df_[\"nrmse\"]\n",
    "        if log == True:\n",
    "            print(\"hawabunga\")\n",
    "            nrmse = np.log(nrmse)\n",
    "        nrmse_dict[model] = nrmse\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    nrmse_diff = nrmse_dict[\"exponential\"].values.reshape(-1,)  - nrmse_dict[\"uniform\"].values.reshape(-1,) \n",
    "    print(\"(+): \" + str(np.sum((nrmse_diff > 0)*1)))\n",
    "    \n",
    "    print(\"(-): \" + str(np.sum((nrmse_diff < 0)*1)))\n",
    "    \n",
    "    \n",
    "    display(nrmse_diff)\n",
    "    xx, yy = add_noise(df_[\"target hz\"]), add_noise(df_[\"obs hz\"])\n",
    "    #sns.distplot(nrmse_diff, ax = ax[2])\n",
    "    sns.scatterplot(x = xx, y = yy, data = df_, ax = ax[2], palette=cmap, alpha = 0.9, s = 50, hue = nrmse_diff) #size = nrmse,\n",
    "    ax[2].set_title(\" diff: exponential - uniform\" )\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    \n",
    "    plot_nrmse_kde_2d(**additional_arguments, log = False, \n",
    "                      models = models, #{\"exponential\" : \"Reds\", \"uniform\" : \"Blues\", \"interpolation\" : \"Greens\"},\n",
    "                     enforce_bounds = True)\n",
    "    \n",
    "    \n",
    "    plot_nrmse_kde_2d(xx = \"obs hz\", **additional_arguments, log = False, \n",
    "                       models = models, #{\"exponential\" : \"Reds\", \"uniform\" : \"Blues\", \"interpolation\" : \"Greens\"},\n",
    "                       enforce_bounds = True)\n",
    "    \n",
    "               \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "kde_plots(models = {\"interpolation\" : \"Greens\", \"hybrid\" : \"Reds\"})#, \"uniform\" : \"Blues\"},)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plots(models = {\"interpolation\" : \"Greens\", \"exponential\" : \"Blues\", \"uniform\" : \"Reds\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: move the legend to the lower right corner\n",
    "kde_plots(target_freq = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exper_ in experiment_lst:\n",
    "    get_experiment(exper_,  compare_ = True, plot_split = False  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plots(target_freq = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    " \n",
    "def optimize_combination(ip, exp, Test, n = 10, optimize = True):\n",
    "    \n",
    "    if optimize == True:\n",
    "        nrmses = []\n",
    "        predictions = []\n",
    "        #(np.array(Test) + np.array(predictions[\"exponential\"])) / 2\n",
    "        vals =[]\n",
    "        for i in range(n):\n",
    "            a = i / n\n",
    "            b = 1 - a\n",
    "            hybrid_pred = ((1-a) * ip + a * exp)\n",
    "            predictions += [hybrid_pred]\n",
    "            nrmses += [nrmse(hybrid_pred , Test) ]\n",
    "            vals += [a]\n",
    "            #nrmse(predictions[\"hybrid\"], Test) \n",
    "        idx = np.argmin(nrmses) \n",
    "        print(nrmses)\n",
    "        print(\"A!! \" + str(vals[idx]))\n",
    "        best_prediction = predictions[idx]\n",
    "        best_nrmse      = nrmses[idx]\n",
    "        return(best_prediction, best_nrmse)\n",
    "    else:\n",
    "        hybrid_pred  = (0.5 * ip) + (0.5 * exp)\n",
    "        hybrid_nrmse = nrmse(hybrid_pred , Test)\n",
    "        return(hybrid_pred, hybrid_nrmse)\n",
    "    \n",
    "\n",
    "def show_images(exper_, aspect = 10, sigma = 1, method = \"heatmap\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Train, Test = recover_test_set(exper_)\n",
    "    \n",
    "    exper_ = fix_interpolation(exper_)\n",
    "    \n",
    "    predictions = exper_[\"prediction\"]\n",
    "    #print(predictions)\n",
    "    for i in predictions.values():\n",
    "        a = np.array(i)\n",
    "        #print(a.shape)\n",
    "        \n",
    "    nrmses      = exper_[\"nrmse\"]\n",
    "    predictions[\"ground_Truth\"]  = Test\n",
    "    nrmses[\"ground_Truth\"]       = 0\n",
    "    #predictions[\"ground_Truth_smooth\"]  = gaussian_filter(Test, sigma=sigma)\n",
    "    #nrmses[\"ground_Truth_smooth\"]       = 0\n",
    "    \n",
    "    fig, ax = plt.subplots(2,3, figsize = (16, 10))\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    for i, (key, value) in enumerate(predictions.items()):\n",
    "        print(i)\n",
    "        print(key)\n",
    "        arr = np.array(value)\n",
    "        full_arr = np.concatenate((Train, arr), axis = 0)\n",
    "        #arr = full_arr\n",
    "        \n",
    "        if method != \"heatmap\":\n",
    "            plt.imshow(arr.T, aspect = aspect)\n",
    "            plt.title(key +\" R: \" + str(nrmses[key]))\n",
    "            plt.subplot(2,3,i)\n",
    "            plt.show()       \n",
    "        else:\n",
    "            sns.heatmap(full_arr.T, ax = ax[i])\n",
    "            ax[i].set_title(key +\" R: \" + str(nrmses[key]))\n",
    "            #plt.show()\n",
    "    #plt.show()\n",
    "show_images(experiment_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(experiment_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(experiment_lst[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(experiment_lst[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(experiment_lst[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(experiment_lst[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(experiment_lst[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (14,4))\n",
    "sns.violinplot( y = \"nrmse\" , x = \"model\", data = df, ax = ax[0])\n",
    "sns.boxplot( y = \"nrmse\" , x = \"model\", data = df, ax = ax[1])\n",
    "ax[0].set_title(\"General NRMSE vs MODEL across different RC's\")\n",
    "ax[1].set_title(\"General NRMSE vs MODEL across different RC's\")\n",
    "ax[0].set_ylabel(\"NRMSE\"); ax[1].set_ylabel(\"NRMSE\")\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (14,4))\n",
    "sns.violinplot( y = \"nrmse\" , x = \"model\", data = df_rel, ax = ax[0])\n",
    "sns.boxplot( y = \"nrmse\" , x = \"model\", data = df_rel, ax = ax[1])\n",
    "ax[0].set_title(\"Relative NRMSE vs Interpolation model across different RC's\")\n",
    "ax[1].set_title(\"Relavite NRMSE vs Interpolation model across different RC's\")\n",
    "ax[0].set_ylabel(\"Relative NRMSE\"); ax[1].set_ylabel(\"Relative NRMSE\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (7,4))\n",
    "sns.violinplot( y = \"nrmse\" , x = \"model\", data = df_diff, ax = ax)\n",
    "#sns.boxplot( y = \"nrmse\" , x = \"model\", data = df_rel, ax = ax[1])\n",
    "ax.set_title(\"Relative NRMSE: ([exp nrmse] -  [unif nrmse])/[unif_nrmse] * 100\")\n",
    "ax.set_ylabel(\"Relative NRMSE\"); ax.set_ylabel(\"Relative NRMSE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"target hz\", data = df)\n",
    "plt.title(\"General NRMSE vs MODEL across different RC's\")\n",
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"target hz\", data = df_rel)\n",
    "plt.title(\"Relavite NRMSE vs Interpolation model across different RC's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = df[\"nrmse\"] #df[\"nrmse\"]np.log(df[\"nrmse\"])\n",
    "fig, ax = plt.subplots(1,1, figsize = (12,6))\n",
    "sns.scatterplot( y = hi, x = \"target hz\", data = df, hue = \"model\", alpha = 0.5, legend = False)\n",
    "sns.lineplot( y = hi, x = \"target hz\", data = df, hue = \"model\", alpha = 0.5)\n",
    "cap = np.log(1.0)/np.log(10)\n",
    "plt.axhline(y=cap, color=\"black\", linestyle='-', label = \"mean \" + str(model_), alpha = 0.5)\n",
    "plt.ylabel(\"log( NRMSE)\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize = (12,6))\n",
    "sns.scatterplot( y = hi, x = \"target hz\", data = df, hue = \"model\", alpha = 0.5, legend = False)\n",
    "sns.lineplot( y = hi, x = \"target hz\", data = df, hue = \"model\", alpha = 0.5)\n",
    "cap = np.log(1.0)/np.log(10)\n",
    "plt.axhline(y=cap, color=\"black\", linestyle='-', label = \"mean \" + str(model_), alpha = 0.5)\n",
    "plt.ylabel(\"log( NRMSE)\")\n",
    "plt.ylim((-1.5,cap))\n",
    "\n",
    "\n",
    "\n",
    "hi = df[\"nrmse\"]\n",
    "fig, ax = plt.subplots(1,1, figsize = (12,6))\n",
    "sns.scatterplot( y = hi, x = \"target hz\", data = df, hue = \"model\", alpha = 0.5, legend = False)\n",
    "sns.lineplot( y = hi, x = \"target hz\", data = df, hue = \"model\", alpha = 0.5)\n",
    "plt.ylabel(\"NRMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = np.log(df[\"nrmse\"])\n",
    "fig, ax = plt.subplots(1,1, figsize = (12,6))\n",
    "sns.scatterplot( y = hi, x = \"obs hz\", data = df, hue = \"model\", alpha = 0.5)\n",
    "sns.lineplot( y = hi, x = \"obs hz\", data = df, hue = \"model\", alpha = 0.5)\n",
    "ax.set_ylabel(\"Log ( NRMSE )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"target freq\", data = df)\n",
    "plt.title(\"General NRMSE vs MODEL across different RC's\")\n",
    "plt.ylim((0,1.5))\n",
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"target freq\", data = df_rel)\n",
    "plt.title(\"Relavite NRMSE vs Interpolation model across different RC's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"obs hz\", data = df)\n",
    "plt.title(\"General NRMSE vs MODEL across different RC's\")\n",
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"obs hz\", data = df_rel)\n",
    "plt.title(\"Relavite NRMSE vs Interpolation model across different RC's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_plot(experiment_lst):\n",
    "    \"\"\"\n",
    "    Let's visualize the hyper-parameter plots.\n",
    "    \"\"\"\n",
    "    log_vars = [\"noise\", \"connectivity\", \"regularization\", \"llambda\"]\n",
    "    \n",
    "    for i, experiment in enumerate(experiment_lst):\n",
    "        df_spec_unif = pd.DataFrame(experiment[\"best arguments\"][\"uniform\"], index = [0])\n",
    "        df_spec_exp  = pd.DataFrame(experiment[\"best arguments\"][\"exponential\"], index = [0])\n",
    "        \n",
    "        if not i:\n",
    "            df_unif = df_spec_unif\n",
    "            df_exp = df_spec_exp\n",
    "        else:\n",
    "            df_unif = pd.concat([df_unif, df_spec_unif])\n",
    "            df_exp = pd.concat([df_exp, df_spec_exp])\n",
    "\n",
    "    unif_vars = [\"connectivity\", \"regularization\", \"leaking_rate\", \"spectral_radius\"]\n",
    "    exp_vars  = [\"llambda\", \"noise\"]\n",
    "    df_unif = df_unif[unif_vars]\n",
    "    df_exp = df_exp[unif_vars + exp_vars]\n",
    "    \n",
    "    for i in list(df_unif.columns):\n",
    "        if i in log_vars:\n",
    "            df_unif[i] = np.log(df_unif[i])/np.log(10)\n",
    "            \n",
    "    for i in list(df_exp.columns):\n",
    "        if i in log_vars:\n",
    "            df_exp[i] = np.log(df_exp[i])/np.log(10)\n",
    "    \n",
    "    \n",
    "    #display(df_unif)\n",
    "    \n",
    "    sns.catplot(data = df_unif)\n",
    "    plt.title(\"uniform RC hyper-parameters\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    sns.catplot(data = df_exp)\n",
    "    plt.title(\"exponential RC hyper-parameters\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    #display(df_exp)\n",
    "   \n",
    "hyper_parameter_plot(experiment_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, experiment in enumerate(experiment_lst):\n",
    "    #print(experiment['get_observer_inputs'].keys())\n",
    "    split = experiment['get_observer_inputs'][\"split\"]\n",
    "    targ_hz = experiment['experiment_inputs'][\"target_hz\"]\n",
    "    targ_idx_LB, targ_idx_UB = experiment[\"resp_idx\"][0], experiment[\"resp_idx\"][-1]\n",
    "    obs_hz = experiment['experiment_inputs'][\"obs_hz\"]\n",
    "    f = np.array(experiment_8_obj.f)\n",
    "    obs_idx = experiment[\"obs_idx\"] \n",
    "\n",
    "    obs_idx  = [int(j) for j in experiment[\"obs_idx\"] ]\n",
    "    obs_freq = [max(f) - f[j] for j in obs_idx]\n",
    "    \n",
    "    \n",
    "    print(\"\\nexperiment: \" + str(i) + \", target hz: \" + str(targ_hz) + \", obs hz: \" + str(obs_hz) +\n",
    "         \", split: \" + str(split))\n",
    "\n",
    "    \n",
    "    print(\"target idx: [\" + str(targ_idx_LB) + \", \" + str(targ_idx_UB) + \"]\")\n",
    "    print(\"target freq: [\" + str(max(f) - f[targ_idx_LB]) + \", \" + str(max(f) - f[targ_idx_UB]) + \"]\")\n",
    "    print(\"obs idx: \" + str(obs_idx))\n",
    "    print(\"obs freq: \" + str(obs_freq))\n",
    "    print(experiment_8_obj.A.shape[0] - np.array(experiment[\"prediction\"][\"interpolation\"]).shape[0])\n",
    "    print(experiment_8_obj.A.shape[0])\n",
    "    #print(experiment[\"resp_idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_exp_weights(json_obj, llambda = None):\n",
    "    print(json_obj.keys())\n",
    "    esn_ = EchoStateNetwork(**json_obj[\"best arguments\"][\"exponential\"], plot = True)\n",
    "    esn_.obs_idx  = json_obj[\"obs_idx\"]\n",
    "    esn_.resp_idx = json_obj[\"resp_idx\"]\n",
    "    if llambda != None:\n",
    "        esn_.llambda = llambda\n",
    "    esn_.get_exp_weights()\n",
    "\n",
    "\n",
    "for i in experiment_lst:\n",
    "    show_exp_weights(i)  \n",
    "#show_exp_weights(experiment_2)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_exp_weights(i, llambda = 10**-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10**-2 \n",
    "np.log(10**-4)/np.log(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_lst = [experiment_1, experiment_2, experiment_3, experiment_4, \n",
    "                  experiment_5, experiment_6, experiment_7, experiment_8]\n",
    "\n",
    "def quick_dirty_convert(lst):\n",
    "    lst *= 3\n",
    "    print(lst)\n",
    "    pd_ = pd.DataFrame(np.array(lst).reshape(-1,1))\n",
    "    return(pd_)\n",
    "    \n",
    "\n",
    "idx_lst = list(range(len(experiment_lst)))\n",
    "#idx_lst *= 3\n",
    "#idx_lst = pd.DataFrame(np.array(idx_lst).reshape(-1,1))\n",
    "\n",
    "idx_lst = quick_dirty_convert(idx_lst)\n",
    "\n",
    "obs_hz_lst, targ_hz_lst = [], []\n",
    "\n",
    "for i, experiment in enumerate(experiment_lst):\n",
    "    targ_hz = experiment[\"experiment_inputs\"][\"target_hz\"]\n",
    "    obs_hz  = experiment[\"experiment_inputs\"][\"obs_hz\"]\n",
    "    \n",
    "    \n",
    "    if experiment[\"experiment_inputs\"][\"target_hz\"] < 1:\n",
    "        targ_hz *= 1000*1000\n",
    "        obs_hz  *= 1000*1000\n",
    "    obs_hz_lst  += [obs_hz]\n",
    "    targ_hz_lst += [targ_hz]\n",
    "    \n",
    "        \n",
    "    hz_line = {\"target hz\" : targ_hz }\n",
    "    hz_line = Merge(hz_line , {\"obs hz\" : obs_hz })\n",
    "    \n",
    "    #print(hz_line)\n",
    "    df_spec = experiment[\"nrmse\"]\n",
    "    #df_spec = Merge(experiment[\"nrmse\"], {\"target hz\": targ_hz})\n",
    "    df_spec = pd.DataFrame(df_spec, index = [0])\n",
    "    \n",
    "    df_spec_rel = df_spec.copy()\n",
    "    df_spec_rel = df_spec_rel / experiment[\"nrmse\"][\"interpolation\"]\n",
    "    \n",
    "    #print( df_spec_rel)\n",
    "    #print(experiment[\"experiment_inputs\"].keys())\n",
    "    if i == 0:\n",
    "        df = df_spec\n",
    "        df_rel = df_spec_rel\n",
    "        \n",
    "    else:\n",
    "        df = pd.concat([df, df_spec])\n",
    "        df_rel = pd.concat([df_rel, df_spec_rel])\n",
    "\n",
    "#obs_hz_lst  *= 3\n",
    "#targ_hz_lst *= 3\n",
    "\n",
    "obs_hz_lst, targ_hz_lst = quick_dirty_convert(obs_hz_lst), quick_dirty_convert(targ_hz_lst)\n",
    "        \n",
    "df, df_rel = pd.melt(df), pd.melt(df_rel)\n",
    "df  = pd.concat( [idx_lst, df,  obs_hz_lst, targ_hz_lst] ,axis = 1)\n",
    "\n",
    "df_rel = pd.concat( [idx_lst, df_rel,  obs_hz_lst, targ_hz_lst], axis = 1)\n",
    "\n",
    "df.columns     = [\"experiment\", \"model\", \"nrmse\", \"obs hz\", \"target hz\" ]\n",
    "df_rel.columns = [\"experiment\", \"model\", \"nrmse\", \"obs hz\", \"target hz\"] \n",
    "display(df)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (14,4))\n",
    "sns.violinplot( y = \"nrmse\" , x = \"model\", data = df, ax = ax[0])\n",
    "sns.boxplot( y = \"nrmse\" , x = \"model\", data = df, ax = ax[1])\n",
    "ax[0].set_title(\"General NRMSE vs MODEL across different RC's\")\n",
    "ax[1].set_title(\"General NRMSE vs MODEL across different RC's\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (14,4))\n",
    "sns.violinplot( y = \"nrmse\" , x = \"model\", data = df_rel, ax = ax[0])\n",
    "sns.boxplot( y = \"nrmse\" , x = \"model\", data = df_rel, ax = ax[1])\n",
    "ax[0].set_title(\"Relative NRMSE vs Interpolation model across different RC's\")\n",
    "ax[1].set_title(\"Relavite NRMSE vs Interpolation model across different RC's\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"target hz\", data = df)\n",
    "plt.title(\"General NRMSE vs MODEL across different RC's\")\n",
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"target hz\", data = df_rel)\n",
    "plt.title(\"Relavite NRMSE vs Interpolation model across different RC's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"obs hz\", data = df)\n",
    "plt.title(\"General NRMSE vs MODEL across different RC's\")\n",
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"obs hz\", data = df_rel)\n",
    "plt.title(\"Relavite NRMSE vs Interpolation model across different RC's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def merge_unif_exp(fp_unif, fp_exp):\n",
    "    exp_dat = load_data(fp_exp)\n",
    "    unif_dat = load_data(fp_unif)\n",
    "    assert exp_dat[\"prediction\"][\"interpolation\"] == unif_dat[\"prediction\"][\"interpolation\"], \"something is wrong!\"\n",
    "    joint_dat = unif_dat.copy()\n",
    "    for i in [\"prediction\", \"nrmse\", \"best arguments\"]:\n",
    "        exp_dict = {\"exponential\" : exp_dat[i][\"exponential\"]}\n",
    "        joint_dat[i] = Merge(joint_dat[i], exp_dict)\n",
    "    print(joint_dat[\"best arguments\"])\n",
    "        \n",
    "     \n",
    "    return(joint_dat)\n",
    "#0.5_1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = load_data('experiment_results/1k/publish/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt')\n",
    "hi = fix_interpolation(hi)\n",
    "\n",
    "get_experiment(hi) # broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = load_data('experiment_results/1k/publish/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt')\n",
    "hi = fix_interpolation(hi)\n",
    "\n",
    "get_experiment(hi) # broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = load_data('experiment_results/1k/publish/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt')\n",
    "hi = fix_interpolation(hi)\n",
    "\n",
    "get_experiment(hi) # broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = load_data('experiment_results/1k/publish/split_0.5/targetKhz:_0.1__obskHz:_0.1.txt')\n",
    "hi = fix_interpolation(hi)\n",
    "\n",
    "get_experiment(hi) # broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = load_data('experiment_results/1k/publish/split_0.5/targetKhz:_0.1__obskHz:_0.25.txt')\n",
    "hi = fix_interpolation(hi)\n",
    "\n",
    "get_experiment(hi) # broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_5 = load_data('/Users/hayden/Desktop/DL_LAB/Reservoir/MARIOS/experiment_results/4k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.5.txt')\n",
    "                         #bp = '/Users/hayden/Desktop/')\n",
    "experiment_5_obj = get_experiment(experiment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "uniform_ = df_rel[df_rel.model == \"uniform\"]\n",
    "exp_ = df_rel[df_rel.model == \"exponential\"]\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (12,6))\n",
    "sns.kdeplot(uniform_[\"target hz\"], uniform_[\"nrmse\"],\n",
    "                 cmap=\"Reds\", shade=True, shade_lowest=False, ax = ax[0])#, alpha = 0.5)\n",
    "sns.kdeplot(exp_[\"target hz\"], exp_[\"nrmse\"],\n",
    "                 cmap=\"Blues\", shade=True, shade_lowest=False, ax = ax[1])#, alpha = 0.5)\n",
    "ax[0].set_ylim(0,0.3)\n",
    "ax[1].set_ylim(0,0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOOTH\n",
    "#experiment_5 = load_data('/Users/hayden/Desktop/DL_LAB/Reservoir/MARIOS/experiment_results/2k/medium/split_0.5/targetKhz:_0.02__obskHz:_0.01.txt')\n",
    "#                         #bp = '/Users/hayden/Desktop/')\n",
    "#experiment_5_obj = get_experiment(experiment_5)\n",
    "%run -i '../MARIOS/PyFiles/imports.py'\n",
    "%run -i '../MARIOS/PyFiles/helpers.py'\n",
    "%run -i \"../MARIOS/PyFiles/experiment.py\"\n",
    "\n",
    "experiment_ = experiment_5.copy()\n",
    "for key, prediction in experiment_[\"prediction\"].items():\n",
    "    prediction = np.array(prediction)\n",
    "    Train, Test = recover_test_set(experiment_)\n",
    "    \n",
    "    experiment_[\"nrmse\"][key] = nrmse(prediction, Test)\n",
    "get_experiment(experiment_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOOTH\n",
    "experiment_5 = load_data('/Users/hayden/Desktop/DL_LAB/Reservoir/MARIOS/experiment_results/2k/medium/split_0.5/targetKhz:_0.02__obskHz:_0.01.txt')\n",
    "                         #bp = '/Users/hayden/Desktop/')\n",
    "experiment_ = experiment_5.copy()\n",
    "for key, prediction in experiment_[\"prediction\"].items():\n",
    "    prediction = np.array(prediction)\n",
    "    Train, Test = recover_test_set(experiment_)\n",
    "    \n",
    "    experiment_[\"nrmse\"][key] = nrmse(prediction, Test)\n",
    "experiment_5_obj = get_experiment(experiment_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liang_idx_convert(250, 259)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i '../MARIOS/PyFiles/imports.py'\n",
    "%run -i '../MARIOS/PyFiles/helpers.py'\n",
    "%run -i \"../MARIOS/PyFiles/experiment.py\"\n",
    "\n",
    "def liang_idx_convert(lb, ub):\n",
    "    idx_list = list(range(lb, ub + 1))\n",
    "    return idx_list\n",
    "\n",
    "\n",
    "\n",
    "experiment_ = EchoStateExperiment( size = \"medium\", \n",
    "                                   test_time_idx = liang_idx_convert(250, 259), \n",
    "                                   target_frequency = 2000,\n",
    "                                   train_time_idx = liang_idx_convert(220, 249),\n",
    "                                   prediction_type = \"column\")\n",
    "experiment_.get_observers(method = \"exact\", plot_split = True, aspect = 1)\n",
    "\n",
    "bounds = {\n",
    "          #'noise' : (-2, -4),\n",
    "          'llambda' : (-3, -1), \n",
    "          'connectivity': (-3, 0), # 0.5888436553555889, \n",
    "          'n_nodes': 1000,#(100, 1500),\n",
    "          'spectral_radius': (0.05, 0.99),\n",
    "          'regularization': (-10,-2)}\n",
    "\n",
    "\n",
    "default_presets = {\n",
    "                  'scoring_method' : 'tanh',\n",
    "                  \"cv_samples\" : 5,\n",
    "                  \"max_iterations\" : 4000,\n",
    "                  \"eps\" : 1e-5,\n",
    "                  'subsequence_length' : 250,\n",
    "                  \"initial_samples\" : 100}\n",
    "\n",
    "cv_args = {\n",
    "  'bounds' : bounds,\n",
    "  \"n_jobs\" : 4,\n",
    "  \"verbose\" : True,\n",
    "  \"plot\" : False, \n",
    "  **default_presets\n",
    "}\n",
    "\n",
    "experiment_.RC_CV(cv_args = cv_args, model = \"uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(experiment_.dat[\"resp_tr\"].T, aspect = 0.1)\n",
    "plt.show()\n",
    "plt.imshow(experiment_.dat[\"resp_te\"].T, aspect = 0.1)\n",
    "plt.show()\n",
    "plt.imshow(experiment_.dat[\"obs_tr\"].T, aspect = 10)\n",
    "plt.show()\n",
    "plt.imshow(experiment_.dat[\"obs_te\"].T, aspect = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwave_data = np.load(\"/Users/hayden/Desktop/GW.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwave_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwave_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3,figsize = (16,8))\n",
    "ax = ax.flatten()\n",
    "n = 5\n",
    "for i, j in enumerate(range(n, n+6)): \n",
    "    ax[i].imshow(gwave_data[j,:,:,1], aspect = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3,figsize = (16,8))\n",
    "ax = ax.flatten()\n",
    "for i, j in enumerate([5, 6, 7, 8, 12,13]): #[5, 6, 7, 8, 12,13]\n",
    "    ax[i].imshow(gwave_data[j,:,:,1], aspect = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/msripooja/steps-to-convert-audio-clip-to-spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import pickle\n",
    "import IPython.display as ipd\n",
    "def Audio(transform):\n",
    "    obj = ipd.Audio(data = transform[\"signal\"], rate = transform[\"sr\"])\n",
    "    return(obj)\n",
    "\n",
    "%run -i '../MARIOS/PyFiles/imports.py'\n",
    "%run -i '../MARIOS/PyFiles/helpers.py'\n",
    "%run -i \"../MARIOS/PyFiles/experiment.py\"\n",
    "\n",
    "\n",
    "pth_high = \"/Users/hayden/Desktop/18th_century_high.m4a\"\n",
    "\n",
    "#pth = \"/Users/hayden/Desktop/19th_century_high.wav\"#\"/Users/hayden/Desktop/get_free.wav\"\n",
    "\n",
    "def partition_song(array, x_start, x_len,  y_start, y_stop):\n",
    "    print(array.shape)\n",
    "    x_stop = x_start + 3000\n",
    "    partitioned_array = array[y_start:y_stop, x_start:x_stop].copy()\n",
    "    print(partitioned_array.shape)\n",
    "    return(partitioned_array)\n",
    "\n",
    "def get_transform(trans_type,\n",
    "                  hop_length_mult = 1, pth = \"/Users/hayden/Desktop/18th_century_dense.m4a\",\n",
    "                  n_bins_mult = 2, bins_per_octave =12, sr = None, y_axis = \"hz\", filter_scale = 1,\n",
    "                  norm = 1, method = \"db\", label = None, partition = False, save_path = None\n",
    "                  ):\n",
    "    fmin   = librosa.note_to_hz('C0')\n",
    "    if trans_type == 'cqt':\n",
    "        \n",
    "        y_axis = \"cqt_note\"\n",
    "    \n",
    "    assert label, \"enter a label so that you can save a file\"\n",
    "    assert trans_type in [\"stft\", \"cqt\", \"hybrid_cqt\", \"pseudo_cqt\", \"vqt\"]\n",
    "    \n",
    "    x, sr = librosa.load(pth, sr=None)\n",
    "    #C = np.abs(librosa.cqt(x, sr=None))\n",
    "    \n",
    "    #print(\"transform_type: \" + trans_type)\n",
    "    # Librosa transform functions dictionary:\n",
    "    trans_dict = { \"stft\" : librosa.stft,\n",
    "                   \"cqt\" : librosa.cqt,\n",
    "                   \"hybrid_cqt\": librosa.hybrid_cqt,\n",
    "                   \"pseudo_cqt\": librosa.pseudo_cqt,\n",
    "                   \"vqt\" : librosa.vqt\n",
    "    }\n",
    "    #n_bins = int(84*n_bins_mult)\n",
    "    n_bins = n_bins_mult\n",
    "    default_args = {\n",
    "         \"stft\" : {\n",
    "              \"n_fft\" : 512\n",
    "              #\"sr\" : sr\n",
    "         },\n",
    "         \"cqt\" : {\n",
    "                  \"fmin\" : fmin,\n",
    "                  'pad_mode': 'wrap',\n",
    "                  #\"fmin\": FMIN, , \n",
    "                  \"sr\" : sr,\n",
    "                  #\"n_bins\": 84,\n",
    "                  #\"hop_length\" : 2**6 * hop_length_mult\n",
    "                  #\"n_bins\" : n_bins #\"norm\": norm,\n",
    "                  }, #, \"hop_length\" : 64**hop_length_exp \"fmin\"  #\"filter_scale\": filter_scale : 1 #\"res_type\": \"fft\", #\"sparsity\": 0.1\n",
    "         \"hybrid_cqt\": {},\n",
    "         \"pseudo_cqt\": {},\n",
    "         \"vqt\" : {}\n",
    "        \n",
    "    }\n",
    "    \n",
    "    #x = librosa.resample(x, orig_sr = sr, target_sr = sr*5) #NOPE\n",
    "\n",
    "    N_FFT = len(x)\n",
    "    N_FFT_exp = 4\n",
    "    f = trans_dict[trans_type]\n",
    "    X = f(x, **default_args[trans_type]) #stft #, n_fft =int(N_FFT/np.exp(N_FFT_exp)\n",
    "\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    Xpow = np.log10( librosa.db_to_power(Xdb))\n",
    "    matrix2plot = Xpow if method == \"pow\" else Xdb\n",
    "    \n",
    "    if partition:\n",
    "        matrix2plot = partition_song(matrix2plot, partition, 15000, 0, 800)\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1,1, figsize=(7, 5)) \n",
    "    im1 = librosa.display.specshow(matrix2plot, x_axis='time', y_axis=y_axis, ax = ax)\n",
    "    plt.colorbar(im1, format='%+2.0f dB')\n",
    "    \n",
    "  \n",
    "    #Librosa frequency functions \n",
    "    f_dict = { \"stft\": librosa.fft_frequencies,\n",
    "               \"cqt\" : librosa.cqt_frequencies,\n",
    "               \"hybrid_cqt\": None,\n",
    "               \"pseudo_cqt\": None,\n",
    "               \"vqt\" : None}\n",
    "    \n",
    "    \n",
    "    f_default_args_stft = {\"stft\": {\"sr\" : sr, \"n_fft\" : 512}}            \n",
    "    \n",
    "    try:\n",
    "        f_default_args_cqt = {\"cqt\" : {\"fmin\" : fmin, \"n_bins\" : Xpow.shape[0]}}\n",
    "        f_default_args     = Merge(f_default_args_stft, f_default_args_cqt)\n",
    "        \n",
    "    except NameError:   \n",
    "        f_default_args = f_default_args_stft\n",
    "        \n",
    "    freq_fun = f_dict[trans_type]\n",
    "    freqs    = freq_fun(**f_default_args[trans_type])\n",
    "    \n",
    "    #\"type\": \n",
    "    #consider putting all transform types in this position.\n",
    "    transform = {\"signal\": x,\n",
    "                 \"sr\" : sr,\n",
    "                 \"transform\": {\n",
    "                               \"Xdb\"  : Xdb,\n",
    "                               \"Xpow\" : Xpow,\n",
    "                               \"f\"  :  freqs\n",
    "                               }\n",
    "                }\n",
    "    \n",
    "    #assertion to avoid incorrect frequency length.\n",
    "    err_msg = str(len(freqs.tolist())) + \"   \" + str(Xpow.shape[0])\n",
    "    assert len(freqs) == Xpow.shape[0], err_msg\n",
    "    \n",
    "    if save_path:\n",
    "        save_path = save_path + \"_\" + trans_type\n",
    "        print(\"saving at: \" + str(save_path))\n",
    "        save_pickle(save_path, transform)\n",
    "    \n",
    "    audio = Audio(transform)\n",
    "    plt.title(label)\n",
    "    \n",
    "    print_msg =  \"\\x1b[31m\\\"\"+ 'pickle_load(' + save_path + ')' + \"\\\"\\x1b[0m\"\n",
    "    print(\" to load this transform type \" + print_msg)\n",
    "    \n",
    "    \n",
    "    #print(plt.get_xydata() )\n",
    "    #print(labels)\n",
    "    #if trans_type == \"cqt\":\n",
    "    #    print(\"C1 = \" + str(librosa.note_to_hz('C0')))\n",
    "    return(audio) #transform, \n",
    "\n",
    "\n",
    "def save_pickle(path, transform):\n",
    "    save_path = \"./pickle_files/spectrogram_files/\" + path +\".pickle\"\n",
    "    with open(save_path, 'wb') as handle:\n",
    "        pickle.dump(transform, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_pickle(path):\n",
    "    path = \"./pickle_files/spectrogram_files/\" + path +\".pickle\"\n",
    "    with open(path, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return(b)\n",
    "#self.librosa_outfile = librosa_outfile\n",
    "#self.spectogram_path = spectogram_path\n",
    "\n",
    "#'./pickle_files/cqt_low_pitch.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transform(\"stft\", label = \"19th century male voice\",\n",
    "              pth = \"/Users/hayden/Desktop/wav_files/computer_male.mp3\",\n",
    "              save_path = \"19th_century_male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transform(\"stft\", label = \"19th century female voice\", pth = \"/Users/hayden/Desktop/computer_female.mp3\", save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_transform(\"cqt\", label = \"19th century male cqt transform\", pth = \"/Users/hayden/Desktop/computer_male.mp3\", save = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transform(\"cqt\", label = \"18th_cqt_f\", pth = \"/Users/hayden/Desktop/computer_female.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transform(\"cqt\", label = \"18th_cqt_f\", pth = \"/Users/hayden/Desktop/computer_female.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transform(\"cqt\", label = \"18th_cqt_high\",  pth = pth_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_free = \"/Users/hayden/Desktop/get_free.wav\"\n",
    "get_transform(\"cqt\", label = \"CQT: Get Free\",  pth = pth_free, partition = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_free = \"/Users/hayden/Desktop/get_free.wav\"\n",
    "#get_transform(\"stft\", label = \"FT: Get Free\",  pth = pth_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cqt = get_transform(\"cqt\", n_bins_mult = 150, y_axis = \"hz\", norm = 1, method = \"pow\" ) #filter_scale = 0.2\n",
    "NBINS = 100\n",
    "\n",
    "#plt.subplot(1,2,1)\n",
    "\n",
    "                              #hop_length_mult = 1)\n",
    "#plt.title(\"dense\")\n",
    "#save_pickle(\"18th_cqt_low\", cqt_low_pitch)\n",
    "\n",
    "#plt.subplot(1,2,2)\n",
    "cqt_high_pitch  = get_transform(\"cqt\", \n",
    "                                pth = pth_high,  \n",
    "                                n_bins_mult = NBINS,\n",
    "                                label = \"18th_cqt_high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the moment log(power) and default db setting appear the same. consider custom functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "fourier = get_transform(\"stft\", n_bins_mult = 150, method = \"pow\") # y_axis = \"log\",)\n",
    "save_pickle(\"fourier_power_low\", fourier_db_low)\n",
    "\n",
    "pth_high = \"/Users/hayden/Desktop/18th_century_high.m4a\"\n",
    "plt.title(\"dense\")\n",
    "fourier = get_transform(\"stft\", n_bins_mult = 150, # y_axis = \"log\",\n",
    "                       pth = pth_high, method = \"pow\")\n",
    "plt.title(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i '../MARIOS/PyFiles/imports.py'\n",
    "%run -i '../MARIOS/PyFiles/helpers.py'\n",
    "%run -i \"../MARIOS/PyFiles/experiment.py\"\n",
    "\n",
    "exper_ = get_experiment(experiment_lst[0], plot_split = False, compare_ = False)\n",
    "print(exper_.A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "librosa.display.specshow(exper_.A.T, y_axis='cqt_note', x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert dB to Pascals: (Pa)\n",
    "\n",
    "https://www.translatorscafe.com/unit-converter/en-US/sound-pressure-level/2-9/pascal-sound%20pressure%20level%20in%20decibels/#:~:text=Sound%20pressure%20level%20Lp,20%20%CE%BCPa%20or%200.00002%20Pa)\n",
    "\n",
    "\"Sound pressure level (SPL) is a logarithmic (decibel) measure of the sound pressure relative to the reference value of 20 μPa threshold of hearing. The threshold of hearing is the quietest sound that most young healthy people can hear. Sound pressure level Lp is measured in decibels (dB) and is calculated as follows:\"\n",
    "\n",
    "$L_p = 20*log_{10} (p/p_0)$\n",
    "\n",
    "Thus:\n",
    "$(p/p_0) = 10^{L_p/20}$\n",
    "\n",
    "usually $p_0 = 20 \\mu $ Pa or 0.00002 Pa\n",
    "\n",
    "\"The sound pressure level is an absolute value because it is referenced to another absolute value — the threshold of hearing. Therefore, the sound pressure in linear values like pascals can be converted into the sound pressure level in decibels and vice versa if the reference sound pressure is known.\"\n",
    "\n",
    "So p = 0.00002 * 10^{L_p/20}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert dB to Intensity of sound: \n",
    "\n",
    "https://www.omnicalculator.com/physics/db#sound-intensity-level-sil\n",
    "\n",
    "Sound intensity is defined as the sound wave power per unit area. It is a special quantity that allows us to measure the energy of sound (or, to be more precise, the energy per second per one squared meter).\n",
    "\n",
    "SIL = $10*log_{10}\\left(\\frac{I}{I_{ref}}\\right)$\n",
    "\n",
    "where:\n",
    "SIL is the sound intensity level in dB;\n",
    "I is the sound intensity in watts per squared meter;\n",
    "Iref is the reference value if sound intensity. Typically, it is assumed to be equal to 1×10⁻¹² W/m².\n",
    "\n",
    "$$I = 10^{\\frac{SIL}{10}-12}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The threshold of hearing:\n",
    "The threshold of hearing is generally reported as the RMS sound pressure of 20 micropascals, i.e. 0 dB SPL, corresponding to a sound intensity of 0.98 pW/m2 at 1 atmosphere and 25 °C.[3] It is approximately the quietest sound a young human with undamaged hearing can detect at 1,000 Hz.[4] The threshold of hearing is frequency-dependent and it has been shown that the ear's sensitivity is best at frequencies between 2 kHz and 5 kHz,[5] where the threshold reaches as low as −9 dB SPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = get_experiment(experiment_lst[0])\n",
    "dat = hi.A\n",
    "sns.distplot(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_parameters(array):\n",
    "    log_array    = np.log(array)\n",
    "    sample_mu, sample_sigma   = np.mean(log_array), np.std(log_array)\n",
    "    sample_variance = sample_sigma**2\n",
    "    estimated_mean = np.exp(sample_mu + 0.5*sample_variance)\n",
    "    estimated_variance = estimated_mean**2 * (np.exp(sample_variance) - 1) #np.exp\n",
    "    \n",
    "    est_params = {\"mean\" : estimated_mean,\n",
    "                  \"sd\" :   np.sqrt(estimated_variance)}\n",
    "    return(est_params)\n",
    "\n",
    "def dB2Pa(db_np, normalize = False, drop_silent = False, relative = True):\n",
    "    \"\"\"\n",
    "    converts a decibel level to pascals, for numpy arrays\n",
    "    \n",
    "    if normalize is set to true it normalizes the data assuming a log-normal distribution.\n",
    "    \n",
    "    if drop_silent is true, the function will flatten sounds not hearable by the human ear ( less that 20 * 10-6 pascals)\n",
    "    \"\"\"\n",
    "    p0 = 0.00002\n",
    "    pa_np = 10**(db_np/20)* p0 \n",
    "    \n",
    "    hearing_threshold = 20 * 10 **(-6)\n",
    "    faint_sounds = pa_np < hearing_threshold\n",
    "    \"\"\"\n",
    "    if normalize: #pa_np has a log-normal distribution: https://stats.stackexchange.com/questions/173715/calculate-variance-and-standard-deviation-for-log-normal-distribution\n",
    "        pa_np = np.log(pa_np) # it has a log-normal distribution roughly, so we transform, normalize, then transform back\n",
    "        pa_np = (pa_np - np.mean(pa_np))/np.std(pa_np)\n",
    "        pa_np = np.exp(pa_np)\n",
    "        \n",
    "     \n",
    "    \"\"\"\n",
    "    if normalize: #pa_np has a log-normal distribution: https://stats.stackexchange.com/questions/173715/calculate-variance-and-standard-deviation-for-log-normal-distribution\n",
    "        params = log_normal_parameters(pa_np)\n",
    "        print(params)\n",
    "        \n",
    "        mn, sig = params[\"mean\"], params[\"sd\"]\n",
    "        #hearing_threshold = (hearing_threshold - mn)/sig\n",
    "        pa_np = ((pa_np - mn)/sig)\n",
    "        #pa_np = pa_np  - np.min(pa_np)\n",
    "    \n",
    "    if relative:\n",
    "        pa_np = pa_np/ hearing_threshold\n",
    "    \n",
    "    #Flatten the sounds which the human ear cannot hear. rounding to 5 places preserved the lower bound of human hearing.\n",
    "    if drop_silent:\n",
    "        pa_np[faint_sounds] = np.round(pa_np[faint_sounds], 6)\n",
    "        #new lower bound to avoid 0 values:\n",
    "        pa_np_threshold = 0.000002 #20 * 10 ** (-7)\n",
    "        pa_np[pa_np < pa_np_threshold] = pa_np_threshold\n",
    "    return(pa_np)\n",
    "\n",
    "\n",
    "def dB2Intensity(db_np):\n",
    "    \"\"\"\n",
    "    converts a decibel level to pascals, for numpy arrays\n",
    "    *\n",
    "    \"\"\"\n",
    "    power = db_np/10 -12\n",
    "    Intensity = np.power(10, power)\n",
    "    return(Intensity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xpow =  dB2Pa(dat, normalize =  True)\n",
    "\n",
    "sns.distplot(Xpow)#Log- Normal!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xdb_normal = (Xdb - np.mean(Xdb))/np.std(Xdb)\n",
    "Xpow =  dB2Pa(Xdb, normalize = True, drop_silent = False)\n",
    "sns.distplot(np.log10(Xpow)) \n",
    "min_sound_human_hearing = 20 * 10**(-6)\n",
    "plt.xlabel(\"log(Pascals)\")\n",
    "plt.title(\"ke plot of Pascal values\")\n",
    "plt.ylabel(\"\")\n",
    "plt.axvline(x=np.log10(min_sound_human_hearing) , color = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 micro Pascals\n",
    "The softest sound a normal human ear can detect has a pressure variation of 20 micro Pascals, abbreviated as µPa, which is 20 x 10-6 Pa (\"20 millionth of a Pascal\") and is called the Threshold of Hearing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linear_log_comparison(dataset, \n",
    "                          method = \"propto-dB\", \n",
    "                          propto = True, \n",
    "                          normalized = True,\n",
    "                          log = False,\n",
    "                          drop_silent = True):\n",
    "\n",
    "    # we are only proportional because we have normalized the data.\n",
    "    assert method in [\"propto-dB\", \"propto-SIL\", \"propto-Pa\"], \"choose decibels or sound energy\"\n",
    "    \n",
    "    if method == \"propto-SIL\":\n",
    "        plot_value_label = \"SIL \"\n",
    "        dataset = dB2Intensity(dataset)\n",
    "        if log:\n",
    "            dataset = np.log(dataset)/np.log(10)\n",
    "        ylab = 'SIL (Sound Intensity Level)'  #sound wave power per unit area')\n",
    "            #dataset = (dataset - np.mean(dataset))/np.std(dataset) <-- gets you  what you started with\n",
    "    elif method == \"propto-Pa\":\n",
    "        \n",
    "        plot_value_label = \" (Pa)\" #sound pressure\n",
    "        ylab = \"Pascal\"\n",
    "        \n",
    "        dataset = dB2Pa(dataset, normalize = normalized, drop_silent = False)\n",
    "        #dataset = np.abs(dataset)\n",
    "        #dataset = np.log(dataset) #/np.std(dataset)\n",
    "        #dataset = (dataset - np.mean(dataset))/ np.std(dataset)\n",
    "        \n",
    "    else:\n",
    "        plot_value_label = \" (dB)\" # decibels\n",
    "        ylab = \"Hz\"\n",
    "        #lower_db_limit = -20\n",
    "        \n",
    "        if normalized:\n",
    "            dataset = (dataset - np.mean(dataset))/np.std(dataset)\n",
    "            #lower_db_limit = (lower_db_limit - np.mean(dataset))/np.std(dataset) \n",
    "        #if drop_silent:\n",
    "        #    dataset[dataset < lower_db_limit] = lower_db_limit\n",
    "            \n",
    "    \n",
    "    plot_title = \" spectrogram of '18th century'\" + plot_value_label\n",
    "    \n",
    "    plt.figure(figsize = (12,8))\n",
    "    \n",
    "    # Linear spectogram Plot\n",
    "    ax1 = plt.subplot(1,2,1)\n",
    "    librosa.display.specshow(dataset, y_axis='linear', x_axis='time')\n",
    "    \n",
    "    #display(quadmesh_.get_axes()) # get the first line, there might be more\n",
    "\n",
    "    #print(ax1.get_axes())#.get_xdata())\n",
    "    #print(plt.get_xdata())\n",
    "    plt.title('Linear ' + plot_title)\n",
    "    add_experiment_regions(ax1)\n",
    "    plt.ylabel(\"Hz\")\n",
    "    \n",
    "    #legend\n",
    "    legend_elements = [Patch(facecolor='pink', edgecolor='red',     label='3500 to 4500 Hz'),\n",
    "                       Patch(facecolor='lightblue', edgecolor='blue',   label='1500 to 2500 Hz'),\n",
    "                       Patch(facecolor='palegreen', edgecolor='green', label='250 to 12250 Hz')]\n",
    "    plt.legend(handles=legend_elements, loc='upper left')\n",
    "\n",
    "    # Log spectogram Plot\n",
    "    ax2 = plt.subplot(1,2,2)\n",
    "    librosa.display.specshow(dataset, y_axis='log', x_axis='time')\n",
    "    plt.title('Log ' + plot_title)\n",
    "    add_experiment_regions(ax2)\n",
    "    plt.ylabel(\"Hz\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    if method == \"propto-dB\":\n",
    "        propto_str = '%+2.0f' + str(r'$\\propto$') if propto else '%+2.0f'\n",
    "        colorbar_label = propto_str +\" dB\" #+\n",
    "    elif method == \"propto-SIL\":\n",
    "        colorbar_label = \"%+2.0f e-12 SIL\"  # + propto_str + \n",
    "    elif method == \"propto-Pa\":\n",
    "        colorbar_label = \"%.1e Pa\"  # propto_str +\n",
    "\n",
    "    plt.colorbar(format= colorbar_label)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    sns.distplot(dataset)\n",
    "    return(dataset)\n",
    "\n",
    "def add_experiment_regions(ax, plot = True):\n",
    "    def fill_region(lb, ub, color_):\n",
    "        ax.axhline(y=lb, color = color_, linestyle='-')\n",
    "        ax.axhline(y=ub, color = color_, linestyle='-')\n",
    "        x  = np.arange(0.0, 27, 0.1)\n",
    "        y1 = lb + 0 * x\n",
    "        y2 = ub + 0 * x\n",
    "        ax.fill_between(x, y2, y1, alpha = 0.2, color = color_)\n",
    "    trial = 2\n",
    "    if trial == 1:\n",
    "        lb_targ, ub_targ, obs_hz  = 210, 560, 320 / 2\n",
    "\n",
    "    elif trial == 2:\n",
    "        lb_targ, ub_targ, obs_hz  = 340, 640, 280\n",
    "    if plot:\n",
    "        fill_region(lb_targ-obs_hz, lb_targ, \"b\")  #150 hz\n",
    "        fill_region(lb_targ, ub_targ, \"g\") #250 hz\n",
    "        fill_region(ub_targ, ub_targ + obs_hz, \"b\") #150 hz\n",
    "    else:\n",
    "        obs_list = list(range(lb_targ-obs_hz, lb_targ, 10))\n",
    "        obs_list += list(range(ub_targ, ub_targ + obs_hz, 10))\n",
    "        resp_list = list(range(lb_targ, ub_targ, 10))\n",
    "        obs_resp = {\"target\": resp_list, \"obs\": obs_list}\n",
    "        return obs_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decibel spectogram (normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exper_ = experiment_lst[0]\n",
    "exper_obj = get_experiment(exper_)\n",
    "dat = exper_obj.A.T\n",
    "#hi = (hi - np.mean(hi))/np.std(hi)\n",
    "dataset_Pow = linear_log_comparison(dat, \n",
    "                      propto = False, \n",
    "                      normalized = False,\n",
    "                      drop_silent = False,\n",
    "                      method = \"propto-Pa\") \n",
    "\n",
    "dataset_db = linear_log_comparison(dat, \n",
    "                                    propto = False, \n",
    "                                    normalized = False,\n",
    "                                    drop_silent = True,\n",
    "                                    method = \"propto-dB\") \n",
    "\n",
    "custom_transform = {\"transform\": {\n",
    "                        \"Xdb\"  : dataset_db,\n",
    "                        \"Xpow\" : dataset_Pow,\n",
    "                        \"f\"  :   exper_obj.f}\n",
    "                   }\n",
    "save_pickle(\"custom\",custom_transform)\n",
    "#load_pickle(\"custom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE THIS NORMALIZED Pa DATASET!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decibel spectogram, unnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_log_comparison(exper_, \n",
    "                      propto = False, \n",
    "                      normalized = False,\n",
    "                      drop_silent = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pascal spectogram, normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_log_comparison(exper_, method = \"propto-Pa\", normalized = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pascal spectogram, unnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_log_comparison(exper_, method = \"propto-Pa\", normalized = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets look at the average sound pressure per log frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dB2Pa(exper_.A_unnormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_log_comparison(inputt = Xdb, method = \"propto-Pa\", drop_silent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(exper_.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_spectogram(dataset = exper_.A, f_arr = exper_.f):\n",
    "    \n",
    "    T = exper_.T\n",
    "    plt.imshow(dataset)\n",
    "    \n",
    "    f = np.array(f_arr)[1:] # humans hearing ranges from 20 db to 20k db so lets drop 0 to avoid -infty.\n",
    "    dataset = dataset[:,1:]\n",
    "    \n",
    "    f = np.log(f)/np.log(2) # humans experience sound logarithmically\n",
    "    \n",
    "    sns.distplot(dataset)\n",
    "    plt.show()\n",
    "    n_timesteps, n_frequencies  = dataset.shape\n",
    "\n",
    "    for i, time_step in enumerate(range(n_timesteps)):\n",
    "        if not i:\n",
    "            dictt_lst = []\n",
    "        this_timestep = T[time_step][0]\n",
    "        \n",
    "        #assert len(f) == len(this_timestep), \"error: \" + str(len(f)) + \" != \" + str(len(this_timestep))\n",
    "        for i, frequency_spec in enumerate(f):              \n",
    "            dictt_lst += [{\"frequency\" : frequency_spec , \n",
    "                           \"time\"      : this_timestep,\n",
    "                           \"amplitude\" : dataset[time_step, i]\n",
    "                            }]\n",
    "        #display(pd.DataFrame(dictt_lst))\n",
    "    \n",
    "    log_frequency_df = pd.DataFrame(dictt_lst)\n",
    "    log_frequency_df = log_frequency_df.pivot(\"frequency\", \"time\", \"amplitude\")\n",
    "    \n",
    "    sns.heatmap(log_frequency_df)\n",
    "    \n",
    "create_log_spectogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = sns.load_dataset(\"flights\")\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(Xdb, y_axis='log', x_axis='time')\n",
    "plt.title('log Power spectrogram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(Xdb, aspect = 10)#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_ = f_[1], f_[15] #_ denotes temporary variable, for testing or within a function.\n",
    "\n",
    "lb_, ub_ = bounds_\n",
    "\n",
    "def retrieve_freqs_btwn(bounds, f_):\n",
    "    f = np.array(f_)\n",
    "    lb, ub = bounds\n",
    "    display(bounds_)\n",
    "    lb_bool_vec, ub_bool_vec = (f > lb_), (f < ub_)\n",
    "    and_vector = ub_bool_vec* lb_bool_vec\n",
    "\n",
    "    freqs = f[and_vector]            #frequencies between bounds\n",
    "    freq_idxs = np.where(and_vector)[0] #indices between bounds\n",
    "\n",
    "    return(freq_idxs.tolist())\n",
    "    \n",
    "retrieve_freqs_btwn(bounds_, f_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def log_amplitude(exper_):\n",
    "    A = np.array(exper_.A)\n",
    "    print(np.min(A))\n",
    "    print(np.max(A))\n",
    "    orig_shape = A.shape\n",
    "    \n",
    "    signs = A.copy().reshape(-1,) < 0\n",
    "    signs = signs * 2 - 1\n",
    "    print(np.unique(signs))\n",
    "    signs = signs.reshape(orig_shape)\n",
    "    #plt.imshow(signs)\n",
    "    A_new = np.log(np.abs(A)) * signs\n",
    "    \n",
    "    #A_new = (A_new - np.mean(A_new))/ np.std(A_new)\n",
    "    #print(np.min(A_new))\n",
    "    #print(np.max(A_new))\n",
    "    #plt.imshow(A_new)\n",
    "    return(A_new)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = load_pickle('./pickle_files/results/18th_cqt_high/db/untouched/split_0.5/tf_250__obsHz_0.1__targHz_0.02.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = load_pickle(\"custom\")\n",
    "\n",
    "sns.heatmap(hi[\"Xpow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = load_pickle(\"18th_cqt_high\")\n",
    "print(hi[\"transform\"][\"Xdb\"])\n",
    "sns.heatmap(hi[\"transform\"][\"Xdb\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i '../MARIOS/PyFiles/imports.py'\n",
    "%run -i '../MARIOS/PyFiles/helpers.py'\n",
    "%run -i \"../MARIOS/PyFiles/experiment.py\"\n",
    "def get_frequencies(trial = 1):\n",
    "    \"\"\"\n",
    "    get frequency lists\n",
    "    \"\"\"\n",
    "    if trial == 1:\n",
    "        lb_targ, ub_targ, obs_hz  = 210, 560, int(320 / 2)\n",
    "\n",
    "    elif trial == 2:\n",
    "        lb_targ, ub_targ, obs_hz  = 340, 640, 280\n",
    "    elif trial == 3:\n",
    "        lb_targ, ub_targ, obs_hz  = 340, 350, 20\n",
    "\n",
    "\n",
    "    obs_list = list(range(lb_targ-obs_hz, lb_targ, 10))\n",
    "    obs_list += list(range(ub_targ, ub_targ + obs_hz, 10))\n",
    "    resp_list = list(range(lb_targ, ub_targ, 10))\n",
    "    return obs_list, resp_list\n",
    "\n",
    "obs_freqs, resp_freqs = get_frequencies(1)\n",
    "librosa_args = { \"spectrogram_path\": \"custom\",#\"cqt_high_pitch\",\n",
    "                         \"librosa\": True}\n",
    "#inputs = {'obs_freq_lst' :, \"targ_freq_lst\": , \"split\": 0.5}\n",
    "                       \n",
    "additional_Echo_inputs = {\n",
    "            \"obs_freq_lst\":  obs_freqs,\n",
    "            \"targ_freq_lst\" : resp_freqs\n",
    "            }\n",
    "Echo_inputs = {\n",
    "        \"size\" : \"medium\",\n",
    "        \"verbose\" : False,\n",
    "        \"prediction_type\" : \"block\"}\n",
    "Echo_inputs = Merge(Echo_inputs, additional_Echo_inputs)\n",
    "experiment = EchoStateExperiment( **Echo_inputs, **librosa_args)\n",
    "experiment.get_observers(method = \"exact\", split = 0.5, aspect = 0.9, plot_split = False)\n",
    "experiment.obs_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree pickle_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = load_pickle(\"./pickle_files/spectrogram_files/18th_cqt_high.pickle\")\n",
    "g_truth = dat[\"transform\"][\"Xdb\"]\n",
    "g_truth = (g_truth - np.mean(g_truth))/np.std(g_truth)\n",
    "line = g_truth[35][513:]\n",
    "fig, ax = plt.subplots(1,1,figsize = (10,4))\n",
    "sns.lineplot(x = range(len(bye)), y = bye, label = \"unif\")\n",
    "sns.lineplot(x = range(len(ip)), y = ip, label = \"ip\")\n",
    "sns.lineplot(x = range(len(line)), y =line, label = \"gtruth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_shape_0 = 1000\n",
    "def get_obs_eq(k):\n",
    "    hi = A_shape_0//k\n",
    "    viable_start = np.random.randint(hi)\n",
    "    observers = [k*i + viable_start for i, idx in  enumerate(range(viable_start, A_shape_0, k))]\n",
    "    print(observers)\n",
    "        \n",
    "get_obs_eq(25)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls pickle_files/results/custom/db/untouched/split_0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Zhizhuo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = 40\n",
    "end_idx = 942\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(test1.ip_res)\n",
    "#https://stackoverflow.com/questions/35215161/most-efficient-way-to-map-function-over-numpy-array\n",
    "%run -i '../MARIOS/PyFiles/imports.py'\n",
    "%run -i '../MARIOS/PyFiles/helpers.py'\n",
    "%run -i \"../MARIOS/PyFiles/experiment.py\"\n",
    "\n",
    "def pure_prediction_ip_generator(missing_data, end_idx):\n",
    "    test_idx = list(range(end_idx))[-missing_data:] #553, 712, 942\n",
    "    print(test_idx)\n",
    "    train_range_input = end_idx - missing_data\n",
    "    train_idx = list(range(train_range_input))\n",
    "    print(train_range_input)\n",
    "\n",
    "    experiment_inputs1 =  {'size': 'medium', \n",
    "                           'target_frequency': None, \n",
    "                           'verbose': False, \n",
    "                           'prediction_type': 'column', \n",
    "                           \"interpolation_method\" : \"griddata-nearest\",\n",
    "                           'train_time_idx': train_idx,\n",
    "                           'test_time_idx' : test_idx}#[514, 515, 516, 517, 518, 519, 520, 521, 522, 523]}#[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249], 'test_time_idx': [250, 251, 252, 253, 254, 255, 256, 257, 258, 259]}\n",
    "\n",
    "    test1 = EchoStateExperiment(**experiment_inputs1)\n",
    "    obs_inputs1 =  {'split': 0.5, 'aspect': 0.9, 'plot_split': False, 'method': 'exact'}\n",
    "    test1.get_observers(**obs_inputs1)\n",
    "\n",
    "\n",
    "    import math\n",
    "    def f(x):\n",
    "        \"\"\"\n",
    "        check if x is nan\n",
    "        x = float('nan')\n",
    "        math.isnan(x)\n",
    "        \"\"\"\n",
    "        return math.isnan(x)\n",
    "    def array_map(x, f):\n",
    "        x_shape= x.shape\n",
    "        print(\"x_shape\" + str(x.shape))\n",
    "        x  = x.flatten().tolist()\n",
    "        hi = np.array(list(map(f,x)))\n",
    "        print(hi)\n",
    "\n",
    "        return np.array(hi).reshape(x_shape)\n",
    "\n",
    "    test1_ip_pred = test1.ip_res[\"prediction\"]\n",
    "\n",
    "    plt.imshow(array_map(test1_ip_pred, f))\n",
    "    test1_ip_pred\n",
    "\n",
    "    my_dict = {\n",
    "        \"interpolation_prediction\": test1.ip_res[\"prediction\"],\n",
    "        \"ground_truth_test\"  : test1.xTe,\n",
    "        \"ground_truth_train\" : test1.xTr,\n",
    "        \"interpolation_MSE\"  : test1.ip_res[\"nrmse\"]\n",
    "    }\n",
    "\n",
    "    from scipy.io import savemat\n",
    "\n",
    "    save_path = \"zhizhuo/testindex_\" + str(test_idx[0]) + \"_\" + str(test_idx[-1]) +\".mat\"\n",
    "\n",
    "    print(save_path)\n",
    "    savemat(save_path, my_dict) #\"zhizhuo/testindex_514_523.mat\"\n",
    "    plt.imshow(test1.ip_res[\"prediction\"], aspect = 0.1)\n",
    "    return(test1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lst = [{\"missing_data\" : 40, \"end_idx\" : 289},\n",
    "            {\"missing_data\" : 40, \"end_idx\" : 553},\n",
    "            {\"missing_data\" : 40, \"end_idx\" : 712},\n",
    "            {\"missing_data\" : 40, \"end_idx\" : 942}]\n",
    "test_results = []\n",
    "for prediction in test_lst:\n",
    "    pred_ = pure_prediction_ip_generator(**prediction)\n",
    "    test_results.append(pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rez = [ test_result.ip_res[\"prediction\"] for test_result in test_results]\n",
    "test_ground = [ test_result.xTe for test_result in test_results]\n",
    "count = 1\n",
    "for i, rez in enumerate(test_rez):\n",
    "    plt.imshow(rez, aspect = 10)\n",
    "    plt.title(\"prediction\" + str(count))\n",
    "    \n",
    "    plt.show()\n",
    "    plt.imshow(test_ground[i], aspect = 10)\n",
    "    plt.title(\"truth\" + str(count))\n",
    "    plt.show()\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_pickle('19th_century_male_stft')\n",
    "plt.imshow(X['transform']['Xdb'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transform(\"stft\", label = \"19th century male voice\", pth = \"/Users/hayden/Desktop/computer_male.mp3\", save_path = \"19th_century_male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = \"\"\"                  {'target_freq': 2000, 'split': 0.5, 'obs_hz': 250, 'target_hz':  500},\n",
    "                          {'target_freq': 2000, 'split': 0.5, 'obs_hz': 250, 'target_hz':  750},\n",
    "                          {'target_freq': 2000, 'split': 0.5, 'obs_hz': 250, 'target_hz': 1000},\n",
    "\n",
    "                          {'target_freq': 2000, 'split': 0.5, 'obs_hz': 500, 'target_hz':  500},\n",
    "                          {'target_freq': 2000, 'split': 0.5, 'obs_hz': 500, 'target_hz':  750},\n",
    "                          {'target_freq': 2000, 'split': 0.5, 'obs_hz': 500, 'target_hz': 1000},\n",
    "\n",
    "                          {'target_freq': 2000, 'split': 0.5, 'obs_hz': 750, 'target_hz':  500},\n",
    "                          {'target_freq': 2000, 'split': 0.5, 'obs_hz': 750, 'target_hz':  750},\n",
    "                          {'target_freq': 2000, 'split': 0.5, 'obs_hz': 750, 'target_hz': 1000},\n",
    "\n",
    "\n",
    "                          {'target_freq': 2000, 'split': 0.9, 'obs_hz': 250, 'target_hz':  500},\n",
    "                          {'target_freq': 2000, 'split': 0.9, 'obs_hz': 250, 'target_hz':  750},\n",
    "                          {'target_freq': 2000, 'split': 0.9, 'obs_hz': 250, 'target_hz': 1000},\n",
    "\n",
    "                          {'target_freq': 2000, 'split': 0.9, 'obs_hz': 500, 'target_hz':  500},\n",
    "                          {'target_freq': 2000, 'split': 0.9, 'obs_hz': 500, 'target_hz':  750},\n",
    "                          {'target_freq': 2000, 'split': 0.9, 'obs_hz': 500, 'target_hz': 1000},\n",
    "\n",
    "                          {'target_freq': 2000, 'split': 0.9, 'obs_hz': 750, 'target_hz':  500},\n",
    "                          {'target_freq': 2000, 'split': 0.9, 'obs_hz': 750, 'target_hz':  750},\n",
    "                          {'target_freq': 2000, 'split': 0.9, 'obs_hz': 750, 'target_hz': 1000},\"\"\"\n",
    "path_lst = [\n",
    "          \"2k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.25.txt\",\n",
    "          \"2k/medium/split_0.5/targetKhz:_0.75__obskHz:_0.25.txt\",\n",
    "          \"2k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.25.txt\",\n",
    "\n",
    "          \"2k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.5.txt\",\n",
    "          \"2k/medium/split_0.5/targetKhz:_0.75__obskHz:_0.5.txt\",\n",
    "          \"2k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.5.txt\",\n",
    "\n",
    "          \"2k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.75.txt\",\n",
    "          \"2k/medium/split_0.5/targetKhz:_0.75__obskHz:_0.75.txt\",\n",
    "          \"2k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.75.txt\",\n",
    "\n",
    "          \"2k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.25.txt\",\n",
    "          \"2k/medium/split_0.9/targetKhz:_0.75__obskHz:_0.25.txt\",\n",
    "          \"2k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.25.txt\",\n",
    "\n",
    "          \"2k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt\",\n",
    "          \"2k/medium/split_0.9/targetKhz:_0.75__obskHz:_0.5.txt\",\n",
    "          \"2k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.5.txt\",\n",
    "\n",
    "          \"2k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.75.txt\",\n",
    "          \"2k/medium/split_0.9/targetKhz:_0.75__obskHz:_0.75.txt\",\n",
    "          \"2k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.75.txt\",\n",
    "    \n",
    "          \"4k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.25.txt\",\n",
    "          \"4k/medium/split_0.5/targetKhz:_0.75__obskHz:_0.25.txt\",\n",
    "          \"4k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.25.txt\",\n",
    "    \n",
    "          \"4k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.5.txt\",\n",
    "          \"4k/medium/split_0.5/targetKhz:_0.75__obskHz:_0.5.txt\",\n",
    "          \"4k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.5.txt\",\n",
    "    \n",
    "          \"4k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.75.txt\",\n",
    "          \"4k/medium/split_0.5/targetKhz:_0.75__obskHz:_0.75.txt\",\n",
    "          \"4k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.75.txt\",\n",
    "    \n",
    "          \"4k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.25.txt\",\n",
    "          \"4k/medium/split_0.9/targetKhz:_0.75__obskHz:_0.25.txt\",\n",
    "          \"4k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.25.txt\",\n",
    "    \n",
    "          \"4k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt\",\n",
    "          \"4k/medium/split_0.9/targetKhz:_0.75__obskHz:_0.5.txt\",\n",
    "          \"4k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.5.txt\",\n",
    "    \n",
    "          \"4k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.75.txt\",\n",
    "          \"4k/medium/split_0.9/targetKhz:_0.75__obskHz:_0.75.txt\",\n",
    "          \"4k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.75.txt\",\n",
    "            ]\n",
    "\n",
    "path_lst = ['/Users/hayden/Desktop/DL_LAB/Reservoir/MARIOS/experiment_results/medium/split_0.5/targetKhz:_0.01__obskHz:_0.02.txt' ]\n",
    "\n",
    "path_lst = ['/Users/hayden/Desktop/DL_LAB/Reservoir/backwards/experiment_results1/1k/publish/split_0.5/targetKhz:_0.1__obskHz:_0.1.txt',\n",
    "            \"/Users/hayden/Desktop/DL_LAB/Reservoir/backwards/experiment_results1/1k/publish/split_0.5/targetKhz:_0.1__obskHz:_0.25.txt\",\n",
    "            \"/Users/hayden/Desktop/DL_LAB/Reservoir/backwards/experiment_results1/1k/publish/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt\",\n",
    "            \"/Users/hayden/Desktop/DL_LAB/Reservoir/backwards/experiment_results1/1k/publish/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt\"\n",
    "           ]\n",
    "complete_experiment_path_lst = [ \n",
    "    #targ 500  kHz COMPLETE\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt',\n",
    "            #targ 1000 kHz COMPLETE\n",
    "            '2k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_1.0__obskHz:_1.0.txt',\n",
    "            \n",
    "            #targ 500  Hz COMPLETE\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.5.txt', #no exp\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.0.txt', #no exp\n",
    "            #targ 1000 Hz COMPLETE\n",
    "            '2k/medium/split_0.5/targetKhz:_1.0__obskHz:_1.0.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.5.txt', #no exp\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "            finished but publish size:\n",
    "            '/1k/publish/split_0.5/targetKhz:_0.1__obskHz:_0.1.txt',\n",
    "            \"/1k/publish/split_0.5/targetKhz:_0.1__obskHz:_0.25.txt\",\n",
    "            \n",
    "            ########################################################################### 1k\n",
    "            completed 1k tests\n",
    "            \"/1k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.0.txt\",\n",
    "            \"/1k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.5.txt\",\n",
    "            \"/1k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt\",\n",
    "            \"/1k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt\",\n",
    "            \"/1k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.5.txt\",\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def check_for_duplicates(lst, UnqLst = True, verbose = True):\n",
    "    for i, item in enumerate(lst):\n",
    "        if not i:\n",
    "            unique_lst = []\n",
    "            duplicates = []\n",
    "        if item in unique_lst:\n",
    "            duplicates.append(item) \n",
    "        else:\n",
    "            unique_lst.append(item)\n",
    "    if verbose:\n",
    "        print(duplicates)\n",
    "    if UnqLst:\n",
    "        return(unique_lst) \n",
    "\"\"\"     \n",
    "\n",
    "    \n",
    "experiments1k = [\n",
    "            \"/1k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt\",\n",
    "            \"/1k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt\",\n",
    "            \"/1k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.5.txt\"]\n",
    "\n",
    "hi = \"\"\"\n",
    "for i in experiments1k:\n",
    "    experiment_ = load_data(i,\n",
    "                             bp = './experiment_results')\n",
    "    hi = pd.DataFrame(experiment_['nrmse'], index = [0])\n",
    "    hi = pd.melt(hi)\n",
    "    hi.columns = [\"model\", \"nrmse\"]\n",
    "    print(hi)\n",
    "    sns.barplot(x = \"model\", y = \"nrmse\", data = hi)\n",
    "    #experiment_obj = get_experiment(experiment_5)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# when it comes time to run a lot of tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run -i '../MARIOS/PyFiles/imports.py'\n",
    "%run -i '../MARIOS/PyFiles/helpers.py'\n",
    "%run -i \"../MARIOS/PyFiles/experiment.py\"\n",
    "def quick_write_path(freq, split, targHz, obsHz, size = \"/medium\"):\n",
    "    if freq == 2000:\n",
    "        freqStr = \"2k\"\n",
    "    elif freq == 4000:\n",
    "        freqStr = \"4k\"\n",
    "    splitStr = \"/split_\" + str(split)\n",
    "    targHz, obsHz = str(targHz/1000) , str(obsHz/1000)\n",
    "    HzStr = \"/targetKhz:_\" + targHz + \"__obskHz:_\" +  obsHz \n",
    "    newPath = freqStr + size + splitStr + HzStr +\".txt\"\n",
    "    return([newPath])\n",
    "\n",
    "def quick_write_dict(freq, split, targHz, obsHz):\n",
    "    dict_tmp = {'target_freq': freq, 'split': split, 'obs_hz': obsHz, 'target_hz': targHz}\n",
    "    return([dict_tmp])\n",
    "\n",
    "\n",
    "path_lst = []\n",
    "dict_lst = []\n",
    "for targ_freq in [2000, 4000]:\n",
    "    for split in [0.5, 0.9]:\n",
    "        for targ in list(range(500, 2001, 250)):\n",
    "            for obs in list(range(500, 2001, 250)):\n",
    "                path_lst += quick_write_path(freq = targ_freq, split = split, targHz = targ, obsHz = obs)\n",
    "                dict_lst += quick_write_dict(freq = targ_freq, split = split, targHz = targ, obsHz = obs)\n",
    "\n",
    "\n",
    "path_lst += [ \n",
    "            # the plan is to run all those tests which will give detail from the LHS. ie increasin\n",
    "            # target Hz.\n",
    "            ########################################################################### 2k\n",
    "            #######################2k, 0.9 \n",
    "            #targ 500  kHz COMPLETE\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.75.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.25.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.75.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_2.0.txt',\n",
    "            \n",
    "    \n",
    "            \n",
    "\n",
    "            #targ 750  H z\n",
    "            '2k/medium/split_0.9/targetKhz:_0.75__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.75__obskHz:_1.0.txt',\n",
    "    \n",
    "            #targ 1000 kHz COMPLETE\n",
    "            '2k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_1.0__obskHz:_1.0.txt',\n",
    "            \n",
    "            #targ 1250  Hz\n",
    "            '2k/medium/split_0.9/targetKhz:_1.25__obskHz:_0.5.txt', \n",
    "            '2k/medium/split_0.9/targetKhz:_1.25__obskHz:_1.0.txt', \n",
    "    \n",
    "            #targ 1500  Hz\n",
    "            '2k/medium/split_0.9/targetKhz:_1.5__obskHz:_0.5.txt', \n",
    "            '2k/medium/split_0.9/targetKhz:_1.5__obskHz:_1.0.txt', \n",
    "    \n",
    "            #targ 1750  Hz\n",
    "            '2k/medium/split_0.9/targetKhz:_1.75__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_1.75__obskHz:_1.0.txt',\n",
    "    \n",
    "            #targ 2000  Hz\n",
    "            '2k/medium/split_0.9/targetKhz:_2.0__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_2.0__obskHz:_1.0.txt',\n",
    "    \n",
    "            #######################2k, 0.5\n",
    "            #targ 500  Hz COMPLETE\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.75.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.0.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.25.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.5.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.75.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_2.0.txt',\n",
    "    \n",
    "             #targ 750 Hz\n",
    "             \"2k/medium/split_0.5/targetKhz:_0.75__obskHz:_1.0.txt\",\n",
    "             \"2k/medium/split_0.5/targetKhz:_0.75__obskHz:_0.5.txt\", #CHECK LATER\n",
    "    \n",
    "            #targ 1000 Hz\n",
    "             \"2k/medium/split_0.5/targetKhz:_1.0__obskHz:_1.0.txt\", #\n",
    "             \"2k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.5.txt\", #\n",
    "    \n",
    "            #targ 1250 Hz\n",
    "             \"2k/medium/split_0.5/targetKhz:_1.25__obskHz:_1.0.txt\", # ABOUT TO RUN 600\n",
    "             \"2k/medium/split_0.5/targetKhz:_1.25__obskHz:_0.5.txt\", # ABOUT TO RUN 600\n",
    "    \n",
    "            #targ 1500 Hz\n",
    "             \"2k/medium/split_0.5/targetKhz:_1.5__obskHz:_1.0.txt\", # ABOUT TO RUN 1000\n",
    "             \"2k/medium/split_0.5/targetKhz:_1.5__obskHz:_0.5.txt\", # ABOUT TO RUN 1000\n",
    "    \n",
    "     \n",
    "             #targ 2000 Hz\n",
    "             '2k/medium/split_0.5/targetKhz:_2.0__obskHz:_1.0.txt', #no exp\n",
    "             \n",
    "    \n",
    "           ########################################################################### 4k\n",
    "           #######################4k, 0.9 \n",
    "           #4k, 0.9 500 target Hz COMPLETE\n",
    "           \"4k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt\",\n",
    "           \"4k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt\",\n",
    "            \n",
    "           #4k, 0.9 1000 target Hz RUNNING\n",
    "           '4k/medium/split_0.9/targetKhz:_0.75__obskHz:_0.5.txt', #RUNNING 200\n",
    "           '4k/medium/split_0.9/targetKhz:_0.75__obskHz:_1.0.txt', #RUNNING 200\n",
    "    \n",
    "           \n",
    "           #4k, 0.9 1000 target Hz COMPLETE\n",
    "           '4k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.5.txt',\n",
    "           '4k/medium/split_0.9/targetKhz:_1.0__obskHz:_1.0.txt',\n",
    "    \n",
    "           #4k, 0.9 1250 target Hz COMPLETE\n",
    "           '4k/medium/split_0.9/targetKhz:_1.25__obskHz:_0.5.txt', #RUNNING 400\n",
    "           '4k/medium/split_0.9/targetKhz:_1.25__obskHz:_1.0.txt', #RUNNING 400\n",
    "           \n",
    "           #4k, 0.9 1500 target Hz COMPLETE\n",
    "           '4k/medium/split_0.9/targetKhz:_1.5__obskHz:_0.5.txt', #RUNNING 700\n",
    "           '4k/medium/split_0.9/targetKhz:_1.5__obskHz:_1.0.txt', #RUNNING 700\n",
    "            \n",
    "\n",
    "           #######################4k, 0.5\n",
    "           #4k 0.5 target kHz COMPLETE\n",
    "           '4k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.5.txt', #???\n",
    "           \"4k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.0.txt\",  #???\n",
    "    \n",
    "           #4k 0.75 target kHz COMPLETE\n",
    "           \"4k/medium/split_0.5/targetKhz:_0.75__obskHz:_0.5.txt\", #NO EXP\n",
    "           \"4k/medium/split_0.5/targetKhz:_0.75__obskHz:_1.0.txt\",  \n",
    "           \n",
    "           #4k 1.0 target kHz \n",
    "           \"4k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.5.txt\",# ????\n",
    "           \"4k/medium/split_0.5/targetKhz:_1.0__obskHz:_1.0.txt\",   # ALREADY HAVE IT\n",
    "    \n",
    "           #4k, 0.5 1250 target Hz NEED TO RUN\n",
    "           '4k/medium/split_0.5/targetKhz:_1.25__obskHz:_0.5.txt', #ABOUT TO RUN 500\n",
    "           '4k/medium/split_0.5/targetKhz:_1.25__obskHz:_1.0.txt', #ABOUT TO RUN 500\n",
    "    \n",
    "            #4k, 0.5 1500 target Hz NEED TO RUN\n",
    "           '4k/medium/split_0.5/targetKhz:_1.5__obskHz:_0.5.txt', #ABOUT TO RUN 900\n",
    "           '4k/medium/split_0.5/targetKhz:_1.5__obskHz:_1.0.txt', #NO EXP\n",
    "\n",
    "           #4k 2.0 target kHz \n",
    "           \"4k/medium/split_0.5/targetKhz:_2.0__obskHz:_0.5.txt\", \n",
    "           \"4k/medium/split_0.5/targetKhz:_2.0__obskHz:_1.0.txt\", \n",
    "           \"4k/medium/split_0.5/targetKhz:_2.0__obskHz:_1.5.txt\", #For now this is deemed unessential.\n",
    "           \"4k/medium/split_0.5/targetKhz:_2.0__obskHz:_2.0.txt\", \n",
    "\n",
    "           #4k 0.5, bigger and better! \n",
    "\n",
    "           #\"2k/medium/split_0.5/targetKhz:_1.5__obskHz:_1.0.txt\", \n",
    "\n",
    "\n",
    "           \"4k/medium/split_0.5/targetKhz:_3.0__obskHz:_0.5.txt\",\n",
    "           \"4k/medium/split_0.5/targetKhz:_3.0__obskHz:_1.0.txt\",\n",
    "           \"4k/medium/split_0.5/targetKhz:_3.0__obskHz:_2.0.txt\",\n",
    "\n",
    "           #\"4k/medium/split_0.5/targetKhz:_4.0__obskHz:_0.5.txt\", #??? broken\n",
    "           #\"4k/medium/split_0.5/targetKhz:_4.0__obskHz:_1.0.txt\", #??? broken\n",
    "           #\"4k/medium/split_0.5/targetKhz:_4.0__obskHz:_2.0.txt\", #??? broken\n",
    "\n",
    "           #\"4k/medium/split_0.5/targetKhz:_0.75__obskHz:_1.0.txt\",\n",
    "\n",
    "           # MORE DETAIL:, given that the others aren't converging. \n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking out low frequency results\n",
    "exper_lst = []\n",
    "bp_ = \"/Users/hayden/Desktop/DL_LAB/Reservoir/MARIOS/pickle_files/results/custom/power/untouched/\"\n",
    "\n",
    "new_exper_path_lsts = [\n",
    "    \"split_0.5/tf_485.0__obsNIdx_56__targNIdx_30.pickle\",\n",
    "    \"split_0.9/tf_380.0__obsNIdx_32__targNIdx_35.pickle\"\n",
    "    #tf_485.0__obsNIdx_56__targNIdx_30.pickle\n",
    "]\n",
    "\n",
    "\n",
    "for i in new_exper_path_lsts:\n",
    "    exper_ = load_p_result(i, bp = bp_)\n",
    "    exper_lst += [exper_]\n",
    "    \n",
    "xpow = load_pickle(\"custom\")[\"transform\"][\"Xpow\"]\n",
    "\n",
    "this_experiment = exper_lst[0]\n",
    "resp_idx_ = this_experiment[\"resp_idx\"]\n",
    "print(resp_idx_)\n",
    "resp_ = xpow[resp_idx_]\n",
    "sns.heatmap(resp_)\n",
    "plt.show()\n",
    "sns.heatmap(resp_[:,512:])\n",
    "plt.show()\n",
    "sns.heatmap(np.array(exper_lst[0][\"prediction\"][\"exponential\"]).T)\n",
    "plt.show()\n",
    "sns.heatmap(np.array(exper_lst[0][\"prediction\"][\"interpolation\"]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def split_lst(lst, scnd_lst):\n",
    "    lst = np.array(lst)\n",
    "    breaka = np.mean(scnd_lst)\n",
    "    lst1, lst2 = lst[lst>breaka], lst[lst<breaka]\n",
    "    \n",
    "    return list(lst1), list(lst2)\n",
    "split_lst([1,2,3, 7,8,9], [4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
