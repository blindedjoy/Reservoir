{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i '../MARIOS/PyFiles/imports.py'\n",
    "%run -i '../MARIOS/PyFiles/helpers.py'\n",
    "%run -i \"../MARIOS/PyFiles/experiment.py\"\n",
    "from tqdm.notebook import trange, tqdm\n",
    "def compare(truth, \n",
    "            unif_w_pred = None, \n",
    "            exp_w_pred = None, \n",
    "            ip_pred = None,\n",
    "            columnwise = False,\n",
    "            verbose = False):\n",
    "    \"\"\"\n",
    "    This function provides two things, conditional on the columnwise variable.\n",
    "    columnwise = False: cross-model comparison of nrmse\n",
    "    \n",
    "    columnwise = True: model nrmse correlary for each point.\n",
    "    \"\"\"\n",
    "    #ip_res =    #runInterpolation(columnwise = columnwise)\n",
    "    \n",
    "    if type(unif_w_pred) != type(None):\n",
    "        unif_nrmse = nrmse(pred_ = unif_w_pred, truth = truth, columnwise = columnwise)\n",
    "        \n",
    "    if type(exp_w_pred) != type(None):\n",
    "        exp_nrmse = nrmse(pred_  = exp_w_pred , truth = truth, columnwise = columnwise)\n",
    "    \n",
    "    if type(ip_pred) != type(None):\n",
    "        ip_nrmse = nrmse(pred_  = ip_pred , truth = truth, columnwise = columnwise)\n",
    "        \n",
    "    ip_res = {\"nrmse\" : ip_nrmse, \"pred\" : ip_pred}\n",
    "        \n",
    "    \n",
    "    assert type(columnwise) == bool, \"columnwise must be a boolean\"\n",
    "    \n",
    "    if columnwise == False:\n",
    "        if verbose != False:\n",
    "            print(\"cubic spline interpolation nrmse: \" + str(ip_res[\"nrmse\"]))\n",
    "            print(\"uniform weights rc nrmse: \" + str(unif_nrmse))\n",
    "            print(\"exponential weights rc nrmse: \" + str(exp_nrmse))\n",
    "            print(\"creating barplot\")\n",
    "        if type(exp_w_pred) != type(None):\n",
    "            df = pd.DataFrame({\"interpolation\" : ip_res[\"nrmse\"], \n",
    "                               \"uniform rc\" : unif_nrmse, \n",
    "                               \"exponential rc\" : exp_nrmse}, index = [0])\n",
    "        else:\n",
    "            df = pd.DataFrame({\"interpolation\" : ip_res[\"nrmse\"], \n",
    "                               \"uniform rc\" : unif_nrmse}, index = [0])\n",
    "        display(df)\n",
    "\n",
    "        plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "        sns.catplot(data = df, kind = \"bar\")\n",
    "        plt.title(\"model vs nrmse\")\n",
    "        plt.ylabel(\"nrmse\")\n",
    "        improvement = []\n",
    "        for rc_nrmse in[unif_nrmse, exp_nrmse]:\n",
    "            impr_spec = ((ip_res[\"nrmse\"] - rc_nrmse)/ip_res[\"nrmse\"]) * 100\n",
    "            impr_spec = [round(impr_spec,1)]\n",
    "            improvement += impr_spec\n",
    "\n",
    "        pct_improve_unif, pct_improve_exp = improvement\n",
    "        if pct_improve_unif > 0:\n",
    "            print(\"unif improvement vs interpolation: nrmse \" + str(-pct_improve_unif) + \"%\")\n",
    "        else:\n",
    "            print(\"rc didn't beat interpolation: nrmse +\" + str(-pct_improve_unif) + \"%\")\n",
    "        \n",
    "        if pct_improve_exp > 0:\n",
    "            print(\"exp improvement vs interpolation: nrmse \" + str(-pct_improve_exp) + \"%\")\n",
    "        else:\n",
    "            print(\"rc didn't beat interpolation: nrmse +\" + str(-pct_improve_exp) + \"%\")\n",
    "\n",
    "        impr_rc_compare = round(((unif_nrmse - exp_nrmse)/unif_nrmse) * 100,1)\n",
    "\n",
    "        if impr_rc_compare > 0:\n",
    "            print(\"exp rc improvement vs unif rc: nrmse \" + str(-impr_rc_compare) + \"%\")\n",
    "        else:\n",
    "            print(\"exp weights didn't improve rc: nrmse +\" + str(-impr_rc_compare) + \"%\")\n",
    "    else:\n",
    "        print(\"creating first figure\")\n",
    "        model_names = [\"interpolation\", \"uniform rc\", \"exponential rc\"]\n",
    "        for i, model_rmse_np in enumerate([ip_res[\"nrmse\"], unif_nrmse, exp_nrmse]):\n",
    "            model_rmse_pd = pd.melt(pd.DataFrame(model_rmse_np.T))\n",
    "            model_rmse_pd.columns = [\"t\",\"y\"]\n",
    "            model_rmse_pd[\"model\"] = model_names[i]\n",
    "            if i == 0:\n",
    "                models_pd = model_rmse_pd\n",
    "            else:\n",
    "                models_pd = pd.concat([models_pd, model_rmse_pd ], axis = 0)\n",
    "        fig, ax = plt.subplots(1,1, figsize = (11, 6))\n",
    "        sns.lineplot(x = \"t\", y = \"y\", hue = \"model\", data = models_pd, ax = ax)\n",
    "        ax.set_title(\"model vs rmse\")\n",
    "        ax.set_ylabel(\"nrmse\")\n",
    "        ax.set_xlabel(\"Test idx\")\n",
    "        \n",
    "def get_experiment(json_obj, verbose = False, compare_ = True, plot_split = True):\n",
    "    \n",
    "    experiment_ = EchoStateExperiment(**json_obj[\"experiment_inputs\"])\n",
    "    \n",
    "    obs_inputs = json_obj[\"get_observer_inputs\"]\n",
    "    obs_inputs[\"method\"] = \"exact\"\n",
    "    \n",
    "    experiment_.obs_idx, experiment_.resp_idx  = json_obj[\"obs_idx\"], json_obj[\"resp_idx\"]\n",
    "    \n",
    "    experiment_.get_observers(**obs_inputs, \n",
    "                              plot_split = plot_split)\n",
    "    if verbose == True:\n",
    "        print(\"experiment inputs: \" + str(json_obj[\"experiment_inputs\"]))\n",
    "        print(\"get_obs_inputs: \" + str(obs_inputs))\n",
    "        print(\"Train.shape: \" + str(experiment_.Train.shape))\n",
    "        print(\"Saved_prediction.shape: \" + str(np.array(json_obj[\"prediction\"][\"uniform\"]).shape))\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    experiment_.already_trained(json_obj[\"best arguments\"][\"uniform\"], exponential = False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(experiment_.prediction.shape)\n",
    "    #print(experiment_.Test.shape)\n",
    "    \n",
    "    experiment_.Train, experiment_.Test = recover_test_set(json_obj)\n",
    "    \n",
    "    ### which line is missing?\n",
    "    xx = range(experiment_.prediction.shape[0])\n",
    "    \n",
    "    \n",
    "    #plt.imshow( experiment_.prediction)\n",
    "    #plt.show()\n",
    "    \"\"\"\n",
    "    #plt.imshow( experiment_.Test)\n",
    "    #plt.show()\n",
    "    \n",
    "    sns.lineplot( x = xx, y = experiment_.prediction[ : , 0 ], label = \"prediction from cluster 0 \")\n",
    "    sns.lineplot( x = xx, y = experiment_.prediction[ : , 0 ], label = \"prediction from cluster 1 \")\n",
    "    sns.lineplot( x = xx, y = experiment_.Test[ : , 0 ], label = \"actual data 0\")\n",
    "    sns.lineplot( x = xx, y = experiment_.Test[ : , -1 ], label = \"actual data 1\")\n",
    "    #plt.plot(experiment_.Test[ : , 1 ])\n",
    "    \"\"\"\n",
    "    \n",
    "    #experiment_.plot_timeseries(method = \"avg\")\n",
    "    if compare_ == True:\n",
    "        n_keys = len(list(json_obj[\"prediction\"].keys()))\n",
    "        if  n_keys == 3:\n",
    "            unif_w_pred, exp_w_pred = json_obj[\"prediction\"][\"uniform\"], json_obj[\"prediction\"][\"exponential\"]\n",
    "            ip_pred = json_obj[\"prediction\"][\"interpolation\"]\n",
    "            unif_w_pred, exp_w_pred, ip_pred = [np.array(i) for i in [unif_w_pred, exp_w_pred, ip_pred]]\n",
    "            \"\"\"\n",
    "            if verbose == True:\n",
    "                for i in [[unif_w_pred, \"unif pred\"],\n",
    "                          [exp_w_pred, \"exp pred\"],\n",
    "                          [ip_pred, \"ip pred\"],\n",
    "                          [np.array(experiment_.Test), \"Test\" ]]:\n",
    "                    Shape(i)\n",
    "            \"\"\"\n",
    "            \n",
    "            compare(\n",
    "                truth       = np.array(experiment_.Test), \n",
    "                unif_w_pred = unif_w_pred,\n",
    "                ip_pred     = ip_pred,\n",
    "                exp_w_pred  = exp_w_pred, \n",
    "                columnwise  = False,\n",
    "                verbose = False)\n",
    "        if n_keys == 2:\n",
    "            compare(\n",
    "                truth       = np.array(experiment_.Test), \n",
    "                unif_w_pred = np.array(json_obj[\"prediction\"][\"uniform\"]),\n",
    "                ip_pred = np.array(json_obj[\"prediction\"][\"interpolation\"]),\n",
    "                exp_w_pred  = None,#np.array(json_obj[\"prediction\"][\"exponential\"]), \n",
    "                columnwise  = False,\n",
    "                verbose = False)\n",
    "\n",
    "    return(experiment_)\n",
    "    \n",
    "##CHECK IF INTERPOLATION IS RUNNING CORRECTLY (#NOWAY)\n",
    "\n",
    "    \n",
    "    #print(ip_)\n",
    "    #exp_ = nrmse(pred_ = np.array(hi[\"prediction\"][\"exponential\"]), truth = hiObj.xTe, columnwise = False)\n",
    "    #diff += [ip_ - exp_]\n",
    "    #print(exp_)\n",
    "#sns.distplot(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Step 2: store hyper-parameter-results: Let's get some nice hyper-parameter plots.\n",
    "#TODO: Step 1: check if observers are correct:\n",
    "#TODO: fix\n",
    "\n",
    "\n",
    "def check_shape_obs(file = \"default\"):\n",
    "    if file == \"default\":\n",
    "        nf = get_new_filename(exp = exp, current = True)\n",
    "    else:\n",
    "        nf = file\n",
    "    with open(nf) as json_file: # 'non_exp_w.txt'\n",
    "        datt = json.load(json_file)\n",
    "    #datt = non_exp_best_args[\"dat\"]\n",
    "    #datt[\"obs_tr\"], datt[\"obs_te\"]   = np.array(datt[\"obs_tr\"]), np.array(datt[\"obs_te\"])\n",
    "    #datt[\"resp_tr\"], datt[\"resp_te\"] = np.array(datt[\"resp_tr\"]), np.array(datt[\"resp_te\"])\n",
    "    return(datt)\n",
    "\n",
    "def load_data(file = \"default\", print_lst = [\"nrmse\"], bp = None, verbose = True, enforce_exp = False):\n",
    "    if bp != None:\n",
    "        file = bp + file\n",
    "    if file == \"default\":\n",
    "        nf = get_new_filename(exp = exp, current = True)\n",
    "    else:\n",
    "        nf = file\n",
    "    with open(nf) as json_file: # 'non_exp_w.txt'\n",
    "        datt = json.load(json_file)\n",
    "    \n",
    "    for i in print_lst:\n",
    "        if verbose == True:\n",
    "            if enforce_exp == True:\n",
    "                assert len(list(print_lst.keys())) >= 3, \"exp not found: \" + file\n",
    "            print(datt[i])\n",
    "        \n",
    "    return(datt)\n",
    "\n",
    "\n",
    "\n",
    "#experiment.save_json(exp = False)\n",
    "#fp = bp + 'targetKhz:_0.01__obskHz:_0.01.txt'\n",
    "#fp = bp + 'targetKhz:_0.02__obskHz:_0.01.txt'\n",
    "def topline(spec_path, \n",
    "            base_path = \"/Users/hayden/Desktop/experiment_results/2k/medium/\",\n",
    "            #base_path = #\"./experiment_results/...\"\n",
    "            verbose = False,\n",
    "            print_filestructure = False):\n",
    "    \n",
    "    print(base_path)\n",
    "    fp = base_path + spec_path\n",
    "    \"\"\"\n",
    "    \n",
    "    targetKhz:_0.02__obskHz:_0.01.txt\n",
    "    │   │   │   ├── targetKhz:_0.5__obskHz:_0.5.txt\n",
    "    │   │   │   └── targetKhz:_0.5__obskHz:_1.0.txt\n",
    "    \"\"\"\n",
    "    hi = load_data(file = fp)\n",
    "    if print_filestructure == True:\n",
    "        for i in hi.keys():\n",
    "            print(i + \"/\")\n",
    "\n",
    "            if type(hi[i]) == dict:\n",
    "\n",
    "                for j in hi[i].keys():\n",
    "                    print(\"    \" +j)\n",
    "    if verbose == True:\n",
    "        print(\"DATA STRUCTURE: (it's a dict)\")\n",
    "        print(\"/n inputs:\")\n",
    "        print(hi[\"experiment_inputs\"])\n",
    "        print(hi[\"get_observer_inputs\"])\n",
    "\n",
    "        print(\"/n key saved values:\")\n",
    "        print(hi[\"best arguments\"])\n",
    "        print(hi[\"nrmse\"])\n",
    "    return(hi)\n",
    "\n",
    "def recover_test_set(json_obj):\n",
    "    \"\"\"\n",
    "    This function exists for an annoying reason: there is a shitty bug in my code.\n",
    "    A timeline is dropped and surely this is minor if we can just recover the index by exact indices.\n",
    "    \"\"\"\n",
    "    \n",
    "    experiment_ = EchoStateExperiment(**json_obj[\"experiment_inputs\"])\n",
    "    \n",
    "    obs_inputs = json_obj[\"get_observer_inputs\"]\n",
    "    obs_inputs[\"method\"] = \"exact\"\n",
    "    \n",
    "\n",
    "    \n",
    "    obs_idx, resp_idx = json_obj[\"obs_idx\"], json_obj[\"resp_idx\"]\n",
    "    A_subset = experiment_.A.copy()\n",
    "    \n",
    "    # pred shape\n",
    "    pred_shape = np.array(json_obj[\"prediction\"][\"interpolation\"]); pred_shape = pred_shape.shape[0]                   \n",
    "    \n",
    "    A = experiment_.A\n",
    "    \n",
    "    train_len = (A.shape[0] - pred_shape)\n",
    "    Train_Tmp, Test_Tmp  = A[:train_len, resp_idx], A[train_len:, resp_idx]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(Test_Tmp.shape)\n",
    "    return(Train_Tmp, Test_Tmp)\n",
    "\n",
    "#recover_test_set(hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "complete_experiment_path_lst = [ \n",
    "    #targ 500  kHz COMPLETE\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt',\n",
    "            #targ 1000 kHz COMPLETE\n",
    "            '2k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_1.0__obskHz:_1.0.txt',\n",
    "            \n",
    "            #targ 500  Hz COMPLETE\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.5.txt', #no exp\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.0.txt', #no exp\n",
    "            #targ 1000 Hz COMPLETE\n",
    "            '2k/medium/split_0.5/targetKhz:_1.0__obskHz:_1.0.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.5.txt', #no exp\n",
    "]\n",
    "def check_splits(complete_experiment_path_lst_):\n",
    "    for i in complete_experiment_path_lst_:\n",
    "        experiment_ = load_data(i, bp = './experiment_results/', verbose = False)\n",
    "        get_experiment(experiment_, compare = True)\n",
    "        #experiment_8_obj = get_experiment(experiment_8)\n",
    "        #get_experiment(i)#E, print_filestructure = False)\n",
    "                #base_path = \"./experiment_results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'interpolation': 1.664992216188176, 'uniform': 0.3403628792387194, 'exponential': 0.2500381416633909}\n",
      "           model     nrmse\n",
      "0  interpolation  1.664992\n",
      "1        uniform  0.340363\n",
      "2    exponential  0.250038\n",
      "{'interpolation': 1.7037950317117738, 'uniform': 0.42083644839727097, 'exponential': 0.2966628728306412}\n",
      "           model     nrmse\n",
      "0  interpolation  1.703795\n",
      "1        uniform  0.420836\n",
      "2    exponential  0.296663\n",
      "{'interpolation': 3.005202142901966, 'uniform': 0.22351629293639289, 'exponential': 0.22099042451719858}\n",
      "           model     nrmse\n",
      "0  interpolation  3.005202\n",
      "1        uniform  0.223516\n",
      "2    exponential  0.220990\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_for_duplicates(lst, UnqLst = True, verbose = True):\n",
    "    lst_tmp = []\n",
    "    duplicates = []\n",
    "    for i in lst:\n",
    "        if i in lst_tmp:\n",
    "            \n",
    "            duplicates += [i]\n",
    "        else:\n",
    "            lst_tmp += [i]\n",
    "    if verbose == True:\n",
    "        print(duplicates)\n",
    "    if UnqLst:\n",
    "        return(lst_tmp)\n",
    "experiments1k = [\n",
    "            \"/1k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt\",\n",
    "            \"/1k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt\",\n",
    "            \"/1k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.5.txt\"]\n",
    "\n",
    "for i in experiments1k:\n",
    "    experiment_ = load_data(i,\n",
    "                             bp = './experiment_results/')\n",
    "    hi = pd.DataFrame(experiment_['nrmse'], index = [0])\n",
    "    hi = pd.melt(hi)\n",
    "    hi.columns = [\"model\", \"nrmse\"]\n",
    "    print(hi)\n",
    "    sns.barplot(x = \"model\", y = \"nrmse\", data = hi)\n",
    "    #experiment_obj = get_experiment(experiment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "            finished but publish size:\n",
    "            '/1k/publish/split_0.5/targetKhz:_0.1__obskHz:_0.1.txt',\n",
    "            \"/1k/publish/split_0.5/targetKhz:_0.1__obskHz:_0.25.txt\",\n",
    "            \n",
    "            ########################################################################### 1k\n",
    "            completed 1k tests\n",
    "            \"/1k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.0.txt\",\n",
    "            \"/1k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.5.txt\",\n",
    "            \"/1k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt\",\n",
    "            \"/1k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt\",\n",
    "            \"/1k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.5.txt\",\n",
    "\"\"\"\n",
    "\n",
    "def quick_write_path(freq, split, targHz, obsHz, size = \"/medium\"):\n",
    "    if freq == 2000:\n",
    "        freqStr = \"2k\"\n",
    "    elif freq == 4000:\n",
    "        freqStr = \"4k\"\n",
    "    splitStr = \"/split_\" + str(split)\n",
    "    targHz, obsHz = str(targHz/1000) , str(obsHz/1000)\n",
    "    HzStr = \"/targetKhz:_\" + targHz + \"__obskHz:_\" +  obsHz \n",
    "    newPath = freqStr + size + splitStr + HzStr +\".txt\"\n",
    "    return([newPath])\n",
    "\n",
    "def quick_write_dict(freq, split, targHz, obsHz):\n",
    "    dict_tmp = {'target_freq': freq, 'split': split, 'obs_hz': obsHz, 'target_hz': targHz}\n",
    "    return([dict_tmp])\n",
    "\n",
    "\n",
    "path_lst = []\n",
    "dict_lst = []\n",
    "for targ_freq in [2000, 4000]:\n",
    "    for split in [0.5, 0.9]:\n",
    "        for targ in list(range(500, 2001, 250)):\n",
    "            for obs in list(range(500, 2001, 250)):\n",
    "                path_lst += quick_write_path(freq = targ_freq, split = split, targHz = targ, obsHz = obs)\n",
    "                dict_lst += quick_write_dict(freq = targ_freq, split = split, targHz = targ, obsHz = obs)\n",
    "\n",
    "\n",
    "path_lst += [ \n",
    "            # the plan is to run all those tests which will give detail from the LHS. ie increasin\n",
    "            # target Hz.\n",
    "            ########################################################################### 2k\n",
    "            #######################2k, 0.9 \n",
    "            #targ 500  kHz COMPLETE\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.75.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.25.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.75.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.5__obskHz:_2.0.txt',\n",
    "            \n",
    "    \n",
    "            \n",
    "\n",
    "            #targ 750  H z\n",
    "            '2k/medium/split_0.9/targetKhz:_0.75__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_0.75__obskHz:_1.0.txt',\n",
    "    \n",
    "            #targ 1000 kHz COMPLETE\n",
    "            '2k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_1.0__obskHz:_1.0.txt',\n",
    "            \n",
    "            #targ 1250  Hz\n",
    "            '2k/medium/split_0.9/targetKhz:_1.25__obskHz:_0.5.txt', \n",
    "            '2k/medium/split_0.9/targetKhz:_1.25__obskHz:_1.0.txt', \n",
    "    \n",
    "            #targ 1500  Hz\n",
    "            '2k/medium/split_0.9/targetKhz:_1.5__obskHz:_0.5.txt', \n",
    "            '2k/medium/split_0.9/targetKhz:_1.5__obskHz:_1.0.txt', \n",
    "    \n",
    "            #targ 1750  Hz\n",
    "            '2k/medium/split_0.9/targetKhz:_1.75__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_1.75__obskHz:_1.0.txt',\n",
    "    \n",
    "            #targ 2000  Hz\n",
    "            '2k/medium/split_0.9/targetKhz:_2.0__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.9/targetKhz:_2.0__obskHz:_1.0.txt',\n",
    "    \n",
    "            #######################2k, 0.5\n",
    "            #targ 500  Hz COMPLETE\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.5.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.75.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.0.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.25.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.5.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.75.txt',\n",
    "            '2k/medium/split_0.5/targetKhz:_0.5__obskHz:_2.0.txt',\n",
    "    \n",
    "             #targ 750 Hz\n",
    "             \"2k/medium/split_0.5/targetKhz:_0.75__obskHz:_1.0.txt\",\n",
    "             \"2k/medium/split_0.5/targetKhz:_0.75__obskHz:_0.5.txt\", #CHECK LATER\n",
    "    \n",
    "            #targ 1000 Hz\n",
    "             \"2k/medium/split_0.5/targetKhz:_1.0__obskHz:_1.0.txt\", #\n",
    "             \"2k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.5.txt\", #\n",
    "    \n",
    "            #targ 1250 Hz\n",
    "             \"2k/medium/split_0.5/targetKhz:_1.25__obskHz:_1.0.txt\", # ABOUT TO RUN 600\n",
    "             \"2k/medium/split_0.5/targetKhz:_1.25__obskHz:_0.5.txt\", # ABOUT TO RUN 600\n",
    "    \n",
    "            #targ 1500 Hz\n",
    "             \"2k/medium/split_0.5/targetKhz:_1.5__obskHz:_1.0.txt\", # ABOUT TO RUN 1000\n",
    "             \"2k/medium/split_0.5/targetKhz:_1.5__obskHz:_0.5.txt\", # ABOUT TO RUN 1000\n",
    "    \n",
    "     \n",
    "             #targ 2000 Hz\n",
    "             '2k/medium/split_0.5/targetKhz:_2.0__obskHz:_1.0.txt', #no exp\n",
    "             \n",
    "    \n",
    "           ########################################################################### 4k\n",
    "           #######################4k, 0.9 \n",
    "           #4k, 0.9 500 target Hz COMPLETE\n",
    "           \"4k/medium/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt\",\n",
    "           \"4k/medium/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt\",\n",
    "            \n",
    "           #4k, 0.9 1000 target Hz RUNNING\n",
    "           '4k/medium/split_0.9/targetKhz:_0.75__obskHz:_0.5.txt', #RUNNING 200\n",
    "           '4k/medium/split_0.9/targetKhz:_0.75__obskHz:_1.0.txt', #RUNNING 200\n",
    "    \n",
    "           \n",
    "           #4k, 0.9 1000 target Hz COMPLETE\n",
    "           '4k/medium/split_0.9/targetKhz:_1.0__obskHz:_0.5.txt',\n",
    "           '4k/medium/split_0.9/targetKhz:_1.0__obskHz:_1.0.txt',\n",
    "    \n",
    "           #4k, 0.9 1250 target Hz COMPLETE\n",
    "           '4k/medium/split_0.9/targetKhz:_1.25__obskHz:_0.5.txt', #RUNNING 400\n",
    "           '4k/medium/split_0.9/targetKhz:_1.25__obskHz:_1.0.txt', #RUNNING 400\n",
    "           \n",
    "           #4k, 0.9 1500 target Hz COMPLETE\n",
    "           '4k/medium/split_0.9/targetKhz:_1.5__obskHz:_0.5.txt', #RUNNING 700\n",
    "           '4k/medium/split_0.9/targetKhz:_1.5__obskHz:_1.0.txt', #RUNNING 700\n",
    "            \n",
    "\n",
    "           #######################4k, 0.5\n",
    "           #4k 0.5 target kHz COMPLETE\n",
    "           '4k/medium/split_0.5/targetKhz:_0.5__obskHz:_0.5.txt', #???\n",
    "           \"4k/medium/split_0.5/targetKhz:_0.5__obskHz:_1.0.txt\",  #???\n",
    "    \n",
    "           #4k 0.75 target kHz COMPLETE\n",
    "           \"4k/medium/split_0.5/targetKhz:_0.75__obskHz:_0.5.txt\", #NO EXP\n",
    "           \"4k/medium/split_0.5/targetKhz:_0.75__obskHz:_1.0.txt\",  \n",
    "           \n",
    "           #4k 1.0 target kHz \n",
    "           \"4k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.5.txt\",# ????\n",
    "           \"4k/medium/split_0.5/targetKhz:_1.0__obskHz:_1.0.txt\",   # ALREADY HAVE IT\n",
    "    \n",
    "           #4k, 0.5 1250 target Hz NEED TO RUN\n",
    "           '4k/medium/split_0.5/targetKhz:_1.25__obskHz:_0.5.txt', #ABOUT TO RUN 500\n",
    "           '4k/medium/split_0.5/targetKhz:_1.25__obskHz:_1.0.txt', #ABOUT TO RUN 500\n",
    "    \n",
    "            #4k, 0.5 1500 target Hz NEED TO RUN\n",
    "           '4k/medium/split_0.5/targetKhz:_1.5__obskHz:_0.5.txt', #ABOUT TO RUN 900\n",
    "           '4k/medium/split_0.5/targetKhz:_1.5__obskHz:_1.0.txt', #NO EXP\n",
    "\n",
    "           #4k 2.0 target kHz \n",
    "           \"4k/medium/split_0.5/targetKhz:_2.0__obskHz:_0.5.txt\", \n",
    "           \"4k/medium/split_0.5/targetKhz:_2.0__obskHz:_1.0.txt\", \n",
    "           \"4k/medium/split_0.5/targetKhz:_2.0__obskHz:_1.5.txt\", #For now this is deemed unessential.\n",
    "           \"4k/medium/split_0.5/targetKhz:_2.0__obskHz:_2.0.txt\", \n",
    "\n",
    "           #4k 0.5, bigger and better! \n",
    "\n",
    "           #\"2k/medium/split_0.5/targetKhz:_1.5__obskHz:_1.0.txt\", \n",
    "\n",
    "\n",
    "           \"4k/medium/split_0.5/targetKhz:_3.0__obskHz:_0.5.txt\",\n",
    "           \"4k/medium/split_0.5/targetKhz:_3.0__obskHz:_1.0.txt\",\n",
    "           \"4k/medium/split_0.5/targetKhz:_3.0__obskHz:_2.0.txt\",\n",
    "\n",
    "           #\"4k/medium/split_0.5/targetKhz:_4.0__obskHz:_0.5.txt\", #??? broken\n",
    "           #\"4k/medium/split_0.5/targetKhz:_4.0__obskHz:_1.0.txt\", #??? broken\n",
    "           #\"4k/medium/split_0.5/targetKhz:_4.0__obskHz:_2.0.txt\", #??? broken\n",
    "\n",
    "           #\"4k/medium/split_0.5/targetKhz:_0.75__obskHz:_1.0.txt\",\n",
    "\n",
    "           # MORE DETAIL:, given that the others aren't converging. \n",
    "         ]\n",
    "path_lst_unq = check_for_duplicates(path_lst, verbose = False)\n",
    "dict_lst_unq = check_for_duplicates(dict_lst, verbose = False)\n",
    "#display(path_lst_unq)\n",
    "complete_experiment_path_lst = path_lst_unq\n",
    "#complete_experiment_path_lst = experiments1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe976c89be74d09bcad35924bf45fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment list, fixing interpolation...', max=101.0, sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EchoStateExperiment' object has no attribute 'smooth_bool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/DL_LAB/Reservoir/MARIOS/PyFiles/experiment.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'experiment list, fixing interpolation...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#range(len(experiment_lst)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m#print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mhi_train_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhi_test_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecover_test_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mmodels_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_LAB/Reservoir/MARIOS/PyFiles/experiment.py\u001b[0m in \u001b[0;36mrecover_test_set\u001b[0;34m(json_obj)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mexperiment_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEchoStateExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mjson_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"experiment_inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mobs_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"get_observer_inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_LAB/Reservoir/MARIOS/PyFiles/experiment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size, file_path, target_frequency, out_path, obs_hz, target_hz, verbose, smooth_bool)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhoriz_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"observer_bounds\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"response_bounds\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_LAB/Reservoir/MARIOS/PyFiles/experiment.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, smooth)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_bool\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EchoStateExperiment' object has no attribute 'smooth_bool'"
     ]
    }
   ],
   "source": [
    "assert(check_for_duplicates(complete_experiment_path_lst) != True), \"duplicates found\"\n",
    "\n",
    "bp_ = \"./experiment_results/\"\n",
    "\n",
    "\n",
    "\n",
    "for i, path in enumerate(complete_experiment_path_lst):\n",
    "    if i ==0:\n",
    "        experiment_lst = []\n",
    "        NOT_INCLUDED = []\n",
    "        NOT_YET_RUN = []\n",
    "    else: \n",
    "        try:\n",
    "            spec_json = load_data(path, bp = bp_, verbose = False)\n",
    "            models_spec = list(spec_json[\"prediction\"].keys())\n",
    "            try:\n",
    "                assert len(models_spec) >= 3\n",
    "                assert \"exponential\" in models_spec\n",
    "                \n",
    "                experiment_lst.append(spec_json)\n",
    "            except:\n",
    "                NOT_INCLUDED += [i]\n",
    "        except:\n",
    "            NOT_YET_RUN +=[i]\n",
    "bye = \"\"\"\n",
    "### CORRECT INTERPOLATION:\n",
    "diff = []\n",
    "for i in range(len(experiment_lst)):\n",
    "    print(i)\n",
    "    hi = experiment_lst[i]\n",
    "    hiObj = get_experiment(hi, verbose = False, plot_split = False, compare_ = False)\n",
    "    hiObj.runInterpolation()\n",
    "    #print(hi[\"nrmse\"])\n",
    "    #plt.imshow(np.array(hi[\"prediction\"][\"exponential\"]), aspect = 0.1)\n",
    "    experiment_lst[i][\"prediction\"][\"interpolation\"] = hiObj.ip_res[\"prediction\"]\n",
    "    experiment_lst[i][\"nrmse\"][\"interpolation\"] = hiObj.ip_res[\"nrmse\"]\n",
    "    \n",
    "#experiment_lst = [ load_data(path, bp = bp_, verbose = False) for path in complete_experiment_path_lst]\n",
    "\"\"\"\n",
    "\n",
    "# fix nrmse calculation AND interpolation\n",
    "for i in trange(len(experiment_lst), desc='experiment list, fixing interpolation...'): #range(len(experiment_lst)):\n",
    "    #print(i)\n",
    "    hi_train_set, hi_test_set = recover_test_set(experiment_lst[i]) \n",
    "    \n",
    "    models_spec = list(experiment_lst[i][\"prediction\"].keys())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for model_ in models_spec:\n",
    "        pred_ = experiment_lst[i][\"prediction\"][model_]\n",
    "        corrected_nrmse = nrmse(pred_, hi_test_set)\n",
    "        experiment_lst[i][\"nrmse\"][model_] =corrected_nrmse\n",
    "        #print(experiment_lst[i][\"nrmse\"][model_] )\n",
    "        \n",
    "    #LINEAR INTERPOLATION: ############\n",
    "    hiObj = get_experiment(experiment_lst[i], verbose = False, plot_split = False, compare_ = False)\n",
    "    hiObj.runInterpolation()\n",
    "    experiment_lst[i][\"prediction\"][\"interpolation\"] = hiObj.ip_res[\"prediction\"]\n",
    "    experiment_lst[i][\"nrmse\"][\"interpolation\"] = hiObj.ip_res[\"nrmse\"]\n",
    "    #END LINEAR INTERPOLATION: ############\n",
    "        \n",
    "if NOT_YET_RUN != []:\n",
    "    print(\"the following paths have not yet been run: \")\n",
    "    print(np.array(dict_lst_unq)[NOT_YET_RUN])\n",
    "   \n",
    "        \n",
    "if NOT_INCLUDED != []:\n",
    "    print(\"the following paths contain incomplete experiments: (only unif finished)\")\n",
    "    #print(np.array(path_lst_unq)[NOT_INCLUDED])\n",
    "    print(np.array(dict_lst_unq)[NOT_INCLUDED])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOT_INCLUDED = check_for_duplicates(NOT_INCLUDED)\n",
    "NOT_YET_RUN = check_for_duplicates(NOT_YET_RUN)\n",
    "print(\"total experiments completed: \" + str(len(experiment_lst)))\n",
    "print(\"total experiments half complete: \" + str(len(NOT_INCLUDED)))\n",
    "print(\"total experiments not yet run: \" + str(len(NOT_YET_RUN)))\n",
    "pct_complete = (len(experiment_lst))/(len(experiment_lst)+len(NOT_INCLUDED)*0.5 + len(NOT_YET_RUN)) * 100\n",
    "pct_complete  = str(round(pct_complete, 1))\n",
    "print(\"Percentage of tests completed: \" + str(pct_complete) + \"%\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_combination(ip, exp, Test, n = 10, optimize = True):\n",
    "    \n",
    "    if optimize == True:\n",
    "        nrmses = []\n",
    "        predictions = []\n",
    "        #(np.array(Test) + np.array(predictions[\"exponential\"])) / 2\n",
    "        vals =[]\n",
    "        for i in range(n):\n",
    "            a = i / n\n",
    "            b = 1 - a\n",
    "            hybrid_pred = ((1-a) * ip + a * exp)\n",
    "            predictions += [hybrid_pred]\n",
    "            nrmses += [nrmse(hybrid_pred , Test) ]\n",
    "            vals += [a]\n",
    "            #nrmse(predictions[\"hybrid\"], Test) \n",
    "        idx = np.argmin(nrmses) \n",
    "        print(nrmses)\n",
    "        print(\"A!! \" + str(vals[idx]))\n",
    "        best_prediction = predictions[idx]\n",
    "        best_nrmse      = nrmses[idx]\n",
    "        return(best_prediction, best_nrmse)\n",
    "    else:\n",
    "        hybrid_pred  = (0.5 * ip) + (0.5 * exp)\n",
    "        hybrid_nrmse = nrmse(hybrid_pred , Test)\n",
    "        return(hybrid_pred, hybrid_nrmse)\n",
    "    \n",
    "\n",
    "### add hybrids\n",
    "for i in list(range(len(experiment_lst))):\n",
    "    experiment_lst[i]\n",
    "    predictions_= experiment_lst[i][\"prediction\"]\n",
    "    Train, Test = recover_test_set(experiment_lst[i])\n",
    "    hybrid_pred_, hybrid_R = optimize_combination(np.array(predictions_[\"interpolation\"]),\n",
    "                                                                      np.array(predictions_[\"exponential\"]),\n",
    "                                                                      Test, optimize = False)\n",
    "    experiment_lst[i][\"nrmse\"][\"hybrid\"]      = hybrid_R\n",
    "    experiment_lst[i][\"prediction\"][\"hybrid\"] = hybrid_pred_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_lst[1][\"nrmse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_IP = False\n",
    "\n",
    "\n",
    "def quick_dirty_convert(lst):\n",
    "    if IGNORE_IP == True:\n",
    "        lst *= 2\n",
    "    else:\n",
    "        lst *= 4\n",
    "    pd_ = pd.DataFrame(np.array(lst).reshape(-1,1))\n",
    "    return(pd_)\n",
    "    \n",
    "\n",
    "idx_lst = list(range(len(experiment_lst)))\n",
    "#idx_lst *= 3\n",
    "#idx_lst = pd.DataFrame(np.array(idx_lst).reshape(-1,1))\n",
    "\n",
    "idx_lst = quick_dirty_convert(idx_lst)\n",
    "\n",
    "obs_hz_lst, targ_hz_lst, targ_freq_lst = [], [], []\n",
    "\n",
    "for i, experiment in enumerate(experiment_lst):\n",
    "    #print(experiment['experiment_inputs'].keys())\n",
    "    targ_hz = experiment[\"experiment_inputs\"][\"target_hz\"]\n",
    "    obs_hz  = experiment[\"experiment_inputs\"][\"obs_hz\"]\n",
    "    targ_freq = experiment[\"experiment_inputs\"]['target_frequency']\n",
    "    \n",
    "    if experiment[\"experiment_inputs\"][\"target_hz\"] < 1:\n",
    "        targ_hz *= 1000*1000\n",
    "        obs_hz  *= 1000*1000\n",
    "    obs_hz_lst  += [obs_hz]\n",
    "    targ_hz_lst += [targ_hz]\n",
    "    targ_freq_lst += [targ_freq]\n",
    "    \n",
    "        \n",
    "    hz_line = {\"target hz\" : targ_hz }\n",
    "    hz_line = Merge(hz_line , {\"obs hz\" : obs_hz })\n",
    "    \n",
    "    #print(hz_line)\n",
    "    df_spec= experiment[\"nrmse\"]\n",
    "    \n",
    "    #df_spec = Merge(experiment[\"nrmse\"], {\"target hz\": targ_hz})\n",
    "    df_spec = pd.DataFrame(df_spec, index = [0])\n",
    "    \n",
    "    df_spec_rel = df_spec.copy()\n",
    "    #/df_spec_diff[\"uniform\"]\n",
    "    #df_spec_diff[\"rc_diff\"]\n",
    "    \n",
    "    if IGNORE_IP == True:\n",
    "        df_spec_rel = df_spec_rel / experiment[\"nrmse\"][\"uniform\"]#\n",
    "    else:\n",
    "        df_spec_rel = df_spec_rel / experiment[\"nrmse\"][\"interpolation\"]\n",
    "\n",
    "   \n",
    "    \n",
    "    #print( df_spec_rel)\n",
    "    #print(experiment[\"experiment_inputs\"].keys())\n",
    "    if i == 0:\n",
    "        df      = df_spec\n",
    "        df_rel  = df_spec_rel\n",
    "\n",
    "        \n",
    "    else:\n",
    "        df = pd.concat([df, df_spec])\n",
    "        df_rel = pd.concat([df_rel, df_spec_rel])\n",
    "\n",
    "\n",
    "df_net = df_rel.copy()\n",
    "        \n",
    "obs_hz_lst, targ_hz_lst = quick_dirty_convert(obs_hz_lst), quick_dirty_convert(targ_hz_lst)\n",
    "targ_freq_lst = quick_dirty_convert(targ_freq_lst)\n",
    "#display(df)\n",
    "if IGNORE_IP == True:\n",
    "    df_rel = df_rel.drop(columns = [\"interpolation\"])\n",
    "    df  = df.drop(columns = [\"interpolation\"])\n",
    "#df_rel  = df_rel.drop(columns = [\"hybrid\"])\n",
    "#df      = df.drop(    columns = [\"hybrid\"])\n",
    "\n",
    "df, df_rel = pd.melt(df), pd.melt(df_rel)\n",
    "df  = pd.concat( [idx_lst, df,  obs_hz_lst, targ_hz_lst, targ_freq_lst] ,axis = 1)\n",
    "\n",
    "df_rel = pd.concat( [idx_lst, df_rel,  obs_hz_lst, targ_hz_lst, targ_freq_lst], axis = 1)\n",
    "\n",
    "#df_diff = pd.concat( [idx_lst, df_diff,  obs_hz_lst, targ_hz_lst, targ_freq_lst], axis = 1)\n",
    "\n",
    "col_names = [\"experiment\", \"model\", \"nrmse\", \"obs hz\", \"target hz\", \"target freq\" ]\n",
    "df.columns, df_rel.columns    = col_names, col_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = df[df[\"model\"] == \"uniform\"]\n",
    "df_diff.model = \"diff\"\n",
    "nrmse_ = (df[df[\"model\"] == \"exponential\"][\"nrmse\"].values - df_diff[\"nrmse\"].values) * 100\n",
    "df_diff.nrmse = nrmse_\n",
    "def plot_loss_reduction():\n",
    "\n",
    "    df_diff = df[df[\"model\"] == \"uniform\"]\n",
    "    df_diff.model = \"diff\"\n",
    "    #df_diff[\"nrmse\"] = df_diff[\"nrmse\"] - df[df[\"model\"] == \"exponential\"][\"nrmse\"]\n",
    "\n",
    "    #df[df[\"model\"] == \"exponential\"] \n",
    "\n",
    "    nrmse_ = (df[df[\"model\"] == \"exponential\"][\"nrmse\"].values - df_diff[\"nrmse\"].values) * 100\n",
    "    df_diff.nrmse = nrmse_\n",
    "    pct = round(np.mean(nrmse_ < 0) * 100,2)\n",
    "    print(\"odds of loss reduction with exponential weights vs uniform weights: \" + str(pct) + \"%\")\n",
    "    print(\"mean % loss change: \" + str(round(np.mean(nrmse_))) + \"%\")\n",
    "\n",
    "    #sns.catplot(x = \"model\", y = \"nrmse\", data = df_diff)\n",
    "    fig, ax = plt.subplots(1,1,figsize = (10, 6))\n",
    "    plt.xlabel(\"%change in loss\")\n",
    "    plt.ylabel(\"density\")\n",
    "    sns.kdeplot(df_diff[\"nrmse\"], shade = True)\n",
    "    plt.axvline(x=0, color = \"black\", label = \"zero\")\n",
    "    plt.axvline(x=np.mean(df_diff[\"nrmse\"]), color = \"red\", label = \"mean loss reduction\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_loss_reduction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_reduction2d(xx = \"target hz\"):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (6,6))\n",
    "    sns.kdeplot(df_diff[xx], df_diff[\"nrmse\"],\n",
    "                     cmap=\"Blues\", shade=True, shade_lowest=False, ax = ax)#, alpha = 0.5)\n",
    "    #plt.ayvline(y=0, color = \"black\", label = \"zero\")\n",
    "    sns.scatterplot(x = xx, y = \"nrmse\", data = df_diff, ax = ax,  linewidth=0, color = \"black\", alpha = 0.4)\n",
    "    plt.title(\"2d kde plot: nrmse vs target hz\")\n",
    "    plt.axhline(y=0.5, color='black', linestyle='-')\n",
    "    ax.set_ylabel(\"pct loss exp vs unif RC\")\n",
    "plot_loss_reduction2d()\n",
    "plot_loss_reduction2d(xx = \"obs hz\")\n",
    "plot_loss_reduction2d(xx = \"target freq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(pred_, truth, columnwise = True, typee = \"L1\"):\n",
    "    \"\"\"\n",
    "    inputs should be numpy arrays\n",
    "    variables:\n",
    "    pred_ : the prediction numpy matrix\n",
    "    truth : ground truth numpy matrix\n",
    "    columnwise: bool if set to true takes row-wise numpy array (assumes reader thinks of time as running left to right\n",
    "        while the code actually runs vertically.)\n",
    "        \n",
    "    This is an average of the loss across that point, which we must do if we are to compare different sizes of data.\n",
    "\n",
    "    \"\"\"\n",
    "    pred_ = np.array(pred_)\n",
    "    truth = np.array(truth)\n",
    "    assert pred_.shape == truth.shape\n",
    "    def L2_(x):\n",
    "        return(x*x)\n",
    "    def L1_(x):\n",
    "        return(abs(x))\n",
    "    assert typee in [\"L1\", \"L2\"]\n",
    "    if typee == \"L1\":\n",
    "        f = L1_\n",
    "    else:\n",
    "        f = L2_\n",
    "        \n",
    "    loss_arr = f(truth - pred_)  \n",
    "    if columnwise == True:\n",
    "        \n",
    "        loss_arr = np.mean(loss_arr, axis = 1)\n",
    "\n",
    "    return(loss_arr)\n",
    "\n",
    "\n",
    "def get_prediction(model, json_obj):\n",
    "    \n",
    "    experiment_ = EchoStateExperiment(**json_obj[\"experiment_inputs\"])\n",
    "    \n",
    "    obs_inputs = json_obj[\"get_observer_inputs\"]\n",
    "    obs_inputs[\"method\"] = \"exact\"\n",
    "    \n",
    "    experiment_.obs_idx, experiment_.resp_idx  = json_obj[\"obs_idx\"], json_obj[\"resp_idx\"]\n",
    "    \n",
    "    experiment_.get_observers(**obs_inputs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(json_obj.keys())\n",
    "    best_args =  json_obj['best arguments'][model]\n",
    "\n",
    "    esn = EchoStateNetwork(**best_args,\n",
    "        obs_idx  = json_obj['obs_idx'],\n",
    "        resp_idx = json_obj['resp_idx'])\n",
    "    Train, Test = recover_test_set(json_obj)\n",
    "    if model == \"uniform\":\n",
    "        esn.exp_weights = False\n",
    "    else:\n",
    "        esn.exp_weights = True\n",
    "        \n",
    "    \n",
    "    \n",
    "    experiment_.already_trained(json_obj[\"best arguments\"][model], exponential = False)\n",
    "    return(experiment_.prediction)\n",
    "\n",
    "\n",
    "def build_loss_df(  #split = 0.5, \n",
    "              exp_json_lst = experiment_lst, \n",
    "              loss_ = \"L1\", \n",
    "              columnwise = True,\n",
    "              relative = True,\n",
    "              rolling = None,\n",
    "              models = [\"uniform\", \"exponential\", \"interpolation\", \"hybrid\"],\n",
    "              silent = True,\n",
    "              hybrid = True):\n",
    "    #exp stands for experiment here, not exponential\n",
    "    \"\"\"\n",
    "    columnwise == False means don't take the mean.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    \n",
    "    for i in trange(len(exp_json_lst), desc='processing path list...'):\n",
    "        exp_json = exp_json_lst[i]\n",
    "        \n",
    "       \n",
    "        split_ = exp_json[\"get_observer_inputs\"][\"split\"]\n",
    "        \n",
    "        exp_obj = get_experiment(exp_json, compare_ = False, verbose = False, plot_split = False)\n",
    "\n",
    "\n",
    "        #construct the required data frame and caculate the nrmse from the predictions:\n",
    "        train_, test_ = recover_test_set(exp_json)\n",
    "        #print(test_.shape)\n",
    "        #print(exp_json[\"prediction\"].shape)\n",
    "\n",
    "\n",
    "        if i == 0:\n",
    "            A = exp_obj.A\n",
    "            \n",
    "        test_len = test_.shape[0]\n",
    "        train_len = A.shape[0] - test_len\n",
    "        time_lst = []\n",
    "        time_lst_one_run = list(exp_obj.T[train_len:].reshape(-1,))\n",
    "        \n",
    "        if columnwise ==  False:\n",
    "            time_lst_one_run *= test_.shape[1]\n",
    "        for j, model in enumerate(models): # \n",
    "            #R is new name for nrmseccccc\n",
    "            shared_args = {\n",
    "                \"pred_\" : exp_json[\"prediction\"][model],\n",
    "                \"truth\": test_,\n",
    "                 \"columnwise\" : columnwise\n",
    "            }\n",
    "            \n",
    "            L1_spec = loss(**shared_args, typee = \"L1\")\n",
    "            L2_spec = loss(**shared_args, typee = \"L2\")\n",
    "            if columnwise == False:\n",
    "                #what does columnwise = True even mean?\n",
    "                L1_spec = np.mean(L1_spec.T, axis = 0)\n",
    "                L2_spec = np.mean(L2_spec.T, axis = 0)\n",
    "            L2_spec = list(L2_spec.reshape(-1,))\n",
    "\n",
    "                #assert np.array_equal(R_spec[:test_len], hi)\n",
    "\n",
    "            #idx_lst = list(range(test_len)\n",
    "\n",
    "            L1_spec = pd.DataFrame({model : L1_spec})\n",
    "            time_lst += time_lst_one_run\n",
    "\n",
    "            if j == 0:\n",
    "                rDF_spec = L1_spec\n",
    "                L2_lst = L2_spec \n",
    "            else:\n",
    "                rDF_spec = pd.concat([rDF_spec, L1_spec], axis = 1)\n",
    "                L2_lst += L2_spec\n",
    "            \n",
    "            \n",
    "        time_ = pd.Series(time_lst)\n",
    "        rDF_spec = pd.melt(rDF_spec)\n",
    "\n",
    "        rDF_spec[\"L2_loss\"] = L2_lst\n",
    "        rDF_spec[\"split\"] = split_\n",
    "        rDF_spec[\"time\"] = time_ \n",
    "        rDF_spec[\"experiment #\"] = count\n",
    "        rDF_spec.columns = [\"model\", \"L1_loss\", \"L2_loss\", \"split\",  \"time\",\"experiment #\"]\n",
    "\n",
    "        if i == 0:\n",
    "            rDF = rDF_spec\n",
    "        else:\n",
    "            rDF = pd.concat([rDF, rDF_spec], axis = 0)\n",
    "            #count+=1\n",
    "            \n",
    "    if silent != True:\n",
    "        display(rDF)\n",
    "    return(rDF)\n",
    "\n",
    "def loss_plot(rDF, rolling, split, loss = \"L2\", relative = False, include_ip = False):\n",
    "    \n",
    "    if include_ip == False:\n",
    "        rDF = rDF[(rDF.model == \"uniform\") | (rDF.model == \"exponential\")]\n",
    "    \n",
    "    rDF = rDF[rDF.split == split]\n",
    "    if loss == \"L2\":\n",
    "        LOSS = rDF.L2_loss\n",
    "    else:\n",
    "        LOSS = rDF.L1_loss\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (12, 6))\n",
    "    if relative == True:\n",
    "        diff = rDF[rDF.model == \"exponential\"][\"loss\"].values.reshape(-1,) - rDF[rDF.model == \"uniform\"][\"loss\"].values.reshape(-1,)\n",
    "\n",
    "        df_diff = rDF[rDF.model == \"uniform\"].copy()\n",
    "        df_diff.model = \"diff\"\n",
    "        df_diff.loss = diff\n",
    "        \n",
    "        sns.lineplot( x = \"time\", y = \"loss\" , hue = \"model\" , data = df_diff)\n",
    "        ax.set_title(loss_ + \" loss vs time relative\")\n",
    "    else:\n",
    "    \n",
    "        \n",
    "        if rolling != None:\n",
    "            sns.lineplot( x = \"time\", y = LOSS.rolling(rolling).mean() , hue = \"model\" , data = rDF)\n",
    "            #sns.scatterplot( x = \"time\", y = \"loss\" , hue = \"model\" , data = rDF, alpha = 0.005, edgecolor= None)\n",
    "        else:\n",
    "            sns.lineplot( x = \"time\", y = \"loss\" , hue = \"model\" , data = rDF)\n",
    "        ax.set_title(loss + \" loss vs time for all RC's, split = \" + str(split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args= {\"relative\": False,\n",
    "       \"columnwise\" : True,\n",
    "       \"rolling\" : 9,\n",
    "        \"models\" : [\"uniform\", \"exponential\", \"interpolation\", \"hybrid\"]\n",
    "}\n",
    "Loss_df = build_loss_df(**args, loss_ = \"L1\")\n",
    "#L2_loss_df = loss_df(**args, loss_ = \"L2\")\n",
    "#L1_loss_df = loss_df(relative = False, columnwise = False, rolling = 10, loss_ = \"L1\", models = [\"uniform\", \"exponential\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Loss_df.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(Loss_df, rolling = 7, split = 0.5, loss = \"L1\")\n",
    "loss_plot(Loss_df, rolling = 7, split = 0.5, loss = \"L2\")\n",
    "loss_plot(Loss_df, rolling = 7, split = 0.5, loss = \"L2\", include_ip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(Loss_df, rolling = 7, split = 0.9, loss = \"L1\")\n",
    "loss_plot(Loss_df, rolling = 7, split = 0.9, loss = \"L2\")\n",
    "loss_plot(Loss_df, rolling = 7, split = 0.9, loss = \"L2\", include_ip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nrmse_kde_2d(xx = \"target hz\", \n",
    "                      log = True, \n",
    "                      alph = 1, \n",
    "                      black_pnts = True, \n",
    "                      models = {\"interpolation\" : \"Greens\", \"exponential\" : \"Reds\", \"uniform\" : \"Blues\"},\n",
    "                      enforce_bounds = False,\n",
    "                      target_freq = None):\n",
    "    \"\"\"\n",
    "    #todo description\n",
    "    \"\"\"\n",
    "    if target_freq != None:\n",
    "        df_spec = df[df[\"target freq\"] == target_freq]\n",
    "    else:\n",
    "        df_spec = df.copy()\n",
    "            \n",
    "    \n",
    "    def plot_(model_, colorr, alph = alph,  black_pnts =  black_pnts):\n",
    "        if colorr == \"Blues\":\n",
    "            color_ = \"blue\"\n",
    "        elif colorr == \"Reds\":\n",
    "            color_ = \"red\"\n",
    "        elif colorr == \"Greens\":\n",
    "            color_ = \"green\"\n",
    "            \n",
    "        df_ = df_spec[df_spec.model == model_] #df_ip  = df[df.model == \"interpolation\"]\n",
    "        \n",
    "        #display(df_)\n",
    "            \n",
    "        \n",
    "        hi = df_[\"nrmse\"]\n",
    "        cap = 1\n",
    "        if log == True:\n",
    "            hi = np.log(hi)/ np.log(10)\n",
    "            cap = np.log(cap) / np.log(10)\n",
    "        \n",
    "        \n",
    "        sns.kdeplot(df_[xx], hi, cmap= colorr, \n",
    "                    shade=True, shade_lowest=False, ax = ax, label = model_, alpha = alph)#, alpha = 0.5)\n",
    "        \n",
    "        if  black_pnts == True:\n",
    "            col_scatter = \"black\"\n",
    "        else:\n",
    "            col_scatter = color_\n",
    "        \n",
    "        sns.scatterplot(x = xx, y = hi, data = df_,  linewidth=0, \n",
    "                        color = col_scatter, alpha = 0.4, ax = ax)\n",
    "        \n",
    "        plt.title(\"2d kde plot: nrmse vs \" + xx)\n",
    "        \n",
    "        plt.axhline(y=cap, color=color_, linestyle='-', label = \"mean \" + str(model_), alpha = 0.5)\n",
    "        sns.lineplot(y = hi, x = xx, data = df_ , color = color_)#, alpha = 0.2)\n",
    "        if enforce_bounds == True:\n",
    "            ax.set_ylim(0,1)\n",
    "        if log == True:\n",
    "            ax.set_ylabel(\"log( NRMSE) \")\n",
    "        else: \n",
    "            ax.set_ylabel(\"NRMSE\")\n",
    "            \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (12,6))\n",
    "    for model in list(models.keys()):\n",
    "        print(model)\n",
    "        plot_(model, models[model], alph = alph)\n",
    "    #plot_(\"interpolation\", \"Blues\")\n",
    "    #plot_(\"exponential\", \"Reds\", alph = alph)\n",
    "    \n",
    "def kde_plots(target_freq = None, log = False, model = \"uniform\", \n",
    "             models = {\"interpolation\" : \"Greens\", \"exponential\" : \"Reds\", \"uniform\" : \"Blues\"},\n",
    "             enforce_bounds = True):\n",
    "    \"\"\"\n",
    "    HEATMAP EXAMPLE:\n",
    "                     enforce_bounds = True)\n",
    "    flights = flights.pivot(\"month\", \"year\", \"passengers\") #y, x, z\n",
    "    ax = sns.heatmap(flights)\n",
    "    plot_nrmse_kde_2d(**additional_arguments, \n",
    "                      models = {\"interpolation\" : \"Greens\", \"exponential\" : \"Reds\", \"uniform\" : \"Blues\"})\n",
    "    \n",
    "    plot_nrmse_kde_2d(xx = \"obs hz\", **additional_arguments, \n",
    "                      models = {\"interpolation\" : \"Greens\", \"exponential\" : \"Reds\", \"uniform\" : \"Blues\"})\n",
    "    \"\"\"\n",
    "    \n",
    "    additional_arguments ={ \"black_pnts\" : False, \n",
    "                           \"alph\" : 0.3, \n",
    "                           \"target_freq\" : target_freq}    \n",
    "    \n",
    "    cmap = \"coolwarm\"\n",
    "    \n",
    "   \n",
    "    def add_noise(np_array, log = log):\n",
    "        sizee = len(np_array)\n",
    "        x =  np.random.randint(100, size = sizee) + np_array \n",
    "        \n",
    "        return(x)\n",
    "    \n",
    "    nrmse_dict = {}\n",
    "    \n",
    "    for i, model in enumerate([\"uniform\", \"exponential\", \"interpolation\"]):\n",
    "        df_ = df[df.model == model ]\n",
    "        xx, yy = add_noise(df_[\"target hz\"]), add_noise(df_[\"obs hz\"])\n",
    "\n",
    "        nrmse= df_[\"nrmse\"]\n",
    "        if log == True:\n",
    "            print(\"hawabunga\")\n",
    "            nrmse = np.log(nrmse)\n",
    "        nrmse_dict[model] = nrmse\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    nrmse_diff = nrmse_dict[\"exponential\"].values.reshape(-1,)  - nrmse_dict[\"uniform\"].values.reshape(-1,) \n",
    "    print(\"(+): \" + str(np.sum((nrmse_diff > 0)*1)))\n",
    "    \n",
    "    print(\"(-): \" + str(np.sum((nrmse_diff < 0)*1)))\n",
    "    \n",
    "    \n",
    "    display(nrmse_diff)\n",
    "    xx, yy = add_noise(df_[\"target hz\"]), add_noise(df_[\"obs hz\"])\n",
    "    #sns.distplot(nrmse_diff, ax = ax[2])\n",
    "    sns.scatterplot(x = xx, y = yy, data = df_, ax = ax[2], palette=cmap, alpha = 0.9, s = 50, hue = nrmse_diff) #size = nrmse,\n",
    "    ax[2].set_title(\" diff: exponential - uniform\" )\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    \n",
    "    plot_nrmse_kde_2d(**additional_arguments, log = False, \n",
    "                      models = models, #{\"exponential\" : \"Reds\", \"uniform\" : \"Blues\", \"interpolation\" : \"Greens\"},\n",
    "                     enforce_bounds = True)\n",
    "    \n",
    "    \n",
    "    plot_nrmse_kde_2d(xx = \"obs hz\", **additional_arguments, log = False, \n",
    "                       models = models, #{\"exponential\" : \"Reds\", \"uniform\" : \"Blues\", \"interpolation\" : \"Greens\"},\n",
    "                       enforce_bounds = True)\n",
    "    \n",
    "               \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "kde_plots(models = {\"interpolation\" : \"Greens\", \"hybrid\" : \"Reds\"})#, \"uniform\" : \"Blues\"},)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plots(models = {\"interpolation\" : \"Greens\", \"exponential\" : \"Blues\", \"hybrid\" : \"Reds\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i, exper_ in enumerate(experiment_lst):\n",
    "    \n",
    "    print(exper_[\"nrmse\"][\"uniform\"])\n",
    "    print(exper_[\"nrmse\"][\"exponential\"])\n",
    "    print(\"\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: move the legend to the lower right corner\n",
    "kde_plots(target_freq = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plots(target_freq = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    " \n",
    "def optimize_combination(ip, exp, Test, n = 10, optimize = True):\n",
    "    \n",
    "    if optimize == True:\n",
    "        nrmses = []\n",
    "        predictions = []\n",
    "        #(np.array(Test) + np.array(predictions[\"exponential\"])) / 2\n",
    "        vals =[]\n",
    "        for i in range(n):\n",
    "            a = i / n\n",
    "            b = 1 - a\n",
    "            hybrid_pred = ((1-a) * ip + a * exp)\n",
    "            predictions += [hybrid_pred]\n",
    "            nrmses += [nrmse(hybrid_pred , Test) ]\n",
    "            vals += [a]\n",
    "            #nrmse(predictions[\"hybrid\"], Test) \n",
    "        idx = np.argmin(nrmses) \n",
    "        print(nrmses)\n",
    "        print(\"A!! \" + str(vals[idx]))\n",
    "        best_prediction = predictions[idx]\n",
    "        best_nrmse      = nrmses[idx]\n",
    "        return(best_prediction, best_nrmse)\n",
    "    else:\n",
    "        hybrid_pred  = (0.5 * ip) + (0.5 * exp)\n",
    "        hybrid_nrmse = nrmse(hybrid_pred , Test)\n",
    "        return(hybrid_pred, hybrid_nrmse)\n",
    "    \n",
    "\n",
    "def show_images(exper_, aspect = 10, sigma = 1, method = \"heatmap\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Train, Test = recover_test_set(exper_)\n",
    "    predictions = exper_[\"prediction\"]\n",
    "    nrmses      = exper_[\"nrmse\"]\n",
    "    predictions[\"ground_Truth\"]  = Test\n",
    "    nrmses[\"ground_Truth\"]       = 0\n",
    "    predictions[\"ground_Truth_smooth\"]  = gaussian_filter(Test, sigma=sigma)\n",
    "    nrmses[\"ground_Truth_smooth\"]       = 0\n",
    "    #predictions[\"hybrid\"]        = (np.array(predictions[\"interpolation\"]) + np.array(predictions[\"exponential\"])) / 2\n",
    "    #nrmses[\"hybrid\"]             =  nrmse(predictions[\"hybrid\"] , Test) \n",
    "    predictions[\"hybrid\"], nrmses[\"hybrid\"] = optimize_combination(np.array(predictions[\"interpolation\"]),\n",
    "                                                                  np.array(predictions[\"exponential\"]),\n",
    "                                                                  Test)\n",
    "    \n",
    "    for key, value in predictions.items():\n",
    "        arr = np.array(value)\n",
    "        full_arr = np.concatenate((Train, arr), axis = 0)\n",
    "        arr = full_arr\n",
    "        if method != \"heatmap\":\n",
    "            plt.imshow(arr.T, aspect = aspect)\n",
    "            plt.title(key +\" R: \" + str(nrmses[key]))\n",
    "            plt.show()       \n",
    "        else:\n",
    "            sns.heatmap(arr.T)\n",
    "            plt.title(key +\" R: \" + str(nrmses[key]))\n",
    "            plt.show()\n",
    "show_images(experiment_lst[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (14,4))\n",
    "sns.violinplot( y = \"nrmse\" , x = \"model\", data = df, ax = ax[0])\n",
    "sns.boxplot( y = \"nrmse\" , x = \"model\", data = df, ax = ax[1])\n",
    "ax[0].set_title(\"General NRMSE vs MODEL across different RC's\")\n",
    "ax[1].set_title(\"General NRMSE vs MODEL across different RC's\")\n",
    "ax[0].set_ylabel(\"NRMSE\"); ax[1].set_ylabel(\"NRMSE\")\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (14,4))\n",
    "sns.violinplot( y = \"nrmse\" , x = \"model\", data = df_rel, ax = ax[0])\n",
    "sns.boxplot( y = \"nrmse\" , x = \"model\", data = df_rel, ax = ax[1])\n",
    "ax[0].set_title(\"Relative NRMSE vs Interpolation model across different RC's\")\n",
    "ax[1].set_title(\"Relavite NRMSE vs Interpolation model across different RC's\")\n",
    "ax[0].set_ylabel(\"Relative NRMSE\"); ax[1].set_ylabel(\"Relative NRMSE\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (7,4))\n",
    "sns.violinplot( y = \"nrmse\" , x = \"model\", data = df_diff, ax = ax)\n",
    "#sns.boxplot( y = \"nrmse\" , x = \"model\", data = df_rel, ax = ax[1])\n",
    "ax.set_title(\"Relative NRMSE: ([exp nrmse] -  [unif nrmse])/[unif_nrmse] * 100\")\n",
    "ax.set_ylabel(\"Relative NRMSE\"); ax.set_ylabel(\"Relative NRMSE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"target hz\", data = df)\n",
    "plt.title(\"General NRMSE vs MODEL across different RC's\")\n",
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"target hz\", data = df_rel)\n",
    "plt.title(\"Relavite NRMSE vs Interpolation model across different RC's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = df[\"nrmse\"] #df[\"nrmse\"]np.log(df[\"nrmse\"])\n",
    "fig, ax = plt.subplots(1,1, figsize = (12,6))\n",
    "sns.scatterplot( y = hi, x = \"target hz\", data = df, hue = \"model\", alpha = 0.5, legend = False)\n",
    "sns.lineplot( y = hi, x = \"target hz\", data = df, hue = \"model\", alpha = 0.5)\n",
    "cap = np.log(1.0)/np.log(10)\n",
    "plt.axhline(y=cap, color=\"black\", linestyle='-', label = \"mean \" + str(model_), alpha = 0.5)\n",
    "plt.ylabel(\"log( NRMSE)\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize = (12,6))\n",
    "sns.scatterplot( y = hi, x = \"target hz\", data = df, hue = \"model\", alpha = 0.5, legend = False)\n",
    "sns.lineplot( y = hi, x = \"target hz\", data = df, hue = \"model\", alpha = 0.5)\n",
    "cap = np.log(1.0)/np.log(10)\n",
    "plt.axhline(y=cap, color=\"black\", linestyle='-', label = \"mean \" + str(model_), alpha = 0.5)\n",
    "plt.ylabel(\"log( NRMSE)\")\n",
    "plt.ylim((-1.5,cap))\n",
    "\n",
    "\n",
    "\n",
    "hi = df[\"nrmse\"]\n",
    "fig, ax = plt.subplots(1,1, figsize = (12,6))\n",
    "sns.scatterplot( y = hi, x = \"target hz\", data = df, hue = \"model\", alpha = 0.5, legend = False)\n",
    "sns.lineplot( y = hi, x = \"target hz\", data = df, hue = \"model\", alpha = 0.5)\n",
    "plt.ylabel(\"NRMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = np.log(df[\"nrmse\"])\n",
    "fig, ax = plt.subplots(1,1, figsize = (12,6))\n",
    "sns.scatterplot( y = hi, x = \"obs hz\", data = df, hue = \"model\", alpha = 0.5)\n",
    "sns.lineplot( y = hi, x = \"obs hz\", data = df, hue = \"model\", alpha = 0.5)\n",
    "ax.set_ylabel(\"Log ( NRMSE )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"target freq\", data = df)\n",
    "plt.title(\"General NRMSE vs MODEL across different RC's\")\n",
    "plt.ylim((0,1.5))\n",
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"target freq\", data = df_rel)\n",
    "plt.title(\"Relavite NRMSE vs Interpolation model across different RC's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"obs hz\", data = df)\n",
    "plt.title(\"General NRMSE vs MODEL across different RC's\")\n",
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"obs hz\", data = df_rel)\n",
    "plt.title(\"Relavite NRMSE vs Interpolation model across different RC's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_plot(experiment_lst):\n",
    "    \"\"\"\n",
    "    Let's visualize the hyper-parameter plots.\n",
    "    \"\"\"\n",
    "    log_vars = [\"noise\", \"connectivity\", \"regularization\", \"llambda\"]\n",
    "    \n",
    "    for i, experiment in enumerate(experiment_lst):\n",
    "        df_spec_unif = pd.DataFrame(experiment[\"best arguments\"][\"uniform\"], index = [0])\n",
    "        df_spec_exp  = pd.DataFrame(experiment[\"best arguments\"][\"exponential\"], index = [0])\n",
    "        if i == 0:\n",
    "            df_unif = df_spec_unif\n",
    "        else:\n",
    "            df_unif = pd.concat([df_unif, df_spec_unif])\n",
    "        if i == 0:\n",
    "            df_exp = df_spec_exp\n",
    "        else:\n",
    "            df_exp = pd.concat([df_exp, df_spec_exp])\n",
    "    print(\"uniform\")\n",
    "    unif_vars = [\"connectivity\", \"regularization\", \"leaking_rate\", \"spectral_radius\"]\n",
    "    exp_vars  = [\"llambda\", \"noise\"]\n",
    "    df_unif = df_unif[unif_vars]\n",
    "    df_exp = df_exp[unif_vars + exp_vars]\n",
    "    \n",
    "    for i in list(df_unif.columns):\n",
    "        if i in log_vars:\n",
    "            df_unif[i] = np.log(df_unif[i])/np.log(10)\n",
    "            \n",
    "    for i in list(df_exp.columns):\n",
    "        if i in log_vars:\n",
    "            df_exp[i] = np.log(df_exp[i])/np.log(10)\n",
    "    \n",
    "    \n",
    "    #display(df_unif)\n",
    "    \n",
    "    sns.catplot(data = df_unif)\n",
    "    plt.title(\"uniform RC hyper-parameters\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    sns.catplot(data = df_exp)\n",
    "    plt.title(\"exponential RC hyper-parameters\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    #display(df_exp)\n",
    "   \n",
    "hyper_parameter_plot(experiment_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, experiment in enumerate(experiment_lst):\n",
    "    #print(experiment['get_observer_inputs'].keys())\n",
    "    split = experiment['get_observer_inputs'][\"split\"]\n",
    "    targ_hz = experiment['experiment_inputs'][\"target_hz\"]\n",
    "    targ_idx_LB, targ_idx_UB = experiment[\"resp_idx\"][0], experiment[\"resp_idx\"][-1]\n",
    "    obs_hz = experiment['experiment_inputs'][\"obs_hz\"]\n",
    "    f = np.array(experiment_8_obj.f)\n",
    "    obs_idx = experiment[\"obs_idx\"] \n",
    "\n",
    "    obs_idx  = [int(j) for j in experiment[\"obs_idx\"] ]\n",
    "    obs_freq = [max(f) - f[j] for j in obs_idx]\n",
    "    \n",
    "    \n",
    "    print(\"\\nexperiment: \" + str(i) + \", target hz: \" + str(targ_hz) + \", obs hz: \" + str(obs_hz) +\n",
    "         \", split: \" + str(split))\n",
    "\n",
    "    \n",
    "    print(\"target idx: [\" + str(targ_idx_LB) + \", \" + str(targ_idx_UB) + \"]\")\n",
    "    print(\"target freq: [\" + str(max(f) - f[targ_idx_LB]) + \", \" + str(max(f) - f[targ_idx_UB]) + \"]\")\n",
    "    print(\"obs idx: \" + str(obs_idx))\n",
    "    print(\"obs freq: \" + str(obs_freq))\n",
    "    print(experiment_8_obj.A.shape[0] - np.array(experiment[\"prediction\"][\"interpolation\"]).shape[0])\n",
    "    print(experiment_8_obj.A.shape[0])\n",
    "    #print(experiment[\"resp_idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_exp_weights(json_obj, llambda = None):\n",
    "    print(json_obj.keys())\n",
    "    esn_ = EchoStateNetwork(**json_obj[\"best arguments\"][\"exponential\"], plot = True)\n",
    "    esn_.obs_idx  = json_obj[\"obs_idx\"]\n",
    "    esn_.resp_idx = json_obj[\"resp_idx\"]\n",
    "    if llambda != None:\n",
    "        esn_.llambda = llambda\n",
    "    esn_.get_exp_weights()\n",
    "\n",
    "\n",
    "for i in experiment_lst:\n",
    "    show_exp_weights(i)  \n",
    "#show_exp_weights(experiment_2)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_exp_weights(i, llambda = 10**-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10**-2 \n",
    "np.log(10**-4)/np.log(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_lst = [experiment_1, experiment_2, experiment_3, experiment_4, \n",
    "                  experiment_5, experiment_6, experiment_7, experiment_8]\n",
    "\n",
    "def quick_dirty_convert(lst):\n",
    "    lst *= 3\n",
    "    print(lst)\n",
    "    pd_ = pd.DataFrame(np.array(lst).reshape(-1,1))\n",
    "    return(pd_)\n",
    "    \n",
    "\n",
    "idx_lst = list(range(len(experiment_lst)))\n",
    "#idx_lst *= 3\n",
    "#idx_lst = pd.DataFrame(np.array(idx_lst).reshape(-1,1))\n",
    "\n",
    "idx_lst = quick_dirty_convert(idx_lst)\n",
    "\n",
    "obs_hz_lst, targ_hz_lst = [], []\n",
    "\n",
    "for i, experiment in enumerate(experiment_lst):\n",
    "    targ_hz = experiment[\"experiment_inputs\"][\"target_hz\"]\n",
    "    obs_hz  = experiment[\"experiment_inputs\"][\"obs_hz\"]\n",
    "    \n",
    "    \n",
    "    if experiment[\"experiment_inputs\"][\"target_hz\"] < 1:\n",
    "        targ_hz *= 1000*1000\n",
    "        obs_hz  *= 1000*1000\n",
    "    obs_hz_lst  += [obs_hz]\n",
    "    targ_hz_lst += [targ_hz]\n",
    "    \n",
    "        \n",
    "    hz_line = {\"target hz\" : targ_hz }\n",
    "    hz_line = Merge(hz_line , {\"obs hz\" : obs_hz })\n",
    "    \n",
    "    #print(hz_line)\n",
    "    df_spec = experiment[\"nrmse\"]\n",
    "    #df_spec = Merge(experiment[\"nrmse\"], {\"target hz\": targ_hz})\n",
    "    df_spec = pd.DataFrame(df_spec, index = [0])\n",
    "    \n",
    "    df_spec_rel = df_spec.copy()\n",
    "    df_spec_rel = df_spec_rel / experiment[\"nrmse\"][\"interpolation\"]\n",
    "    \n",
    "    #print( df_spec_rel)\n",
    "    #print(experiment[\"experiment_inputs\"].keys())\n",
    "    if i == 0:\n",
    "        df = df_spec\n",
    "        df_rel = df_spec_rel\n",
    "        \n",
    "    else:\n",
    "        df = pd.concat([df, df_spec])\n",
    "        df_rel = pd.concat([df_rel, df_spec_rel])\n",
    "\n",
    "#obs_hz_lst  *= 3\n",
    "#targ_hz_lst *= 3\n",
    "\n",
    "obs_hz_lst, targ_hz_lst = quick_dirty_convert(obs_hz_lst), quick_dirty_convert(targ_hz_lst)\n",
    "        \n",
    "df, df_rel = pd.melt(df), pd.melt(df_rel)\n",
    "df  = pd.concat( [idx_lst, df,  obs_hz_lst, targ_hz_lst] ,axis = 1)\n",
    "\n",
    "df_rel = pd.concat( [idx_lst, df_rel,  obs_hz_lst, targ_hz_lst], axis = 1)\n",
    "\n",
    "df.columns     = [\"experiment\", \"model\", \"nrmse\", \"obs hz\", \"target hz\" ]\n",
    "df_rel.columns = [\"experiment\", \"model\", \"nrmse\", \"obs hz\", \"target hz\"] \n",
    "display(df)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (14,4))\n",
    "sns.violinplot( y = \"nrmse\" , x = \"model\", data = df, ax = ax[0])\n",
    "sns.boxplot( y = \"nrmse\" , x = \"model\", data = df, ax = ax[1])\n",
    "ax[0].set_title(\"General NRMSE vs MODEL across different RC's\")\n",
    "ax[1].set_title(\"General NRMSE vs MODEL across different RC's\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (14,4))\n",
    "sns.violinplot( y = \"nrmse\" , x = \"model\", data = df_rel, ax = ax[0])\n",
    "sns.boxplot( y = \"nrmse\" , x = \"model\", data = df_rel, ax = ax[1])\n",
    "ax[0].set_title(\"Relative NRMSE vs Interpolation model across different RC's\")\n",
    "ax[1].set_title(\"Relavite NRMSE vs Interpolation model across different RC's\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"target hz\", data = df)\n",
    "plt.title(\"General NRMSE vs MODEL across different RC's\")\n",
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"target hz\", data = df_rel)\n",
    "plt.title(\"Relavite NRMSE vs Interpolation model across different RC's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"obs hz\", data = df)\n",
    "plt.title(\"General NRMSE vs MODEL across different RC's\")\n",
    "sns.catplot(y = \"nrmse\" , x = \"model\", hue =\"obs hz\", data = df_rel)\n",
    "plt.title(\"Relavite NRMSE vs Interpolation model across different RC's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def merge_unif_exp(fp_unif, fp_exp):\n",
    "    exp_dat = load_data(fp_exp)\n",
    "    unif_dat = load_data(fp_unif)\n",
    "    assert exp_dat[\"prediction\"][\"interpolation\"] == unif_dat[\"prediction\"][\"interpolation\"], \"something is wrong!\"\n",
    "    joint_dat = unif_dat.copy()\n",
    "    for i in [\"prediction\", \"nrmse\", \"best arguments\"]:\n",
    "        exp_dict = {\"exponential\" : exp_dat[i][\"exponential\"]}\n",
    "        joint_dat[i] = Merge(joint_dat[i], exp_dict)\n",
    "    print(joint_dat[\"best arguments\"])\n",
    "        \n",
    "     \n",
    "    return(joint_dat)\n",
    "#0.5_1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_lst =[experiment_1, experiment_2, experiment_3, experiment_4,\n",
    "                 experiment_5, experiment_6, experiment_7, experiment_8\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_interpolation(exper_):\n",
    "    hiObj = get_experiment(exper_, verbose = False, plot_split = False, compare_ = False)\n",
    "    hiObj.runInterpolation()\n",
    "    exper_[\"prediction\"][\"interpolation\"] = hiObj.ip_res[\"prediction\"]\n",
    "    exper_[\"nrmse\"][\"interpolation\"] = hiObj.ip_res[\"nrmse\"]\n",
    "    print(hiObj.ip_res[\"nrmse\"])\n",
    "    return(exper_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = load_data('experiment_results/1k/publish/split_0.9/targetKhz:_0.5__obskHz:_0.5.txt')\n",
    "hi = fix_interpolation(hi)\n",
    "\n",
    "get_experiment(hi) # broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = load_data('experiment_results/1k/publish/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt')\n",
    "hi = fix_interpolation(hi)\n",
    "\n",
    "get_experiment(hi) # broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = load_data('experiment_results/1k/publish/split_0.9/targetKhz:_0.5__obskHz:_1.0.txt')\n",
    "hi = fix_interpolation(hi)\n",
    "\n",
    "get_experiment(hi) # broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = load_data('experiment_results/1k/publish/split_0.5/targetKhz:_0.1__obskHz:_0.1.txt')\n",
    "hi = fix_interpolation(hi)\n",
    "\n",
    "get_experiment(hi) # broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = load_data('experiment_results/1k/publish/split_0.5/targetKhz:_0.1__obskHz:_0.25.txt')\n",
    "hi = fix_interpolation(hi)\n",
    "\n",
    "get_experiment(hi) # broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_5 = load_data('/Users/hayden/Desktop/DL_LAB/Reservoir/MARIOS/experiment_results/4k/medium/split_0.5/targetKhz:_1.0__obskHz:_0.5.txt')\n",
    "                         #bp = '/Users/hayden/Desktop/')\n",
    "experiment_5_obj = get_experiment(experiment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "uniform_ = df_rel[df_rel.model == \"uniform\"]\n",
    "exp_ = df_rel[df_rel.model == \"exponential\"]\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (12,6))\n",
    "sns.kdeplot(uniform_[\"target hz\"], uniform_[\"nrmse\"],\n",
    "                 cmap=\"Reds\", shade=True, shade_lowest=False, ax = ax[0])#, alpha = 0.5)\n",
    "sns.kdeplot(exp_[\"target hz\"], exp_[\"nrmse\"],\n",
    "                 cmap=\"Blues\", shade=True, shade_lowest=False, ax = ax[1])#, alpha = 0.5)\n",
    "ax[0].set_ylim(0,0.3)\n",
    "ax[1].set_ylim(0,0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOOTH\n",
    "#experiment_5 = load_data('/Users/hayden/Desktop/DL_LAB/Reservoir/MARIOS/experiment_results/2k/medium/split_0.5/targetKhz:_0.02__obskHz:_0.01.txt')\n",
    "#                         #bp = '/Users/hayden/Desktop/')\n",
    "#experiment_5_obj = get_experiment(experiment_5)\n",
    "%run -i '../MARIOS/PyFiles/imports.py'\n",
    "%run -i '../MARIOS/PyFiles/helpers.py'\n",
    "%run -i \"../MARIOS/PyFiles/experiment.py\"\n",
    "\n",
    "experiment_ = experiment_5.copy()\n",
    "for key, prediction in experiment_[\"prediction\"].items():\n",
    "    prediction = np.array(prediction)\n",
    "    Train, Test = recover_test_set(experiment_)\n",
    "    \n",
    "    experiment_[\"nrmse\"][key] = nrmse(prediction, Test)\n",
    "get_experiment(experiment_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOOTH\n",
    "experiment_5 = load_data('/Users/hayden/Desktop/DL_LAB/Reservoir/MARIOS/experiment_results/2k/medium/split_0.5/targetKhz:_0.02__obskHz:_0.01.txt')\n",
    "                         #bp = '/Users/hayden/Desktop/')\n",
    "experiment_ = experiment_5.copy()\n",
    "for key, prediction in experiment_[\"prediction\"].items():\n",
    "    prediction = np.array(prediction)\n",
    "    Train, Test = recover_test_set(experiment_)\n",
    "    \n",
    "    experiment_[\"nrmse\"][key] = nrmse(prediction, Test)\n",
    "experiment_5_obj = get_experiment(experiment_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
